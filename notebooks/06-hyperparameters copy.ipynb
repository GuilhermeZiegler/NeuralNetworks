{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import myFunctions\n",
    "from myFunctions import install_packages, save_table \n",
    "### packages required\n",
    "install_packages()\n",
    "\n",
    "### importing required packages\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import joblib\n",
    "\n",
    "\n",
    "## Model Classes\n",
    "# LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM model class for time series forecasting.\n",
    "\n",
    "    Attributes:\n",
    "        lstm (nn.LSTM): LSTM layer for sequence processing.\n",
    "        fc (nn.Linear): Fully connected layer to output predictions.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with shape (batch_size, seq_len, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with predictions.\n",
    "        \"\"\"\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Using the last output of the sequence\n",
    "        return out\n",
    "\n",
    "# GRU Model\n",
    "class GRUModel(nn.Module):\n",
    "    \"\"\"\n",
    "    GRU model class for time series forecasting.\n",
    "\n",
    "    Attributes:\n",
    "        gru (nn.GRU): GRU layer for sequence processing.\n",
    "        fc (nn.Linear): Fully connected layer to output predictions.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with shape (batch_size, seq_len, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with predictions.\n",
    "        \"\"\"\n",
    "        gru_out, hn = self.gru(x)\n",
    "        out = self.fc(gru_out[:, -1, :])  # Using the last output of the sequence\n",
    "        return out\n",
    "\n",
    "# CNN-LSTM Model\n",
    "class CNNLSTMModel(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN-LSTM model class combining convolutional layers with LSTM for time series forecasting.\n",
    "\n",
    "    Attributes:\n",
    "        conv1d (nn.Conv1d): Convolutional layer for feature extraction.\n",
    "        lstm (nn.LSTM): LSTM layer for sequence processing.\n",
    "        fc (nn.Linear): Fully connected layer to output predictions.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, conv_filters):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(input_size, conv_filters, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(conv_filters, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with shape (batch_size, seq_len, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with predictions.\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)  # For Conv1d, we need [batch, channels, seq_len]\n",
    "        x = self.conv1d(x)\n",
    "        x = x.permute(0, 2, 1)  # Returning to [batch, seq_len, channels]\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Using the last output of the sequence\n",
    "        return out\n",
    "\n",
    "# CNN-GRU Model\n",
    "class CNNGRUModel(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN-GRU model class combining convolutional layers with GRU for time series forecasting.\n",
    "\n",
    "    Attributes:\n",
    "        conv1d (nn.Conv1d): Convolutional layer for feature extraction.\n",
    "        gru (nn.GRU): GRU layer for sequence processing.\n",
    "        fc (nn.Linear): Fully connected layer to output predictions.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, conv_filters):\n",
    "        super(CNNGRUModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(input_size, conv_filters, kernel_size=3, padding=1)\n",
    "        self.gru = nn.GRU(conv_filters, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with shape (batch_size, seq_len, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with predictions.\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)  # For Conv1d, we need [batch, channels, seq_len]\n",
    "        x = self.conv1d(x)\n",
    "        x = x.permute(0, 2, 1)  # Returning to [batch, seq_len, channels]\n",
    "        gru_out, hn = self.gru(x)\n",
    "        out = self.fc(gru_out[:, -1, :])  # Using the last output of the sequence\n",
    "        return out\n",
    "\n",
    "\n",
    "def scale_features(df, exclude_columns=['date', 'day']):\n",
    "    \"\"\"\n",
    "    Scales all columns of the DataFrame except the ones specified in exclude_columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        exclude_columns (list): Columns that should not be scaled.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Scaled DataFrame.\n",
    "        dict: A dictionary containing the scalers for each scaled column.\n",
    "    \"\"\"\n",
    "    scalers = {}\n",
    "    columns_to_scale = [col for col in df.columns if col not in exclude_columns]\n",
    "    \n",
    "    df_scaled = df.copy()\n",
    "    for col in columns_to_scale:\n",
    "        scaler = MinMaxScaler()\n",
    "        df_scaled[col] = scaler.fit_transform(df[[col]])\n",
    "        scalers[col] = scaler\n",
    "    \n",
    "    return df_scaled, scalers\n",
    "\n",
    "def data_to_array(df, window_size, target, features):\n",
    "    \"\"\"\n",
    "    Prepares X and y with targets shifted for the next day after the window.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the data.\n",
    "        window_size (int): The window size (e.g., 7 days).\n",
    "        target (str): The target column name (e.g., 'close_price_target').\n",
    "        features (list): List of feature column names (e.g., ['open', 'high', 'low', 'close']).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Input features (X).\n",
    "        np.ndarray: Target values (y).\n",
    "        np.ndarray: Dates associated with the targets.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    y_dates = []\n",
    "\n",
    "    for i in range(len(df) - window_size):\n",
    "        # Access the target column directly by its name\n",
    "        target_value = df.iloc[i + window_size][target]\n",
    "        y.append(target_value)\n",
    "        y_dates.append(df.iloc[i + window_size]['date'])\n",
    "        \n",
    "        # Prepare the features using the provided column names\n",
    "        X.append(df.iloc[i:i + window_size][features].values)\n",
    "\n",
    "    return np.array(X), np.array(y), np.array(y_dates)\n",
    "\n",
    "def segment_data(df, test_size=0.15):\n",
    "    \"\"\"\n",
    "    Segments the data into training and test sets based on the test size percentage.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to be segmented.\n",
    "        test_size (float): The percentage of data to be used for testing.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Training data.\n",
    "        pd.DataFrame: Testing data.\n",
    "    \"\"\"\n",
    "    test_len = int(len(df) * test_size)\n",
    "    train_data = df[:-test_len]  # 85% for training\n",
    "    test_data = df[-test_len:]   # 15% for testing\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def train_evaluate_model(trial, X_train, y_train, X_test, y_test, target, window_size, look_forward, model_type, study_name, model_dir):\n",
    "    \"\"\"\n",
    "    Trains and evaluates the model using Optuna for hyperparameter tuning.\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.Trial): The trial object for hyperparameter tuning.\n",
    "        X_train (np.ndarray): Training features.\n",
    "        y_train (np.ndarray): Training target.\n",
    "        X_test (np.ndarray): Test features.\n",
    "        y_test (np.ndarray): Test target.\n",
    "        target (str): The target column.\n",
    "        window_size (int): The window size for the model.\n",
    "        look_forward (int): The look-forward period for the prediction.\n",
    "        model_type (str): The type of model ('LSTM', 'GRU', etc.).\n",
    "        study_name (str): The study name for saving results.\n",
    "        model_dir (str): The directory to save model results.\n",
    "\n",
    "    Returns:\n",
    "        float: The error value (AUC or MSE).\n",
    "    \"\"\"\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    epochs = trial.suggest_int('epochs', 10, 20)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_float('dropout', 0.2, 0.5)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 3)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 64, 128)\n",
    "\n",
    "    if model_type == 'LSTM':\n",
    "        model = LSTMModel(input_size=X_train.shape[2], hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "    elif model_type == 'GRU':\n",
    "        model = GRUModel(input_size=X_train.shape[2], hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "    elif model_type == 'CNN-LSTM':\n",
    "        conv_filters = trial.suggest_int('conv_filters', 16, 64)\n",
    "        model = CNNLSTMModel(input_size=X_train.shape[2], hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, conv_filters=conv_filters)\n",
    "    else:\n",
    "        conv_filters = trial.suggest_int('conv_filters', 16, 64)\n",
    "        model = CNNGRUModel(input_size=X_train.shape[2], hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, conv_filters=conv_filters)\n",
    "\n",
    "    criterion = nn.MSELoss() if 'price' in target else nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test).squeeze().numpy()\n",
    "        if 'price' in target:\n",
    "            # MSE for regression\n",
    "            error = mean_squared_error(y_test.numpy(), predictions)\n",
    "        else:\n",
    "            # AUC for classification\n",
    "            predictions = (predictions > 0.5).astype(int)\n",
    "            error = roc_auc_score(y_test.numpy(), predictions)\n",
    "    \n",
    "    # Saving the model and results\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_name = f'{model_type}_{study_name}.pth'\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    joblib.dump(study.best_params, os.path.join(model_dir, f'{study_name}_params.pkl'))\n",
    "\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
