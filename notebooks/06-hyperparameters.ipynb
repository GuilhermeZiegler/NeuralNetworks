{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTAÇÕES NECESSÁRIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages: ['numpy', 'pandas', 'scikit-learn', 'joblib', 'pyarrow', 'fastparquet', 'plotly', 'matplotlib', 'MetaTrader5', 'tabulate', 'optuna', 'torch', 'tqdm']\n",
      "numpy is already installed.\n",
      "pandas is already installed.\n",
      "scikit-learn is already installed.\n",
      "joblib is already installed.\n",
      "pyarrow is already installed.\n",
      "fastparquet is already installed.\n",
      "plotly is already installed.\n",
      "matplotlib is already installed.\n",
      "MetaTrader5 is already installed.\n",
      "tabulate is already installed.\n",
      "optuna is already installed.\n",
      "torch is already installed.\n",
      "tqdm is already installed.\n",
      "All packages are verified.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../scripts'))\n",
    "\n",
    "from myFunctions import install_packages, save_table \n",
    "install_packages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing required packages\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL CLASSES DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Using the last output of the sequence\n",
    "        return out\n",
    "\n",
    "# GRU Model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        gru_out, hn = self.gru(x)\n",
    "        out = self.fc(gru_out[:, -1, :])  # Using the last output of the sequence\n",
    "        return out\n",
    "\n",
    "# CNN-LSTM Model\n",
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, conv_filters):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(input_size, conv_filters, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(conv_filters, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # For Conv1d, we need [batch, channels, seq_len]\n",
    "        x = self.conv1d(x)\n",
    "        x = x.permute(0, 2, 1)  # Returning to [batch, seq_len, channels]\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Using the last output of the sequence\n",
    "        return out\n",
    "\n",
    "# CNN-GRU Model\n",
    "class CNNGRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, conv_filters):\n",
    "        super(CNNGRUModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(input_size, conv_filters, kernel_size=3, padding=1)\n",
    "        self.gru = nn.GRU(conv_filters, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # For Conv1d, we need [batch, channels, seq_len]\n",
    "        x = self.conv1d(x)\n",
    "        x = x.permute(0, 2, 1)  # Returning to [batch, seq_len, channels]\n",
    "        gru_out, hn = self.gru(x)\n",
    "        out = self.fc(gru_out[:, -1, :])  # Using the last output of the sequence\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROCESSING DATA TO ARRAYS FOR WINDOWS SIZE AND LOOK FORWARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(df, exclude_columns=['date', 'day']):\n",
    "    \"\"\"\n",
    "    Escalona todas as colunas do DataFrame, exceto as especificadas em exclude_columns.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): O DataFrame contendo os dados.\n",
    "        exclude_columns (list): Lista de colunas que não serão escalonadas.\n",
    "\n",
    "    Returns:\n",
    "        df_scaled (pd.DataFrame): DataFrame com as colunas escalonadas.\n",
    "        scalers (dict): Dicionário contendo os escaladores para cada coluna escalonada.\n",
    "    \"\"\"\n",
    "    scalers = {}\n",
    "    columns_to_scale = [col for col in df.columns if col not in exclude_columns]\n",
    "    \n",
    "    df_scaled = df.copy()\n",
    "    for col in columns_to_scale:\n",
    "        scaler = MinMaxScaler()\n",
    "        df_scaled[col] = scaler.fit_transform(df[[col]])\n",
    "        scalers[col] = scaler\n",
    "    \n",
    "    return df_scaled, scalers\n",
    "\n",
    "\n",
    "def data_to_array(df, window_size, target, features):\n",
    "    \"\"\"\n",
    "    Prepares X and y with targets shifted for the next day after the window.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The dataframe containing the data.\n",
    "        window_size (int): The window size (e.g., 7 days).\n",
    "        target (str): The target column name (e.g., 'close_price_target').\n",
    "        features (list): List of feature column names (e.g., ['open', 'high', 'low', 'close']).\n",
    "\n",
    "    Returns:\n",
    "        X (np.ndarray): Input features.\n",
    "        y (np.ndarray): Target values.\n",
    "        y_dates (np.ndarray): Dates associated with the targets.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    y_dates = []\n",
    "\n",
    "    for i in range(len(df) - window_size):\n",
    "        # Access the target column directly by its name\n",
    "        target_value = df.iloc[i + window_size][target]\n",
    "        y.append(target_value)\n",
    "        y_dates.append(df.iloc[i + window_size]['date'])\n",
    "        \n",
    "        # Prepare the features using the provided column names\n",
    "        X.append(df.iloc[i:i + window_size][features].values)\n",
    "\n",
    "    return np.array(X), np.array(y), np.array(y_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLITING DATA TO TRAIN AND TEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_data(df, test_size=0.15):\n",
    "    \"\"\"\n",
    "    Segments the data into training and test sets based on the test size percentage.\n",
    "    \"\"\"\n",
    "    # Calculates the size of the test set\n",
    "    test_len = int(len(df) * test_size)\n",
    "    \n",
    "    # Segments the data\n",
    "    train_data = df[:-test_len]  # 85% for training\n",
    "    test_data = df[-test_len:]   # 15% for testing\n",
    "    \n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(trial, X_train, y_train, X_test, y_test, target, window_size, look_forward, model_type, study_name, model_dir):\n",
    "    \"\"\"\n",
    "    Train and evaluate the model based on the suggested hyperparameters.\n",
    "    \"\"\"\n",
    "    # Convert data to tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    # Hyperparameter suggestions\n",
    "    epochs = trial.suggest_int('epochs', 10, 20)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_float('dropout', 0.2, 0.5)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 3)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 16, 128)\n",
    "\n",
    "    if model_type in ['CNN-LSTM', 'CNN-GRU']:\n",
    "        conv_filters = trial.suggest_categorical('conv_filters', [32, 64, 128])\n",
    "\n",
    "    # Model selection\n",
    "    if model_type == 'LSTM':\n",
    "        model = LSTMModel(input_size=X_train.shape[2], hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "    elif model_type == 'GRU':\n",
    "        model = GRUModel(input_size=X_train.shape[2], hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "    elif model_type == 'CNN-LSTM':\n",
    "        model = CNNLSTMModel(input_size=X_train.shape[2], hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, conv_filters=conv_filters)\n",
    "    elif model_type == 'CNN-GRU':\n",
    "        model = CNNGRUModel(input_size=X_train.shape[2], hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, conv_filters=conv_filters)\n",
    "\n",
    "    # Optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss() if 'price' in target else nn.BCELoss()\n",
    "\n",
    "    # DataLoader for training\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    average_losses = {epoch: [] for epoch in range(epochs)}\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()  # Accumulate the loss\n",
    "\n",
    "        # Print loss for each epoch\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        for epoch in range(epochs):\n",
    "            average_losses[epoch].append(avg_loss)\n",
    "\n",
    "    # Evaluation on test data\n",
    "    model.eval()\n",
    "    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "    predictions = []\n",
    "    true_values = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            output = model(X_batch)\n",
    "            predictions.append(output.numpy())\n",
    "            true_values.append(y_batch.numpy())\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_values = np.concatenate(true_values, axis=0)\n",
    "\n",
    "    if 'price' in target:\n",
    "        error = mean_squared_error(true_values, predictions)\n",
    "    else:\n",
    "        predictions = (predictions > 0.5).astype(int)\n",
    "        error = -accuracy_score(true_values, predictions)\n",
    "\n",
    "    loss_decay_file = os.path.join(model_dir, f\"{study_name}_loss_decay.pkl\")\n",
    "    with open(loss_decay_file, 'wb') as f:\n",
    "        joblib.dump(average_losses, f)\n",
    "\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_models(df, targets, target_type, features, windows, look_forwards, max_samples=100):\n",
    "    \"\"\"\n",
    "    Optimizes models using Optuna for hyperparameter tuning. Now prepares the data within the function.\n",
    "    \"\"\"\n",
    "    study_results = {}\n",
    "    input_dir = os.path.join('..', 'data', 'models', target_type).replace(\"/\", \"\\\\\")  \n",
    "    if not os.path.exists(input_dir):\n",
    "        os.makedirs(input_dir)\n",
    "    \n",
    "    exclude_columns = ['date', 'day']\n",
    "    df_scaled, _ = scale_features(df, exclude_columns)\n",
    "    df_scaled, scalers = scale_features(df)\n",
    "    train_data, test_data = segment_data(df_scaled, test_size=0.15)\n",
    "    \n",
    "    for window_size in windows:\n",
    "        for look_forward in look_forwards:\n",
    "            for target in targets:\n",
    "                X_train, y_train, y_dates = data_to_array(train_data.copy(), \n",
    "                                                          window_size,\n",
    "                                                          target, \n",
    "                                                          features)\n",
    "\n",
    "                X_test, y_test, _ = data_to_array(test_data.copy(), \n",
    "                                                  window_size, \n",
    "                                                  target, \n",
    "                                                  features)\n",
    "\n",
    "                model_names = ['LSTM', 'GRU', 'CNN-LSTM', 'CNN-GRU']\n",
    "                for model_type in tqdm(model_names):\n",
    "                    study_name = f\"{model_type}_window_{window_size}_look_forward_{look_forward}_{target}\"\n",
    "                    model_dir = os.path.join(input_dir, study_name).replace(\"/\", \"\\\\\")\n",
    "                    \n",
    "                    if not os.path.exists(model_dir):\n",
    "                        os.makedirs(model_dir)\n",
    "                    \n",
    "                    # Creating the Optuna study\n",
    "                    study = optuna.create_study(direction='minimize', study_name=study_name)\n",
    "                    study.optimize(\n",
    "                        lambda trial: train_evaluate_model(\n",
    "                            trial, X_train, y_train, X_test, y_test, target, window_size, look_forward, model_type, study_name, model_dir\n",
    "                        ),\n",
    "                        n_trials=max_samples\n",
    "                    )\n",
    "\n",
    "                    study_file = os.path.join(model_dir, f\"{study_name}_study.pkl\").replace(\"/\", \"\\\\\")\n",
    "                    joblib.dump(study, study_file)\n",
    "                    print(f'{study_name} saved to {study_file}')\n",
    "\n",
    "\n",
    "                    best_params = study.best_params\n",
    "                    best_trial_index = study.best_trial.number \n",
    "                    best_trial_value = study.best_value  \n",
    "\n",
    "                    best_params_dict = {\n",
    "                        'best_params': best_params,\n",
    "                        'best_trial_index': best_trial_index,\n",
    "                        'best_trial_value': best_trial_value\n",
    "                    }\n",
    "                    params_file = os.path.join(model_dir, f\"{study_name}_best_params.pkl\").replace(\"/\", \"\\\\\")\n",
    "                    with open(params_file, \"wb\") as f:\n",
    "                        joblib.dump(best_params_dict, f)\n",
    "\n",
    "                    try:\n",
    "                        fig_optimization = vis.plot_optimization_history(study)\n",
    "                        fig_optimization.write_image(os.path.join(model_dir, f\"{study_name}_optimization_history.png\"))\n",
    "\n",
    "                        fig_importances = vis.plot_param_importances(study)\n",
    "                        fig_importances.write_image(os.path.join(model_dir, f\"{study_name}_param_importances.png\"))\n",
    "\n",
    "                        fig_slice = vis.plot_slice(study)\n",
    "                        fig_slice.write_image(os.path.join(model_dir, f\"{study_name}_slice_plot.png\"))\n",
    "\n",
    "                        print(f\"Images saved to {model_dir}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in plotting images for {study_name}: {e}\")\n",
    "\n",
    "\n",
    "                    print(f\"Saved to {model_dir}:\")\n",
    "                    print(f\"Best hyperparameters for {model_type}, window size: {window_size}, look forward: {look_forward}, target {target}: {best_params}\")\n",
    "                    print(f\"Best trial index: {best_trial_index}, Best trial value: {best_trial_value}\")\n",
    "\n",
    "                    study_results[study_name] = {\n",
    "                        \"study\": study,\n",
    "                        \"best_params\": best_params,\n",
    "                        \"best_trial_index\": best_trial_index,\n",
    "                        \"best_trial_value\": best_trial_value,\n",
    "                        \"directory\": model_dir\n",
    "                    }\n",
    "\n",
    "    return study_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s][I 2024-12-21 13:44:22,788] A new study created in memory with name: LSTM_window_7_look_forward_1_close_price_target\n",
      "[I 2024-12-21 13:44:37,950] Trial 0 finished with value: 0.07875198125839233 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 2.5069623247826513e-05, 'dropout': 0.4629577156784078, 'num_layers': 3, 'hidden_size': 48}. Best is trial 0 with value: 0.07875198125839233.\n",
      "[I 2024-12-21 13:44:57,559] Trial 1 finished with value: 0.07919950783252716 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 1.7722795463645685e-05, 'dropout': 0.4528624730382779, 'num_layers': 3, 'hidden_size': 90}. Best is trial 0 with value: 0.07875198125839233.\n",
      "[I 2024-12-21 13:45:07,187] Trial 2 finished with value: 0.06899137049913406 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.00010473126125547903, 'dropout': 0.22075493423979614, 'num_layers': 2, 'hidden_size': 29}. Best is trial 2 with value: 0.06899137049913406.\n",
      "[I 2024-12-21 13:45:16,678] Trial 3 finished with value: 0.11336087435483932 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 0.0009475445910215768, 'dropout': 0.3128945788688829, 'num_layers': 2, 'hidden_size': 41}. Best is trial 2 with value: 0.06899137049913406.\n",
      "[I 2024-12-21 13:45:22,133] Trial 4 finished with value: 0.07230167835950851 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 2.3670233941823787e-05, 'dropout': 0.4807601500612229, 'num_layers': 2, 'hidden_size': 18}. Best is trial 2 with value: 0.06899137049913406.\n",
      "[I 2024-12-21 13:45:41,179] Trial 5 finished with value: 0.08723299205303192 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 1.7767039476621077e-05, 'dropout': 0.3786765878456473, 'num_layers': 3, 'hidden_size': 106}. Best is trial 2 with value: 0.06899137049913406.\n",
      "[I 2024-12-21 13:46:00,862] Trial 6 finished with value: 0.08371174335479736 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 0.00016790987308463329, 'dropout': 0.49570039467988203, 'num_layers': 2, 'hidden_size': 90}. Best is trial 2 with value: 0.06899137049913406.\n",
      "[I 2024-12-21 13:46:26,410] Trial 7 finished with value: 0.08917313069105148 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.000510031244474923, 'dropout': 0.247377421661792, 'num_layers': 3, 'hidden_size': 101}. Best is trial 2 with value: 0.06899137049913406.\n",
      "[I 2024-12-21 13:46:42,787] Trial 8 finished with value: 0.10454539209604263 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 0.0002759565026738579, 'dropout': 0.4692391230726517, 'num_layers': 2, 'hidden_size': 61}. Best is trial 2 with value: 0.06899137049913406.\n",
      "[I 2024-12-21 13:50:35,785] Trial 9 finished with value: 0.07332300394773483 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 0.004259955507251036, 'dropout': 0.40217861687504497, 'num_layers': 3, 'hidden_size': 98}. Best is trial 2 with value: 0.06899137049913406.\n",
      "[I 2024-12-21 13:50:40,833] Trial 10 finished with value: 0.09749224036931992 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 9.92069739637248e-05, 'dropout': 0.21629465051938426, 'num_layers': 2, 'hidden_size': 23}. Best is trial 2 with value: 0.06899137049913406.\n",
      "[I 2024-12-21 13:50:47,284] Trial 11 finished with value: 0.06620997935533524 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 6.730898177947778e-05, 'dropout': 0.30984600967206444, 'num_layers': 2, 'hidden_size': 16}. Best is trial 11 with value: 0.06620997935533524.\n",
      "[I 2024-12-21 13:50:59,741] Trial 12 finished with value: 0.0814334824681282 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 7.188869571232072e-05, 'dropout': 0.28487094790759937, 'num_layers': 2, 'hidden_size': 33}. Best is trial 11 with value: 0.06620997935533524.\n",
      "[I 2024-12-21 13:51:37,837] Trial 13 finished with value: 0.0566304512321949 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 5.854826065757415e-05, 'dropout': 0.20567953248263088, 'num_layers': 2, 'hidden_size': 123}. Best is trial 13 with value: 0.0566304512321949.\n",
      "[I 2024-12-21 13:52:19,114] Trial 14 finished with value: 0.08479294925928116 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 5.319442525016474e-05, 'dropout': 0.31369044056857204, 'num_layers': 2, 'hidden_size': 128}. Best is trial 13 with value: 0.0566304512321949.\n",
      "[I 2024-12-21 13:52:41,682] Trial 15 finished with value: 0.14147134125232697 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 0.0009773338183496135, 'dropout': 0.26726606018967963, 'num_layers': 2, 'hidden_size': 127}. Best is trial 13 with value: 0.0566304512321949.\n",
      "[I 2024-12-21 13:53:03,985] Trial 16 finished with value: 0.055130697786808014 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 4.166776087254742e-05, 'dropout': 0.343733949340302, 'num_layers': 2, 'hidden_size': 68}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:54:03,023] Trial 17 finished with value: 0.07194936275482178 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.008566334951744806, 'dropout': 0.4131076694097845, 'num_layers': 2, 'hidden_size': 73}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:54:24,610] Trial 18 finished with value: 0.06758026778697968 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 4.443271016397777e-05, 'dropout': 0.36235154520347723, 'num_layers': 2, 'hidden_size': 67}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:54:39,507] Trial 19 finished with value: 0.0740731731057167 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 1.0650105279008021e-05, 'dropout': 0.34076208340654557, 'num_layers': 2, 'hidden_size': 79}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:55:16,482] Trial 20 finished with value: 0.0972583219408989 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.00023828312906640169, 'dropout': 0.25211376739662383, 'num_layers': 3, 'hidden_size': 114}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:55:34,426] Trial 21 finished with value: 0.08983799815177917 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 4.04396202071413e-05, 'dropout': 0.3307692333691692, 'num_layers': 2, 'hidden_size': 54}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:56:03,233] Trial 22 finished with value: 0.07867561280727386 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.00013407701938984484, 'dropout': 0.30168579110000293, 'num_layers': 2, 'hidden_size': 81}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:56:18,683] Trial 23 finished with value: 0.063214011490345 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 4.114571300760986e-05, 'dropout': 0.38262206316336345, 'num_layers': 2, 'hidden_size': 43}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:56:42,261] Trial 24 finished with value: 0.10591615736484528 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 1.1242657203182273e-05, 'dropout': 0.4194955324935108, 'num_layers': 2, 'hidden_size': 57}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:56:57,216] Trial 25 finished with value: 0.08298047631978989 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 2.867423688800298e-05, 'dropout': 0.3871242264914444, 'num_layers': 2, 'hidden_size': 47}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:57:17,412] Trial 26 finished with value: 0.0704541951417923 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 3.697040527521919e-05, 'dropout': 0.4393602166747858, 'num_layers': 2, 'hidden_size': 40}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:57:36,849] Trial 27 finished with value: 0.09065770357847214 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.0005019317628736678, 'dropout': 0.36735640631396654, 'num_layers': 2, 'hidden_size': 68}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:58:13,797] Trial 28 finished with value: 0.07245871424674988 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 7.691346468379946e-05, 'dropout': 0.34631363425237294, 'num_layers': 2, 'hidden_size': 118}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:58:28,034] Trial 29 finished with value: 0.10106857120990753 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 0.00016267812450057484, 'dropout': 0.4276597279568458, 'num_layers': 3, 'hidden_size': 44}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:58:38,331] Trial 30 finished with value: 0.14690078794956207 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 2.093654252717543e-05, 'dropout': 0.20001762806220127, 'num_layers': 2, 'hidden_size': 51}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:58:52,432] Trial 31 finished with value: 0.0795520469546318 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 6.236456764420833e-05, 'dropout': 0.3896175632388989, 'num_layers': 2, 'hidden_size': 33}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 13:59:27,627] Trial 32 finished with value: 0.06383387744426727 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 3.1909954658723806e-05, 'dropout': 0.28518197790767985, 'num_layers': 2, 'hidden_size': 88}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:00:05,233] Trial 33 finished with value: 0.08014623820781708 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 3.3333862696693766e-05, 'dropout': 0.2831399436624917, 'num_layers': 2, 'hidden_size': 91}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:00:28,888] Trial 34 finished with value: 0.08218082040548325 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 1.4902469125543454e-05, 'dropout': 0.24211789203945905, 'num_layers': 2, 'hidden_size': 83}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:00:48,840] Trial 35 finished with value: 0.08140313625335693 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 2.5944854198672286e-05, 'dropout': 0.32658690065250207, 'num_layers': 2, 'hidden_size': 119}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:01:05,316] Trial 36 finished with value: 0.0765925869345665 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 1.60506408866701e-05, 'dropout': 0.22650031184246627, 'num_layers': 2, 'hidden_size': 64}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:01:29,353] Trial 37 finished with value: 0.08401941508054733 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.00010222866023413116, 'dropout': 0.3618355516303993, 'num_layers': 3, 'hidden_size': 108}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:01:50,268] Trial 38 finished with value: 0.07725955545902252 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 4.640070689848103e-05, 'dropout': 0.28723956446299215, 'num_layers': 2, 'hidden_size': 91}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:02:12,231] Trial 39 finished with value: 0.07297772169113159 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 2.124348285625848e-05, 'dropout': 0.2694558773175147, 'num_layers': 2, 'hidden_size': 76}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:02:40,793] Trial 40 finished with value: 0.09716368466615677 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 0.0012242814380419402, 'dropout': 0.3761173065806084, 'num_layers': 2, 'hidden_size': 85}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:02:46,223] Trial 41 finished with value: 0.0862063392996788 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 6.57311133312109e-05, 'dropout': 0.3095408830371246, 'num_layers': 2, 'hidden_size': 16}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:03:11,316] Trial 42 finished with value: 0.06773032993078232 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.00012082035915095207, 'dropout': 0.3228705123944916, 'num_layers': 2, 'hidden_size': 37}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:03:19,696] Trial 43 finished with value: 0.10029492527246475 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 3.10662177701802e-05, 'dropout': 0.351786566187832, 'num_layers': 2, 'hidden_size': 24}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:03:30,668] Trial 44 finished with value: 0.08691497147083282 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 8.510957455194557e-05, 'dropout': 0.30297878717065174, 'num_layers': 2, 'hidden_size': 28}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:03:56,539] Trial 45 finished with value: 0.0928564965724945 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.00017129644868812578, 'dropout': 0.23048665749710953, 'num_layers': 2, 'hidden_size': 96}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:04:18,370] Trial 46 finished with value: 0.0964764803647995 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 5.857946000851486e-05, 'dropout': 0.26688288930674187, 'num_layers': 2, 'hidden_size': 56}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:04:42,130] Trial 47 finished with value: 0.0710940808057785 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.00022737595954101, 'dropout': 0.2936876542720759, 'num_layers': 2, 'hidden_size': 105}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:04:54,840] Trial 48 finished with value: 0.09762591868638992 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 1.5430783020525822e-05, 'dropout': 0.3354711875294724, 'num_layers': 3, 'hidden_size': 60}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:05:20,142] Trial 49 finished with value: 0.08718837797641754 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 4.917593255353716e-05, 'dropout': 0.20923437296981354, 'num_layers': 2, 'hidden_size': 70}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:05:24,847] Trial 50 finished with value: 0.08609035611152649 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 0.00046527595503975504, 'dropout': 0.3540271816694761, 'num_layers': 2, 'hidden_size': 21}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:05:37,776] Trial 51 finished with value: 0.07498431950807571 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 4.2738862098090496e-05, 'dropout': 0.40205922562603696, 'num_layers': 2, 'hidden_size': 66}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:05:53,051] Trial 52 finished with value: 0.08284255862236023 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 2.477420024545901e-05, 'dropout': 0.3659962047954051, 'num_layers': 2, 'hidden_size': 74}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:06:08,409] Trial 53 finished with value: 0.079463891685009 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 3.743423509345429e-05, 'dropout': 0.37924950791624545, 'num_layers': 2, 'hidden_size': 48}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:06:20,386] Trial 54 finished with value: 0.07293262332677841 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 8.548089980541872e-05, 'dropout': 0.3161680969812832, 'num_layers': 2, 'hidden_size': 63}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:06:35,750] Trial 55 finished with value: 0.07549083232879639 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 5.34720698169246e-05, 'dropout': 0.40094652300224143, 'num_layers': 2, 'hidden_size': 87}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:08:22,751] Trial 56 finished with value: 0.10641104727983475 and parameters: {'epochs': 12, 'batch_size': 64, 'learning_rate': 0.0024514815113207632, 'dropout': 0.3432130942536186, 'num_layers': 2, 'hidden_size': 78}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:08:31,739] Trial 57 finished with value: 0.08085592091083527 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 1.2124594444587678e-05, 'dropout': 0.2747478162186531, 'num_layers': 2, 'hidden_size': 37}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:08:49,467] Trial 58 finished with value: 0.09566096216440201 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 1.9870468596408077e-05, 'dropout': 0.35818528630448465, 'num_layers': 2, 'hidden_size': 95}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:09:18,955] Trial 59 finished with value: 0.07300327718257904 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 2.9805358429967093e-05, 'dropout': 0.2460065349214987, 'num_layers': 2, 'hidden_size': 111}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:09:54,775] Trial 60 finished with value: 0.07808683812618256 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.0001261734935383997, 'dropout': 0.2597475159458611, 'num_layers': 2, 'hidden_size': 124}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:10:03,664] Trial 61 finished with value: 0.09619172662496567 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.00011673004836959217, 'dropout': 0.32227494749484237, 'num_layers': 2, 'hidden_size': 29}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:10:15,272] Trial 62 finished with value: 0.08281814306974411 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 7.230067878429603e-05, 'dropout': 0.33675164781100175, 'num_layers': 2, 'hidden_size': 36}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:10:29,799] Trial 63 finished with value: 0.07767252624034882 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.0001606386433284229, 'dropout': 0.32187601547650324, 'num_layers': 2, 'hidden_size': 51}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:10:45,451] Trial 64 finished with value: 0.08398747444152832 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.0003358558582887715, 'dropout': 0.29976946585232134, 'num_layers': 2, 'hidden_size': 59}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:11:03,508] Trial 65 finished with value: 0.07345592230558395 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 9.262428989067134e-05, 'dropout': 0.3904755120286231, 'num_layers': 2, 'hidden_size': 41}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:11:11,743] Trial 66 finished with value: 0.10465385764837265 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 4.101369431644656e-05, 'dropout': 0.3730631073871201, 'num_layers': 2, 'hidden_size': 24}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:11:39,134] Trial 67 finished with value: 0.08138943463563919 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 5.464153218626389e-05, 'dropout': 0.347625406543576, 'num_layers': 2, 'hidden_size': 101}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:11:53,776] Trial 68 finished with value: 0.09337975084781647 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 3.55952087717972e-05, 'dropout': 0.3109342213084591, 'num_layers': 2, 'hidden_size': 46}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:12:10,779] Trial 69 finished with value: 0.058272235095500946 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 6.747682358272599e-05, 'dropout': 0.3266515517151131, 'num_layers': 3, 'hidden_size': 69}. Best is trial 16 with value: 0.055130697786808014.\n",
      "[I 2024-12-21 14:12:25,301] Trial 70 finished with value: 0.04525243118405342 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 6.504926282417684e-05, 'dropout': 0.46184568837879203, 'num_layers': 3, 'hidden_size': 68}. Best is trial 70 with value: 0.04525243118405342.\n",
      "[I 2024-12-21 14:12:38,496] Trial 71 finished with value: 0.0693022608757019 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 6.984545702567073e-05, 'dropout': 0.45270575624465986, 'num_layers': 3, 'hidden_size': 70}. Best is trial 70 with value: 0.04525243118405342.\n",
      "[I 2024-12-21 14:13:04,671] Trial 72 finished with value: 0.06643112003803253 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 2.4912534993727194e-05, 'dropout': 0.4620198900915333, 'num_layers': 3, 'hidden_size': 66}. Best is trial 70 with value: 0.04525243118405342.\n",
      "[I 2024-12-21 14:13:18,941] Trial 73 finished with value: 0.10968617349863052 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 2.8527087137686288e-05, 'dropout': 0.495983913240738, 'num_layers': 3, 'hidden_size': 72}. Best is trial 70 with value: 0.04525243118405342.\n",
      "[I 2024-12-21 14:13:40,322] Trial 74 finished with value: 0.09908376634120941 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 1.8231041723921205e-05, 'dropout': 0.48449104645098356, 'num_layers': 3, 'hidden_size': 63}. Best is trial 70 with value: 0.04525243118405342.\n",
      "[I 2024-12-21 14:14:07,343] Trial 75 finished with value: 0.07065561413764954 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 2.395148978478422e-05, 'dropout': 0.4656833901438022, 'num_layers': 3, 'hidden_size': 79}. Best is trial 70 with value: 0.04525243118405342.\n",
      "[I 2024-12-21 14:14:43,703] Trial 76 finished with value: 0.061362311244010925 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 4.5714960189885064e-05, 'dropout': 0.4496505236301538, 'num_layers': 3, 'hidden_size': 53}. Best is trial 70 with value: 0.04525243118405342.\n",
      "[I 2024-12-21 14:15:00,570] Trial 77 finished with value: 0.09399048238992691 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 4.7933710688219446e-05, 'dropout': 0.43580218255806785, 'num_layers': 3, 'hidden_size': 54}. Best is trial 70 with value: 0.04525243118405342.\n",
      "[I 2024-12-21 14:15:13,998] Trial 78 finished with value: 0.0647096261382103 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 5.812471712477562e-05, 'dropout': 0.4508689481996997, 'num_layers': 3, 'hidden_size': 52}. Best is trial 70 with value: 0.04525243118405342.\n",
      "[I 2024-12-21 14:15:25,605] Trial 79 finished with value: 0.08127700537443161 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 3.35455080148029e-05, 'dropout': 0.48769321601976545, 'num_layers': 3, 'hidden_size': 51}. Best is trial 70 with value: 0.04525243118405342.\n",
      "[I 2024-12-21 14:15:36,331] Trial 80 finished with value: 0.044933706521987915 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 8.122193038809427e-05, 'dropout': 0.4405032809638877, 'num_layers': 3, 'hidden_size': 44}. Best is trial 80 with value: 0.044933706521987915.\n",
      "[I 2024-12-21 14:15:56,555] Trial 81 finished with value: 0.07875313609838486 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 5.7978013401626474e-05, 'dropout': 0.4523601426516093, 'num_layers': 3, 'hidden_size': 54}. Best is trial 80 with value: 0.044933706521987915.\n",
      "[I 2024-12-21 14:16:08,214] Trial 82 finished with value: 0.05309368297457695 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.00010459949651507247, 'dropout': 0.4735516349853195, 'num_layers': 3, 'hidden_size': 43}. Best is trial 80 with value: 0.044933706521987915.\n",
      "[I 2024-12-21 14:16:23,277] Trial 83 finished with value: 0.07650510221719742 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 8.353257697434921e-05, 'dropout': 0.47774654344620454, 'num_layers': 3, 'hidden_size': 42}. Best is trial 80 with value: 0.044933706521987915.\n",
      "[I 2024-12-21 14:16:53,642] Trial 84 finished with value: 0.07815223187208176 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 9.923446929230997e-05, 'dropout': 0.44105712790767493, 'num_layers': 3, 'hidden_size': 57}. Best is trial 80 with value: 0.044933706521987915.\n",
      "[I 2024-12-21 14:17:08,870] Trial 85 finished with value: 0.07377529889345169 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 4.5282627312576075e-05, 'dropout': 0.4192810463141411, 'num_layers': 3, 'hidden_size': 44}. Best is trial 80 with value: 0.044933706521987915.\n",
      "[I 2024-12-21 14:17:16,461] Trial 86 finished with value: 0.06475351750850677 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 7.043755051849951e-05, 'dropout': 0.4667289653378465, 'num_layers': 3, 'hidden_size': 32}. Best is trial 80 with value: 0.044933706521987915.\n",
      "[I 2024-12-21 14:17:30,077] Trial 87 finished with value: 0.0800912156701088 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.0001416239429421902, 'dropout': 0.4440267412020952, 'num_layers': 3, 'hidden_size': 45}. Best is trial 80 with value: 0.044933706521987915.\n",
      "[I 2024-12-21 14:17:49,579] Trial 88 finished with value: 0.043682295829057693 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 4.194763340764618e-05, 'dropout': 0.4792148808905295, 'num_layers': 3, 'hidden_size': 76}. Best is trial 88 with value: 0.043682295829057693.\n",
      "[I 2024-12-21 14:18:07,412] Trial 89 finished with value: 0.08828087151050568 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.00022370961087556877, 'dropout': 0.4745958452043955, 'num_layers': 3, 'hidden_size': 61}. Best is trial 88 with value: 0.043682295829057693.\n",
      "[I 2024-12-21 14:18:28,044] Trial 90 finished with value: 0.06139262393116951 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.00010633839559597164, 'dropout': 0.43289140510249485, 'num_layers': 3, 'hidden_size': 69}. Best is trial 88 with value: 0.043682295829057693.\n",
      "[I 2024-12-21 14:18:43,128] Trial 91 finished with value: 0.07890539616346359 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.00010288739531014035, 'dropout': 0.4263114982642198, 'num_layers': 3, 'hidden_size': 70}. Best is trial 88 with value: 0.043682295829057693.\n",
      "[I 2024-12-21 14:19:04,032] Trial 92 finished with value: 0.05643918737769127 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 8.141578467861254e-05, 'dropout': 0.4320400236122094, 'num_layers': 3, 'hidden_size': 75}. Best is trial 88 with value: 0.043682295829057693.\n",
      "[I 2024-12-21 14:19:23,136] Trial 93 finished with value: 0.09007135778665543 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 7.988363229194621e-05, 'dropout': 0.4594200980539163, 'num_layers': 3, 'hidden_size': 81}. Best is trial 88 with value: 0.043682295829057693.\n",
      "[I 2024-12-21 14:19:37,908] Trial 94 finished with value: 0.058895714581012726 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 6.622701311390758e-05, 'dropout': 0.4728145513059452, 'num_layers': 3, 'hidden_size': 76}. Best is trial 88 with value: 0.043682295829057693.\n",
      "[I 2024-12-21 14:19:53,746] Trial 95 finished with value: 0.08678621798753738 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.00018582398010736059, 'dropout': 0.47227157514745655, 'num_layers': 3, 'hidden_size': 73}. Best is trial 88 with value: 0.043682295829057693.\n",
      "[I 2024-12-21 14:20:15,444] Trial 96 finished with value: 0.07841412723064423 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 6.439435498787779e-05, 'dropout': 0.48342507901563087, 'num_layers': 3, 'hidden_size': 76}. Best is trial 88 with value: 0.043682295829057693.\n",
      "[I 2024-12-21 14:20:31,897] Trial 97 finished with value: 0.061914749443531036 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 4.9632054644762993e-05, 'dropout': 0.4911757256331588, 'num_layers': 3, 'hidden_size': 85}. Best is trial 88 with value: 0.043682295829057693.\n",
      "[I 2024-12-21 14:20:44,578] Trial 98 finished with value: 0.07000280171632767 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 3.7550309441246625e-05, 'dropout': 0.49865010869783283, 'num_layers': 3, 'hidden_size': 65}. Best is trial 88 with value: 0.043682295829057693.\n",
      "[I 2024-12-21 14:21:13,707] Trial 99 finished with value: 0.10099874436855316 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.00014365067960498177, 'dropout': 0.4589510459094522, 'num_layers': 3, 'hidden_size': 82}. Best is trial 88 with value: 0.043682295829057693.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_window_7_look_forward_1_close_price_target saved to ..\\data\\models\\LSTM_window_7_look_forward_1_close_price_target\\LSTM_window_7_look_forward_1_close_price_target_study.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [37:00<1:51:02, 2220.89s/it][I 2024-12-21 14:21:23,683] A new study created in memory with name: GRU_window_7_look_forward_1_close_price_target\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved to ..\\data\\models\\LSTM_window_7_look_forward_1_close_price_target\n",
      "Saved to ..\\data\\models\\LSTM_window_7_look_forward_1_close_price_target:\n",
      "Best hyperparameters for LSTM, window size: 7, look forward: 1, target close_price_target: {'epochs': 18, 'batch_size': 32, 'learning_rate': 4.194763340764618e-05, 'dropout': 0.4792148808905295, 'num_layers': 3, 'hidden_size': 76}\n",
      "Best trial index: 88, Best trial value: 0.043682295829057693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 14:21:35,443] Trial 0 finished with value: 0.08163440227508545 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 0.00013195123243419195, 'dropout': 0.4647796922968444, 'num_layers': 2, 'hidden_size': 81}. Best is trial 0 with value: 0.08163440227508545.\n",
      "[I 2024-12-21 14:21:42,349] Trial 1 finished with value: 0.09828151762485504 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 0.0016721499924803969, 'dropout': 0.32772823620797653, 'num_layers': 2, 'hidden_size': 127}. Best is trial 0 with value: 0.08163440227508545.\n",
      "[I 2024-12-21 14:21:57,781] Trial 2 finished with value: 0.1279335916042328 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.00033463700941438056, 'dropout': 0.38535348346283776, 'num_layers': 3, 'hidden_size': 89}. Best is trial 0 with value: 0.08163440227508545.\n",
      "[I 2024-12-21 14:22:01,134] Trial 3 finished with value: 0.09155957400798798 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 2.899530430901127e-05, 'dropout': 0.4287083581425753, 'num_layers': 2, 'hidden_size': 42}. Best is trial 0 with value: 0.08163440227508545.\n",
      "[I 2024-12-21 14:22:10,094] Trial 4 finished with value: 0.13132672011852264 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.820326596906717e-05, 'dropout': 0.20199504607202343, 'num_layers': 2, 'hidden_size': 65}. Best is trial 0 with value: 0.08163440227508545.\n",
      "[I 2024-12-21 14:22:16,205] Trial 5 finished with value: 0.09933838993310928 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 0.00014724038571211118, 'dropout': 0.29781197695861095, 'num_layers': 2, 'hidden_size': 32}. Best is trial 0 with value: 0.08163440227508545.\n",
      "[I 2024-12-21 14:22:20,681] Trial 6 finished with value: 0.05601045861840248 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 0.00010637491646711091, 'dropout': 0.2627472811945472, 'num_layers': 2, 'hidden_size': 39}. Best is trial 6 with value: 0.05601045861840248.\n",
      "[I 2024-12-21 14:22:24,700] Trial 7 finished with value: 0.06777660548686981 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 3.563899831474057e-05, 'dropout': 0.36094567819509915, 'num_layers': 3, 'hidden_size': 30}. Best is trial 6 with value: 0.05601045861840248.\n",
      "[I 2024-12-21 14:22:28,132] Trial 8 finished with value: 0.10599713772535324 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 0.0014786713532028257, 'dropout': 0.27196342335469714, 'num_layers': 2, 'hidden_size': 39}. Best is trial 6 with value: 0.05601045861840248.\n",
      "[I 2024-12-21 14:22:36,386] Trial 9 finished with value: 0.11458340287208557 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 8.381670632968345e-05, 'dropout': 0.25448937498385676, 'num_layers': 2, 'hidden_size': 103}. Best is trial 6 with value: 0.05601045861840248.\n",
      "[I 2024-12-21 14:22:49,212] Trial 10 finished with value: 0.0745607540011406 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 0.009916857974372044, 'dropout': 0.21363066344300052, 'num_layers': 3, 'hidden_size': 59}. Best is trial 6 with value: 0.05601045861840248.\n",
      "[I 2024-12-21 14:22:53,321] Trial 11 finished with value: 0.3233143091201782 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 1.2166854735233237e-05, 'dropout': 0.3706703630141249, 'num_layers': 3, 'hidden_size': 18}. Best is trial 6 with value: 0.05601045861840248.\n",
      "[I 2024-12-21 14:22:57,909] Trial 12 finished with value: 0.09788797050714493 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 4.7187594775078764e-05, 'dropout': 0.3415982341706636, 'num_layers': 3, 'hidden_size': 18}. Best is trial 6 with value: 0.05601045861840248.\n",
      "[I 2024-12-21 14:23:15,409] Trial 13 finished with value: 0.07524513453245163 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.00038268937710461844, 'dropout': 0.407052463195731, 'num_layers': 3, 'hidden_size': 53}. Best is trial 6 with value: 0.05601045861840248.\n",
      "[I 2024-12-21 14:23:20,825] Trial 14 finished with value: 0.08278445154428482 and parameters: {'epochs': 12, 'batch_size': 64, 'learning_rate': 4.6766943335794725e-05, 'dropout': 0.29603490425121204, 'num_layers': 3, 'hidden_size': 32}. Best is trial 6 with value: 0.05601045861840248.\n",
      "[I 2024-12-21 14:23:29,164] Trial 15 finished with value: 0.11918056756258011 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 0.0009173221456158909, 'dropout': 0.24321570463144315, 'num_layers': 3, 'hidden_size': 50}. Best is trial 6 with value: 0.05601045861840248.\n",
      "[I 2024-12-21 14:23:32,345] Trial 16 finished with value: 0.06858855485916138 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 8.271582767312066e-05, 'dropout': 0.3187433465413227, 'num_layers': 2, 'hidden_size': 25}. Best is trial 6 with value: 0.05601045861840248.\n",
      "[I 2024-12-21 14:23:40,571] Trial 17 finished with value: 0.050538212060928345 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 1.0281306623614688e-05, 'dropout': 0.4927245807295241, 'num_layers': 3, 'hidden_size': 72}. Best is trial 17 with value: 0.050538212060928345.\n",
      "[I 2024-12-21 14:23:54,841] Trial 18 finished with value: 0.034170981496572495 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.208096963507205e-05, 'dropout': 0.46235620086732465, 'num_layers': 2, 'hidden_size': 75}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:24:17,873] Trial 19 finished with value: 0.0772908478975296 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.0142508617567499e-05, 'dropout': 0.49708894558374095, 'num_layers': 3, 'hidden_size': 75}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:24:33,058] Trial 20 finished with value: 0.07780318707227707 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 1.8874847931608736e-05, 'dropout': 0.4966583380741924, 'num_layers': 2, 'hidden_size': 93}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:24:44,182] Trial 21 finished with value: 0.05294901132583618 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.010578124058223e-05, 'dropout': 0.4569763391682417, 'num_layers': 2, 'hidden_size': 105}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:25:00,229] Trial 22 finished with value: 0.08850055932998657 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.9754502710892205e-05, 'dropout': 0.457362389190402, 'num_layers': 2, 'hidden_size': 109}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:25:17,313] Trial 23 finished with value: 0.07231289148330688 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.3959923566843743e-05, 'dropout': 0.45207179257711827, 'num_layers': 2, 'hidden_size': 116}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:25:29,569] Trial 24 finished with value: 0.11818047612905502 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 2.488923328041643e-05, 'dropout': 0.433248321236503, 'num_layers': 2, 'hidden_size': 71}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:25:42,786] Trial 25 finished with value: 0.1838190108537674 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 0.007916301946289558, 'dropout': 0.4768459037850281, 'num_layers': 2, 'hidden_size': 93}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:26:05,866] Trial 26 finished with value: 0.05687835440039635 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 1.0361909253955727e-05, 'dropout': 0.4180927329330662, 'num_layers': 3, 'hidden_size': 84}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:26:21,441] Trial 27 finished with value: 0.03795555979013443 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 5.626137823810163e-05, 'dropout': 0.3967190690832578, 'num_layers': 2, 'hidden_size': 105}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:26:34,400] Trial 28 finished with value: 0.1037687286734581 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 4.8017251283366014e-05, 'dropout': 0.3814817572512226, 'num_layers': 3, 'hidden_size': 69}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:26:45,862] Trial 29 finished with value: 0.09864260256290436 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 0.00018099624467219846, 'dropout': 0.4028840838238002, 'num_layers': 2, 'hidden_size': 77}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:27:11,082] Trial 30 finished with value: 0.06871254742145538 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 5.502271362760411e-05, 'dropout': 0.47588211389268464, 'num_layers': 2, 'hidden_size': 85}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:27:29,427] Trial 31 finished with value: 0.04155552759766579 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.6318719208562035e-05, 'dropout': 0.4456107479502579, 'num_layers': 2, 'hidden_size': 104}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:27:55,583] Trial 32 finished with value: 0.07068491727113724 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 2.9277569651984134e-05, 'dropout': 0.43991818346495304, 'num_layers': 2, 'hidden_size': 126}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:28:13,074] Trial 33 finished with value: 0.057275183498859406 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.6373032406924052e-05, 'dropout': 0.4820094880609051, 'num_layers': 2, 'hidden_size': 98}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:28:26,536] Trial 34 finished with value: 0.05727606639266014 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.00023039967887772517, 'dropout': 0.3965420698210399, 'num_layers': 2, 'hidden_size': 81}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:28:39,290] Trial 35 finished with value: 0.056772585958242416 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 2.9545616800212043e-05, 'dropout': 0.420857879161734, 'num_layers': 2, 'hidden_size': 116}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:28:52,628] Trial 36 finished with value: 0.07395389676094055 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.642527126534737e-05, 'dropout': 0.4378525565902482, 'num_layers': 2, 'hidden_size': 114}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:29:03,041] Trial 37 finished with value: 0.07203779369592667 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 6.966542615139249e-05, 'dropout': 0.47465079212722694, 'num_layers': 2, 'hidden_size': 62}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:29:16,757] Trial 38 finished with value: 0.054381970316171646 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 2.2434637304954932e-05, 'dropout': 0.4459770127890393, 'num_layers': 2, 'hidden_size': 98}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:29:25,269] Trial 39 finished with value: 0.0517805777490139 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 3.701718004253436e-05, 'dropout': 0.4610924715833458, 'num_layers': 2, 'hidden_size': 92}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:29:36,371] Trial 40 finished with value: 0.08291143923997879 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.0005494722074849229, 'dropout': 0.385423667344948, 'num_layers': 2, 'hidden_size': 123}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:29:46,795] Trial 41 finished with value: 0.05299762636423111 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 3.299538411092002e-05, 'dropout': 0.46415570747935075, 'num_layers': 2, 'hidden_size': 97}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:29:58,621] Trial 42 finished with value: 0.05438190698623657 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.00012279190015149961, 'dropout': 0.4998782231984959, 'num_layers': 2, 'hidden_size': 88}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:30:03,579] Trial 43 finished with value: 0.05386490002274513 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 1.612228823728024e-05, 'dropout': 0.4255076217350748, 'num_layers': 2, 'hidden_size': 79}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:30:16,448] Trial 44 finished with value: 0.0754813700914383 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 0.004150685263551764, 'dropout': 0.48239665696526757, 'num_layers': 2, 'hidden_size': 106}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:30:40,364] Trial 45 finished with value: 0.05278434231877327 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 3.872280330407177e-05, 'dropout': 0.41282090330655713, 'num_layers': 2, 'hidden_size': 68}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:31:00,449] Trial 46 finished with value: 0.07289101183414459 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 2.3336415249843373e-05, 'dropout': 0.46718435166626965, 'num_layers': 3, 'hidden_size': 56}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:31:13,058] Trial 47 finished with value: 0.0658220425248146 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 6.676672326402912e-05, 'dropout': 0.4448142948247118, 'num_layers': 2, 'hidden_size': 93}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:31:30,236] Trial 48 finished with value: 0.08308297395706177 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 1.3405907853891785e-05, 'dropout': 0.35956343653704076, 'num_layers': 2, 'hidden_size': 109}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:31:41,625] Trial 49 finished with value: 0.0781250149011612 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 4.1802645306043183e-05, 'dropout': 0.48697395186522113, 'num_layers': 3, 'hidden_size': 64}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:31:51,689] Trial 50 finished with value: 0.10764655470848083 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 1.3165207280925638e-05, 'dropout': 0.46279434854977614, 'num_layers': 2, 'hidden_size': 48}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:32:04,102] Trial 51 finished with value: 0.03592485189437866 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 3.3152519165215874e-05, 'dropout': 0.4145702233649352, 'num_layers': 2, 'hidden_size': 67}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:32:17,857] Trial 52 finished with value: 0.03931684419512749 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 9.621627763507849e-05, 'dropout': 0.39313039629868296, 'num_layers': 2, 'hidden_size': 76}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:32:31,359] Trial 53 finished with value: 0.07344014197587967 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 9.762802460649727e-05, 'dropout': 0.3960126553629242, 'num_layers': 2, 'hidden_size': 75}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:32:45,574] Trial 54 finished with value: 0.08456149697303772 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 5.971791301100921e-05, 'dropout': 0.3746148679506677, 'num_layers': 2, 'hidden_size': 59}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:32:56,273] Trial 55 finished with value: 0.08769860118627548 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.0001562387493870842, 'dropout': 0.34504602277270463, 'num_layers': 2, 'hidden_size': 45}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:33:10,478] Trial 56 finished with value: 0.03657715395092964 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 2.4870743680885646e-05, 'dropout': 0.429547724506436, 'num_layers': 2, 'hidden_size': 72}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:33:28,451] Trial 57 finished with value: 0.08817022293806076 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.5578696087865867e-05, 'dropout': 0.43180967567311784, 'num_layers': 2, 'hidden_size': 67}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:33:50,590] Trial 58 finished with value: 0.04296984151005745 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 9.57140002483721e-05, 'dropout': 0.33191010707739077, 'num_layers': 2, 'hidden_size': 83}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:34:14,982] Trial 59 finished with value: 0.08394977450370789 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 1.95147819800964e-05, 'dropout': 0.4051941722178928, 'num_layers': 2, 'hidden_size': 72}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:34:33,798] Trial 60 finished with value: 0.09885692596435547 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.0002378744802504207, 'dropout': 0.3595805097598901, 'num_layers': 2, 'hidden_size': 87}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:34:46,058] Trial 61 finished with value: 0.08158285915851593 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 8.757131494004524e-05, 'dropout': 0.32924198085361384, 'num_layers': 2, 'hidden_size': 80}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:34:58,511] Trial 62 finished with value: 0.0629238486289978 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 7.635375833323572e-05, 'dropout': 0.33258931898617267, 'num_layers': 2, 'hidden_size': 61}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:35:13,327] Trial 63 finished with value: 0.06177261844277382 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.00011847535568488545, 'dropout': 0.3099096384833827, 'num_layers': 2, 'hidden_size': 75}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:35:28,964] Trial 64 finished with value: 0.03789456561207771 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 5.302675183522319e-05, 'dropout': 0.38671759851344345, 'num_layers': 2, 'hidden_size': 82}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:35:45,572] Trial 65 finished with value: 0.05499458312988281 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 5.1271628108362126e-05, 'dropout': 0.3888262598206391, 'num_layers': 2, 'hidden_size': 101}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:36:03,374] Trial 66 finished with value: 0.1035032719373703 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 3.2876504550482986e-05, 'dropout': 0.4127824373243424, 'num_layers': 2, 'hidden_size': 55}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:36:23,217] Trial 67 finished with value: 0.07069315016269684 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 2.17929593266757e-05, 'dropout': 0.39511272778799245, 'num_layers': 2, 'hidden_size': 77}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:36:46,329] Trial 68 finished with value: 0.05237637460231781 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 4.3760585583400185e-05, 'dropout': 0.3712516916345268, 'num_layers': 2, 'hidden_size': 66}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:36:55,270] Trial 69 finished with value: 0.056625958532094955 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 2.8093620849915125e-05, 'dropout': 0.42574885079813873, 'num_layers': 2, 'hidden_size': 72}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:37:06,022] Trial 70 finished with value: 0.06563499569892883 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 5.756379839047009e-05, 'dropout': 0.4518759799102771, 'num_layers': 2, 'hidden_size': 111}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:37:17,409] Trial 71 finished with value: 0.06237306818366051 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.00011063333170373095, 'dropout': 0.27703327760862234, 'num_layers': 2, 'hidden_size': 83}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:37:32,813] Trial 72 finished with value: 0.1081741601228714 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.0003933292453870122, 'dropout': 0.414567114954812, 'num_layers': 2, 'hidden_size': 91}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:37:44,064] Trial 73 finished with value: 0.06570760905742645 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 6.665709352813169e-05, 'dropout': 0.3770520806327019, 'num_layers': 2, 'hidden_size': 83}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:38:12,600] Trial 74 finished with value: 0.036336902529001236 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.00016477200683100168, 'dropout': 0.36604683296764606, 'num_layers': 2, 'hidden_size': 121}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:38:36,450] Trial 75 finished with value: 0.04437994584441185 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.0001933557367413346, 'dropout': 0.3659120812173373, 'num_layers': 2, 'hidden_size': 123}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:38:58,625] Trial 76 finished with value: 0.11264777928590775 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.00014135231155583975, 'dropout': 0.3878934399615195, 'num_layers': 2, 'hidden_size': 118}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:39:27,264] Trial 77 finished with value: 0.08694296330213547 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 1.598136799335176e-05, 'dropout': 0.40446740320083663, 'num_layers': 2, 'hidden_size': 127}. Best is trial 18 with value: 0.034170981496572495.\n",
      "[I 2024-12-21 14:39:47,759] Trial 78 finished with value: 0.03060317039489746 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 3.524060137296664e-05, 'dropout': 0.4345327188012782, 'num_layers': 2, 'hidden_size': 120}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:40:10,437] Trial 79 finished with value: 0.03537823632359505 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 4.5098926535092e-05, 'dropout': 0.4224693064189391, 'num_layers': 2, 'hidden_size': 118}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:40:29,274] Trial 80 finished with value: 0.03732098266482353 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 3.2891684064268454e-05, 'dropout': 0.43713257990033727, 'num_layers': 2, 'hidden_size': 120}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:40:58,751] Trial 81 finished with value: 0.08819665014743805 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 3.0823623460837366e-05, 'dropout': 0.436955500603165, 'num_layers': 2, 'hidden_size': 120}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:41:18,339] Trial 82 finished with value: 0.09468141943216324 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 3.7653923369564e-05, 'dropout': 0.4272103968507267, 'num_layers': 2, 'hidden_size': 123}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:41:42,602] Trial 83 finished with value: 0.061059314757585526 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 4.560994045547106e-05, 'dropout': 0.4215344467409514, 'num_layers': 2, 'hidden_size': 113}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:42:06,063] Trial 84 finished with value: 0.061350177973508835 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 2.6515406224694215e-05, 'dropout': 0.412106881107084, 'num_layers': 2, 'hidden_size': 120}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:42:25,953] Trial 85 finished with value: 0.1626816689968109 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.0008316796074894684, 'dropout': 0.45086987022536734, 'num_layers': 2, 'hidden_size': 128}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:42:47,571] Trial 86 finished with value: 0.08672886341810226 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 2.0837277770822156e-05, 'dropout': 0.44025751566064525, 'num_layers': 2, 'hidden_size': 116}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:43:13,620] Trial 87 finished with value: 0.09057150036096573 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 5.1419768987109446e-05, 'dropout': 0.35041895033600184, 'num_layers': 2, 'hidden_size': 107}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:43:34,429] Trial 88 finished with value: 0.04814206808805466 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 1.193365009934252e-05, 'dropout': 0.400959841811213, 'num_layers': 2, 'hidden_size': 113}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:43:51,078] Trial 89 finished with value: 0.057687193155288696 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 3.634102453814015e-05, 'dropout': 0.23470894384251093, 'num_layers': 2, 'hidden_size': 120}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:44:12,544] Trial 90 finished with value: 0.10590658336877823 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 6.376885005275868e-05, 'dropout': 0.4330931873607846, 'num_layers': 2, 'hidden_size': 125}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:44:23,423] Trial 91 finished with value: 0.060742300003767014 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 7.821776627047407e-05, 'dropout': 0.39312733764680863, 'num_layers': 2, 'hidden_size': 70}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:44:42,820] Trial 92 finished with value: 0.05948157608509064 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 4.070131904203111e-05, 'dropout': 0.3810547145237666, 'num_layers': 2, 'hidden_size': 118}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:45:04,011] Trial 93 finished with value: 0.07231570035219193 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 5.401111479618179e-05, 'dropout': 0.4205379438367385, 'num_layers': 2, 'hidden_size': 101}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:45:20,563] Trial 94 finished with value: 0.08953648060560226 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 8.9967004091796e-05, 'dropout': 0.40123801128356373, 'num_layers': 2, 'hidden_size': 64}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:45:33,301] Trial 95 finished with value: 0.05214880406856537 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.00016647880905832087, 'dropout': 0.40799248781975783, 'num_layers': 2, 'hidden_size': 75}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:45:51,320] Trial 96 finished with value: 0.035592757165431976 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 3.358489684703779e-05, 'dropout': 0.35320575690691625, 'num_layers': 2, 'hidden_size': 124}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:46:13,039] Trial 97 finished with value: 0.10109444707632065 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 2.423161467608886e-05, 'dropout': 0.4575998741998406, 'num_layers': 2, 'hidden_size': 125}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:46:29,970] Trial 98 finished with value: 0.039115991443395615 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 3.0801719253826635e-05, 'dropout': 0.3545449012720605, 'num_layers': 2, 'hidden_size': 122}. Best is trial 78 with value: 0.03060317039489746.\n",
      "[I 2024-12-21 14:46:48,572] Trial 99 finished with value: 0.09402086585760117 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.7656192133317538e-05, 'dropout': 0.46991735380179556, 'num_layers': 2, 'hidden_size': 116}. Best is trial 78 with value: 0.03060317039489746.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_window_7_look_forward_1_close_price_target saved to ..\\data\\models\\GRU_window_7_look_forward_1_close_price_target\\GRU_window_7_look_forward_1_close_price_target_study.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [1:02:29<1:00:27, 1813.88s/it][I 2024-12-21 14:46:52,660] A new study created in memory with name: CNN-LSTM_window_7_look_forward_1_close_price_target\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved to ..\\data\\models\\GRU_window_7_look_forward_1_close_price_target\n",
      "Saved to ..\\data\\models\\GRU_window_7_look_forward_1_close_price_target:\n",
      "Best hyperparameters for GRU, window size: 7, look forward: 1, target close_price_target: {'epochs': 19, 'batch_size': 32, 'learning_rate': 3.524060137296664e-05, 'dropout': 0.4345327188012782, 'num_layers': 2, 'hidden_size': 120}\n",
      "Best trial index: 78, Best trial value: 0.03060317039489746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 14:47:05,717] Trial 0 finished with value: 0.06937533617019653 and parameters: {'epochs': 12, 'batch_size': 64, 'learning_rate': 0.001969553125282057, 'dropout': 0.28617573710266797, 'num_layers': 2, 'hidden_size': 47, 'conv_filters': 64}. Best is trial 0 with value: 0.06937533617019653.\n",
      "[I 2024-12-21 14:47:13,567] Trial 1 finished with value: 0.09042465686798096 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 1.531167764807073e-05, 'dropout': 0.30278105041148445, 'num_layers': 2, 'hidden_size': 33, 'conv_filters': 32}. Best is trial 0 with value: 0.06937533617019653.\n",
      "[I 2024-12-21 14:47:30,449] Trial 2 finished with value: 0.10133057832717896 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 0.00028492026593722296, 'dropout': 0.23089819106837034, 'num_layers': 3, 'hidden_size': 72, 'conv_filters': 64}. Best is trial 0 with value: 0.06937533617019653.\n",
      "[I 2024-12-21 14:47:43,233] Trial 3 finished with value: 0.10678987950086594 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 0.0003391662220517133, 'dropout': 0.4948121805362671, 'num_layers': 2, 'hidden_size': 29, 'conv_filters': 64}. Best is trial 0 with value: 0.06937533617019653.\n",
      "[I 2024-12-21 14:48:23,450] Trial 4 finished with value: 0.08127042651176453 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.00015927053615526007, 'dropout': 0.33861228982542824, 'num_layers': 3, 'hidden_size': 113, 'conv_filters': 128}. Best is trial 0 with value: 0.06937533617019653.\n",
      "[I 2024-12-21 14:48:45,829] Trial 5 finished with value: 0.049124278128147125 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 0.0001096124221336016, 'dropout': 0.23170318718083943, 'num_layers': 2, 'hidden_size': 125, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:49:24,657] Trial 6 finished with value: 0.10144905745983124 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 0.00012098267889316814, 'dropout': 0.24050359670294813, 'num_layers': 3, 'hidden_size': 34, 'conv_filters': 128}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:50:02,613] Trial 7 finished with value: 0.11442927271127701 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.00014988458701085304, 'dropout': 0.3553129709708702, 'num_layers': 3, 'hidden_size': 20, 'conv_filters': 128}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:50:22,538] Trial 8 finished with value: 0.09914989024400711 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 0.0002786243332754669, 'dropout': 0.25920839602016765, 'num_layers': 2, 'hidden_size': 116, 'conv_filters': 128}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:50:31,158] Trial 9 finished with value: 0.0888822078704834 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 0.00025033939660206437, 'dropout': 0.4091351577509241, 'num_layers': 2, 'hidden_size': 106, 'conv_filters': 32}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:51:03,737] Trial 10 finished with value: 0.07376444339752197 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 0.009781400285864602, 'dropout': 0.20665368416238955, 'num_layers': 2, 'hidden_size': 92, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:51:21,214] Trial 11 finished with value: 0.07488564401865005 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 0.002050674047658559, 'dropout': 0.2896100024404515, 'num_layers': 2, 'hidden_size': 63, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:51:52,229] Trial 12 finished with value: 0.06869068741798401 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 0.001757443859507026, 'dropout': 0.2831421407489057, 'num_layers': 2, 'hidden_size': 55, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:52:11,327] Trial 13 finished with value: 0.059691205620765686 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 3.861044505465898e-05, 'dropout': 0.34732269310945374, 'num_layers': 2, 'hidden_size': 90, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:52:28,115] Trial 14 finished with value: 0.05982360616326332 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 2.398688152972823e-05, 'dropout': 0.4200926250626565, 'num_layers': 2, 'hidden_size': 92, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:52:36,732] Trial 15 finished with value: 0.06546676903963089 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 4.370896455811426e-05, 'dropout': 0.38526639191904477, 'num_layers': 2, 'hidden_size': 127, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:52:47,544] Trial 16 finished with value: 0.0593942329287529 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 5.559972766586424e-05, 'dropout': 0.46740477309783546, 'num_layers': 2, 'hidden_size': 90, 'conv_filters': 32}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:53:03,768] Trial 17 finished with value: 0.06879854202270508 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 6.550724009871923e-05, 'dropout': 0.47506794264832874, 'num_layers': 3, 'hidden_size': 80, 'conv_filters': 32}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:53:21,952] Trial 18 finished with value: 0.10608884692192078 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 0.0007581115882977431, 'dropout': 0.4346002633026493, 'num_layers': 2, 'hidden_size': 125, 'conv_filters': 32}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:53:37,972] Trial 19 finished with value: 0.069231778383255 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.0358494010813427e-05, 'dropout': 0.4635847025164148, 'num_layers': 2, 'hidden_size': 104, 'conv_filters': 32}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:53:46,934] Trial 20 finished with value: 0.09420297294855118 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 7.679128064135171e-05, 'dropout': 0.37533313136004487, 'num_layers': 3, 'hidden_size': 77, 'conv_filters': 32}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:54:15,880] Trial 21 finished with value: 0.06550963968038559 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 3.333824055654266e-05, 'dropout': 0.3259833476600561, 'num_layers': 2, 'hidden_size': 88, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:54:34,083] Trial 22 finished with value: 0.07803642749786377 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 6.111878500293412e-05, 'dropout': 0.20448472363873627, 'num_layers': 2, 'hidden_size': 98, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:54:46,043] Trial 23 finished with value: 0.06430961936712265 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 1.8245703037116464e-05, 'dropout': 0.43928624259839344, 'num_layers': 2, 'hidden_size': 118, 'conv_filters': 32}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:55:10,913] Trial 24 finished with value: 0.051116809248924255 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 3.527383414760724e-05, 'dropout': 0.38969889693872173, 'num_layers': 2, 'hidden_size': 66, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:55:20,999] Trial 25 finished with value: 0.0892748087644577 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 0.00012108180629824815, 'dropout': 0.3902101084991394, 'num_layers': 2, 'hidden_size': 65, 'conv_filters': 32}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:55:40,247] Trial 26 finished with value: 0.11656304448843002 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 0.0006861244834316765, 'dropout': 0.46295118202545243, 'num_layers': 2, 'hidden_size': 45, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:55:51,368] Trial 27 finished with value: 0.05455482378602028 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 2.8775399152790127e-05, 'dropout': 0.31714788575190866, 'num_layers': 2, 'hidden_size': 81, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:56:08,411] Trial 28 finished with value: 0.07232112437486649 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 1.0003921815563332e-05, 'dropout': 0.3150904636404702, 'num_layers': 2, 'hidden_size': 61, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:56:28,785] Trial 29 finished with value: 0.07241601496934891 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 2.3344916257084482e-05, 'dropout': 0.2545469389917162, 'num_layers': 2, 'hidden_size': 43, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:56:46,781] Trial 30 finished with value: 0.06383803486824036 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 8.437385902044133e-05, 'dropout': 0.3649900263694825, 'num_layers': 2, 'hidden_size': 57, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:56:56,573] Trial 31 finished with value: 0.08309168368577957 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 4.7311150081110295e-05, 'dropout': 0.400240934072304, 'num_layers': 2, 'hidden_size': 82, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:57:10,542] Trial 32 finished with value: 0.06462245434522629 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 3.1185754183551656e-05, 'dropout': 0.27503185666173907, 'num_layers': 2, 'hidden_size': 71, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:57:19,606] Trial 33 finished with value: 0.07143464684486389 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 1.799818025565498e-05, 'dropout': 0.30124721118659004, 'num_layers': 2, 'hidden_size': 72, 'conv_filters': 32}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:57:30,462] Trial 34 finished with value: 0.06007150188088417 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 9.810282868096058e-05, 'dropout': 0.4394746779790586, 'num_layers': 2, 'hidden_size': 52, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:57:45,583] Trial 35 finished with value: 0.07248346507549286 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 5.6215583393560684e-05, 'dropout': 0.49809666553892246, 'num_layers': 2, 'hidden_size': 101, 'conv_filters': 128}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:58:13,290] Trial 36 finished with value: 0.0733681470155716 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.00016994069631589217, 'dropout': 0.22203315310707586, 'num_layers': 2, 'hidden_size': 110, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:58:24,481] Trial 37 finished with value: 0.09743208438158035 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 2.8677579850189934e-05, 'dropout': 0.3307805642792644, 'num_layers': 3, 'hidden_size': 82, 'conv_filters': 32}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:58:47,468] Trial 38 finished with value: 0.0614948607981205 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 1.4922719433657446e-05, 'dropout': 0.4786574994093212, 'num_layers': 2, 'hidden_size': 69, 'conv_filters': 128}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:59:01,897] Trial 39 finished with value: 0.09190193563699722 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 0.00018907795735792599, 'dropout': 0.2622506903043702, 'num_layers': 3, 'hidden_size': 96, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:59:42,274] Trial 40 finished with value: 0.11017096042633057 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.00043251728396999974, 'dropout': 0.23497650837402825, 'num_layers': 2, 'hidden_size': 86, 'conv_filters': 128}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 14:59:59,057] Trial 41 finished with value: 0.06696897745132446 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 3.422086628096482e-05, 'dropout': 0.3487027179461096, 'num_layers': 2, 'hidden_size': 76, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:00:16,984] Trial 42 finished with value: 0.06390301883220673 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 4.2143208176866045e-05, 'dropout': 0.3454908880301234, 'num_layers': 2, 'hidden_size': 90, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:00:48,730] Trial 43 finished with value: 0.09476244449615479 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 9.702480806391646e-05, 'dropout': 0.3093509328673387, 'num_layers': 2, 'hidden_size': 121, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:01:10,696] Trial 44 finished with value: 0.07727878540754318 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 1.3984819455119822e-05, 'dropout': 0.4142425489005558, 'num_layers': 2, 'hidden_size': 109, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:01:29,812] Trial 45 finished with value: 0.056080691516399384 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 2.3654616474959704e-05, 'dropout': 0.36630522485453315, 'num_layers': 2, 'hidden_size': 67, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:01:51,168] Trial 46 finished with value: 0.06256098300218582 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 2.3455950940605907e-05, 'dropout': 0.3703718131338622, 'num_layers': 2, 'hidden_size': 49, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:02:15,410] Trial 47 finished with value: 0.07637039572000504 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 0.009777421237174951, 'dropout': 0.36311626135325864, 'num_layers': 2, 'hidden_size': 38, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:02:21,806] Trial 48 finished with value: 0.07938037067651749 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 5.97155899190347e-05, 'dropout': 0.39485890458241035, 'num_layers': 2, 'hidden_size': 66, 'conv_filters': 32}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:02:57,813] Trial 49 finished with value: 0.08013744652271271 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.0001251796080481069, 'dropout': 0.3812954567089881, 'num_layers': 2, 'hidden_size': 58, 'conv_filters': 128}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:03:19,257] Trial 50 finished with value: 0.08973090350627899 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 4.743401150839254e-05, 'dropout': 0.22005637689538682, 'num_layers': 2, 'hidden_size': 16, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:03:40,552] Trial 51 finished with value: 0.06079736351966858 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 3.62087394871177e-05, 'dropout': 0.3336988826926871, 'num_layers': 2, 'hidden_size': 76, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:03:59,379] Trial 52 finished with value: 0.05396967753767967 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 2.461478898566508e-05, 'dropout': 0.42460440545098066, 'num_layers': 2, 'hidden_size': 95, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:04:31,524] Trial 53 finished with value: 0.05763547867536545 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 1.9265795839786622e-05, 'dropout': 0.45144551998573923, 'num_layers': 2, 'hidden_size': 85, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:04:47,321] Trial 54 finished with value: 0.05084923282265663 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 2.240052702663503e-05, 'dropout': 0.4499093482878764, 'num_layers': 2, 'hidden_size': 85, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:05:07,424] Trial 55 finished with value: 0.05346439778804779 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.4044187122747532e-05, 'dropout': 0.42839307390033565, 'num_layers': 2, 'hidden_size': 97, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:05:39,597] Trial 56 finished with value: 0.06819255650043488 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.1461407176571063e-05, 'dropout': 0.4266628591809566, 'num_layers': 2, 'hidden_size': 95, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:06:07,856] Trial 57 finished with value: 0.05606217309832573 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.305288142550411e-05, 'dropout': 0.453596954319692, 'num_layers': 2, 'hidden_size': 103, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:06:33,479] Trial 58 finished with value: 0.07252828031778336 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 1.7768971157538173e-05, 'dropout': 0.4050271823618107, 'num_layers': 3, 'hidden_size': 99, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:07:00,560] Trial 59 finished with value: 0.058974627405405045 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.520951319916359e-05, 'dropout': 0.4216021333360355, 'num_layers': 2, 'hidden_size': 115, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:07:14,077] Trial 60 finished with value: 0.06584299355745316 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 2.0092351693330376e-05, 'dropout': 0.4832066053075088, 'num_layers': 2, 'hidden_size': 94, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:07:36,196] Trial 61 finished with value: 0.055414121598005295 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.397123446074611e-05, 'dropout': 0.45100906237662786, 'num_layers': 2, 'hidden_size': 103, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:07:57,505] Trial 62 finished with value: 0.059481896460056305 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.361217143214375e-05, 'dropout': 0.44673586915924907, 'num_layers': 2, 'hidden_size': 110, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:08:18,706] Trial 63 finished with value: 0.06931600719690323 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 2.767301334957207e-05, 'dropout': 0.43368884799113, 'num_layers': 2, 'hidden_size': 80, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:08:41,291] Trial 64 finished with value: 0.05351221188902855 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.5083283335853846e-05, 'dropout': 0.41062715691412127, 'num_layers': 2, 'hidden_size': 105, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:09:04,430] Trial 65 finished with value: 0.05765435844659805 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.7541766693187135e-05, 'dropout': 0.41106904173281217, 'num_layers': 2, 'hidden_size': 119, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:09:31,564] Trial 66 finished with value: 0.08492135256528854 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 7.088290457201476e-05, 'dropout': 0.42489344803733176, 'num_layers': 2, 'hidden_size': 106, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:09:51,739] Trial 67 finished with value: 0.05895783007144928 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 1.0663384112891304e-05, 'dropout': 0.40137729426399277, 'num_layers': 2, 'hidden_size': 123, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:10:04,025] Trial 68 finished with value: 0.07551998645067215 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 3.661814692169591e-05, 'dropout': 0.38714721587565315, 'num_layers': 2, 'hidden_size': 84, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:10:19,366] Trial 69 finished with value: 0.07352881878614426 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 4.852163720549911e-05, 'dropout': 0.41519344082656495, 'num_layers': 2, 'hidden_size': 89, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:10:29,936] Trial 70 finished with value: 0.06796417385339737 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 0.00021364326268481562, 'dropout': 0.46137153200042996, 'num_layers': 2, 'hidden_size': 93, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:10:47,320] Trial 71 finished with value: 0.052823569625616074 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.49689922061782e-05, 'dropout': 0.4320270706897472, 'num_layers': 2, 'hidden_size': 98, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:11:04,367] Trial 72 finished with value: 0.05641496926546097 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 1.9861719610403857e-05, 'dropout': 0.43652827346492595, 'num_layers': 2, 'hidden_size': 98, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:11:17,959] Trial 73 finished with value: 0.07552265375852585 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 2.8053517640332874e-05, 'dropout': 0.43068641068393065, 'num_layers': 2, 'hidden_size': 112, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:11:31,235] Trial 74 finished with value: 0.05828135460615158 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.667925191267048e-05, 'dropout': 0.2929558651581366, 'num_layers': 2, 'hidden_size': 106, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:11:56,412] Trial 75 finished with value: 0.06662967056035995 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 2.1316654274576683e-05, 'dropout': 0.39532589573762883, 'num_layers': 2, 'hidden_size': 78, 'conv_filters': 128}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:12:14,244] Trial 76 finished with value: 0.06144077703356743 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.1688777039914968e-05, 'dropout': 0.44259183177630956, 'num_layers': 2, 'hidden_size': 87, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:12:22,358] Trial 77 finished with value: 0.07026335597038269 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 1.535183704424167e-05, 'dropout': 0.47096839122393486, 'num_layers': 2, 'hidden_size': 127, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:12:33,834] Trial 78 finished with value: 0.05840650945901871 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 3.1245884236918085e-05, 'dropout': 0.41700199574259417, 'num_layers': 2, 'hidden_size': 62, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:12:53,379] Trial 79 finished with value: 0.06670185923576355 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 2.6207014491726966e-05, 'dropout': 0.24853339159841015, 'num_layers': 2, 'hidden_size': 98, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:13:07,384] Trial 80 finished with value: 0.08755265921354294 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 0.00041366455780753167, 'dropout': 0.40583935354597545, 'num_layers': 2, 'hidden_size': 101, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:13:25,257] Trial 81 finished with value: 0.057516612112522125 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.3846494696256352e-05, 'dropout': 0.4576617664020723, 'num_layers': 2, 'hidden_size': 74, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:13:37,289] Trial 82 finished with value: 0.05787867680191994 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 1.528087362932669e-05, 'dropout': 0.44891668726059664, 'num_layers': 2, 'hidden_size': 102, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:13:58,600] Trial 83 finished with value: 0.06698489934206009 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.0238663144061486e-05, 'dropout': 0.49136351845388343, 'num_layers': 2, 'hidden_size': 106, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:14:17,300] Trial 84 finished with value: 0.05553389713168144 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.1469177179606514e-05, 'dropout': 0.4414560277946039, 'num_layers': 2, 'hidden_size': 92, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:14:33,181] Trial 85 finished with value: 0.0590582937002182 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.2727498325680544e-05, 'dropout': 0.4293452259839337, 'num_layers': 2, 'hidden_size': 115, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:14:56,649] Trial 86 finished with value: 0.07298292964696884 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 3.220429821613082e-05, 'dropout': 0.2771988356880622, 'num_layers': 2, 'hidden_size': 82, 'conv_filters': 128}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:15:28,344] Trial 87 finished with value: 0.05978664010763168 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 4.1538643045782924e-05, 'dropout': 0.35837884023978966, 'num_layers': 2, 'hidden_size': 96, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:15:38,783] Trial 88 finished with value: 0.06606394052505493 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 1.6076731038662937e-05, 'dropout': 0.37768632004637, 'num_layers': 3, 'hidden_size': 90, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:15:53,011] Trial 89 finished with value: 0.13328328728675842 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 0.0014932460379976098, 'dropout': 0.41853413936260564, 'num_layers': 2, 'hidden_size': 100, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:16:10,230] Trial 90 finished with value: 0.0696016252040863 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 1.2079501983006534e-05, 'dropout': 0.4708899535858968, 'num_layers': 2, 'hidden_size': 108, 'conv_filters': 32}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:16:36,703] Trial 91 finished with value: 0.062298595905303955 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.201423954849039e-05, 'dropout': 0.32148710725210156, 'num_layers': 2, 'hidden_size': 91, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:16:59,028] Trial 92 finished with value: 0.0618889294564724 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.078224425387989e-05, 'dropout': 0.44213308534513096, 'num_layers': 2, 'hidden_size': 104, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:17:21,210] Trial 93 finished with value: 0.05805531144142151 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.6857756611503427e-05, 'dropout': 0.4251338228948279, 'num_layers': 2, 'hidden_size': 94, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:17:34,916] Trial 94 finished with value: 0.06949052959680557 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 1.754898493422592e-05, 'dropout': 0.4543823970530782, 'num_layers': 2, 'hidden_size': 87, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:17:55,508] Trial 95 finished with value: 0.05616283416748047 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 2.2426557162248292e-05, 'dropout': 0.4461522272528694, 'num_layers': 2, 'hidden_size': 70, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:18:20,567] Trial 96 finished with value: 0.0546749085187912 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 8.444640213395217e-05, 'dropout': 0.4087812884376357, 'num_layers': 2, 'hidden_size': 97, 'conv_filters': 64}. Best is trial 5 with value: 0.049124278128147125.\n",
      "[I 2024-12-21 15:18:41,916] Trial 97 finished with value: 0.042012374848127365 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.00014022536015319403, 'dropout': 0.4097775637333472, 'num_layers': 2, 'hidden_size': 96, 'conv_filters': 64}. Best is trial 97 with value: 0.042012374848127365.\n",
      "[I 2024-12-21 15:19:03,205] Trial 98 finished with value: 0.07834044843912125 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 9.220840969647687e-05, 'dropout': 0.39390125240246604, 'num_layers': 2, 'hidden_size': 97, 'conv_filters': 64}. Best is trial 97 with value: 0.042012374848127365.\n",
      "[I 2024-12-21 15:19:31,779] Trial 99 finished with value: 0.09297417849302292 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.00014018681925835749, 'dropout': 0.4115823651717169, 'num_layers': 2, 'hidden_size': 84, 'conv_filters': 64}. Best is trial 97 with value: 0.042012374848127365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-LSTM_window_7_look_forward_1_close_price_target saved to ..\\data\\models\\CNN-LSTM_window_7_look_forward_1_close_price_target\\CNN-LSTM_window_7_look_forward_1_close_price_target_study.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [1:35:13<31:22, 1882.26s/it]  [I 2024-12-21 15:19:36,295] A new study created in memory with name: CNN-GRU_window_7_look_forward_1_close_price_target\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved to ..\\data\\models\\CNN-LSTM_window_7_look_forward_1_close_price_target\n",
      "Saved to ..\\data\\models\\CNN-LSTM_window_7_look_forward_1_close_price_target:\n",
      "Best hyperparameters for CNN-LSTM, window size: 7, look forward: 1, target close_price_target: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.00014022536015319403, 'dropout': 0.4097775637333472, 'num_layers': 2, 'hidden_size': 96, 'conv_filters': 64}\n",
      "Best trial index: 97, Best trial value: 0.042012374848127365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 15:19:56,255] Trial 0 finished with value: 0.10054013133049011 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.00019560501298495795, 'dropout': 0.20559714300774562, 'num_layers': 2, 'hidden_size': 101, 'conv_filters': 64}. Best is trial 0 with value: 0.10054013133049011.\n",
      "[I 2024-12-21 15:20:28,267] Trial 1 finished with value: 0.07192445546388626 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 0.005631701188773274, 'dropout': 0.4575168850250389, 'num_layers': 2, 'hidden_size': 67, 'conv_filters': 128}. Best is trial 1 with value: 0.07192445546388626.\n",
      "[I 2024-12-21 15:20:40,892] Trial 2 finished with value: 0.07639764994382858 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.004819168551786034, 'dropout': 0.27699102842113105, 'num_layers': 2, 'hidden_size': 86, 'conv_filters': 32}. Best is trial 1 with value: 0.07192445546388626.\n",
      "[I 2024-12-21 15:20:46,883] Trial 3 finished with value: 0.08321455121040344 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 0.002552493538735898, 'dropout': 0.24591262248833182, 'num_layers': 2, 'hidden_size': 115, 'conv_filters': 32}. Best is trial 1 with value: 0.07192445546388626.\n",
      "[I 2024-12-21 15:21:06,807] Trial 4 finished with value: 0.07338643819093704 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.0021003707191279476, 'dropout': 0.42796880497301104, 'num_layers': 2, 'hidden_size': 66, 'conv_filters': 64}. Best is trial 1 with value: 0.07192445546388626.\n",
      "[I 2024-12-21 15:21:32,037] Trial 5 finished with value: 0.06534575670957565 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.000138892657289523, 'dropout': 0.437605758896794, 'num_layers': 3, 'hidden_size': 120, 'conv_filters': 64}. Best is trial 5 with value: 0.06534575670957565.\n",
      "[I 2024-12-21 15:21:44,921] Trial 6 finished with value: 0.10631275177001953 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.0006222191733886223, 'dropout': 0.23340682941528762, 'num_layers': 2, 'hidden_size': 22, 'conv_filters': 32}. Best is trial 5 with value: 0.06534575670957565.\n",
      "[I 2024-12-21 15:21:53,966] Trial 7 finished with value: 0.1232198104262352 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 0.00043539898421920286, 'dropout': 0.35057679365426686, 'num_layers': 2, 'hidden_size': 82, 'conv_filters': 32}. Best is trial 5 with value: 0.06534575670957565.\n",
      "[I 2024-12-21 15:22:16,446] Trial 8 finished with value: 0.0581047423183918 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 3.090922234658495e-05, 'dropout': 0.4729255835103487, 'num_layers': 2, 'hidden_size': 112, 'conv_filters': 128}. Best is trial 8 with value: 0.0581047423183918.\n",
      "[I 2024-12-21 15:22:25,184] Trial 9 finished with value: 0.07282119244337082 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 0.0029116125699051956, 'dropout': 0.41988372651455685, 'num_layers': 3, 'hidden_size': 86, 'conv_filters': 64}. Best is trial 8 with value: 0.0581047423183918.\n",
      "[I 2024-12-21 15:22:50,454] Trial 10 finished with value: 0.05324742943048477 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 1.3931278827132557e-05, 'dropout': 0.49965352609903496, 'num_layers': 3, 'hidden_size': 40, 'conv_filters': 128}. Best is trial 10 with value: 0.05324742943048477.\n",
      "[I 2024-12-21 15:23:19,643] Trial 11 finished with value: 0.059060823172330856 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 1.3157178547113858e-05, 'dropout': 0.4975126739310405, 'num_layers': 3, 'hidden_size': 37, 'conv_filters': 128}. Best is trial 10 with value: 0.05324742943048477.\n",
      "[I 2024-12-21 15:23:39,194] Trial 12 finished with value: 0.05565395951271057 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 1.2728795997955754e-05, 'dropout': 0.49711556514857913, 'num_layers': 3, 'hidden_size': 46, 'conv_filters': 128}. Best is trial 10 with value: 0.05324742943048477.\n",
      "[I 2024-12-21 15:24:20,376] Trial 13 finished with value: 0.07026701420545578 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 4.409212711510402e-05, 'dropout': 0.37380867132670414, 'num_layers': 3, 'hidden_size': 47, 'conv_filters': 128}. Best is trial 10 with value: 0.05324742943048477.\n",
      "[I 2024-12-21 15:24:50,019] Trial 14 finished with value: 0.04163585603237152 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 1.3914004260977343e-05, 'dropout': 0.49687010955594524, 'num_layers': 3, 'hidden_size': 46, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:25:15,097] Trial 15 finished with value: 0.1001887246966362 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 5.803040605711184e-05, 'dropout': 0.39189757849553275, 'num_layers': 3, 'hidden_size': 20, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:25:41,433] Trial 16 finished with value: 0.056462548673152924 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.0571152745392304e-05, 'dropout': 0.29938343244488386, 'num_layers': 3, 'hidden_size': 56, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:26:11,266] Trial 17 finished with value: 0.1040913462638855 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 9.715602518852104e-05, 'dropout': 0.32225810644185504, 'num_layers': 3, 'hidden_size': 32, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:26:28,840] Trial 18 finished with value: 0.05535145103931427 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 2.0574915560645205e-05, 'dropout': 0.46506956648652736, 'num_layers': 3, 'hidden_size': 55, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:26:55,197] Trial 19 finished with value: 0.07000551372766495 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 6.908036431567646e-05, 'dropout': 0.40525420299397674, 'num_layers': 3, 'hidden_size': 34, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:27:53,693] Trial 20 finished with value: 0.07139202952384949 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.001020180885683598, 'dropout': 0.4529283344840683, 'num_layers': 3, 'hidden_size': 54, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:28:11,136] Trial 21 finished with value: 0.06200284883379936 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 2.5357564702281946e-05, 'dropout': 0.4798427630986985, 'num_layers': 3, 'hidden_size': 56, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:28:28,107] Trial 22 finished with value: 0.05724606290459633 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 2.3913253243893994e-05, 'dropout': 0.46947293220498754, 'num_layers': 3, 'hidden_size': 42, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:28:44,629] Trial 23 finished with value: 0.058642975986003876 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 1.9877935870447964e-05, 'dropout': 0.49854443376904, 'num_layers': 3, 'hidden_size': 74, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:29:02,063] Trial 24 finished with value: 0.09308252483606339 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 4.2971419479203806e-05, 'dropout': 0.44823558512357475, 'num_layers': 3, 'hidden_size': 28, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:29:31,056] Trial 25 finished with value: 0.049408603459596634 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 1.56608898895713e-05, 'dropout': 0.4749513006454545, 'num_layers': 3, 'hidden_size': 63, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:29:58,398] Trial 26 finished with value: 0.04277953505516052 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 1.0830047290764276e-05, 'dropout': 0.3784380939538283, 'num_layers': 3, 'hidden_size': 74, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:30:27,688] Trial 27 finished with value: 0.08999714255332947 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 0.00024596744104578516, 'dropout': 0.35511296309538876, 'num_layers': 3, 'hidden_size': 94, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:30:53,305] Trial 28 finished with value: 0.06194106489419937 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 9.900416163850895e-05, 'dropout': 0.3854690578740058, 'num_layers': 3, 'hidden_size': 76, 'conv_filters': 64}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:31:07,816] Trial 29 finished with value: 0.08791742473840714 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.00014550774647112082, 'dropout': 0.3244346689012165, 'num_layers': 3, 'hidden_size': 66, 'conv_filters': 32}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:31:29,558] Trial 30 finished with value: 0.05347850173711777 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 3.592537330308174e-05, 'dropout': 0.2013000102037562, 'num_layers': 3, 'hidden_size': 98, 'conv_filters': 64}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:31:49,085] Trial 31 finished with value: 0.04916733503341675 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 1.5878198279883238e-05, 'dropout': 0.4831368627421009, 'num_layers': 3, 'hidden_size': 61, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:32:11,362] Trial 32 finished with value: 0.04630622640252113 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 1.0322627532506496e-05, 'dropout': 0.4105896616873231, 'num_layers': 3, 'hidden_size': 63, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:32:39,293] Trial 33 finished with value: 0.04360067844390869 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 1.0631328640948003e-05, 'dropout': 0.4215347080304011, 'num_layers': 3, 'hidden_size': 77, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:33:12,141] Trial 34 finished with value: 0.04760295897722244 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 1.0508593049318016e-05, 'dropout': 0.42313185708890705, 'num_layers': 3, 'hidden_size': 80, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:33:52,808] Trial 35 finished with value: 0.048932407051324844 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 1.0071309329056716e-05, 'dropout': 0.3695230723469479, 'num_layers': 3, 'hidden_size': 71, 'conv_filters': 128}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:34:06,052] Trial 36 finished with value: 0.04314792901277542 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 2.81922933972986e-05, 'dropout': 0.4054495018787997, 'num_layers': 2, 'hidden_size': 90, 'conv_filters': 32}. Best is trial 14 with value: 0.04163585603237152.\n",
      "[I 2024-12-21 15:34:18,493] Trial 37 finished with value: 0.03998464345932007 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 2.7401745978086e-05, 'dropout': 0.32818144227487284, 'num_layers': 2, 'hidden_size': 108, 'conv_filters': 32}. Best is trial 37 with value: 0.03998464345932007.\n",
      "[I 2024-12-21 15:34:30,975] Trial 38 finished with value: 0.04833361878991127 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 6.660295278096103e-05, 'dropout': 0.28114962502303, 'num_layers': 2, 'hidden_size': 107, 'conv_filters': 32}. Best is trial 37 with value: 0.03998464345932007.\n",
      "[I 2024-12-21 15:34:44,418] Trial 39 finished with value: 0.039319802075624466 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 2.9437804838358743e-05, 'dropout': 0.32327071880747804, 'num_layers': 2, 'hidden_size': 127, 'conv_filters': 32}. Best is trial 39 with value: 0.039319802075624466.\n",
      "[I 2024-12-21 15:35:02,642] Trial 40 finished with value: 0.04710238426923752 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 4.5248647778294564e-05, 'dropout': 0.32253143993977584, 'num_layers': 2, 'hidden_size': 128, 'conv_filters': 32}. Best is trial 39 with value: 0.039319802075624466.\n",
      "[I 2024-12-21 15:35:20,791] Trial 41 finished with value: 0.038246456533670425 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 2.9719414672891207e-05, 'dropout': 0.33424117206445203, 'num_layers': 2, 'hidden_size': 93, 'conv_filters': 32}. Best is trial 41 with value: 0.038246456533670425.\n",
      "[I 2024-12-21 15:35:34,293] Trial 42 finished with value: 0.043698750436306 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 1.9000850431132577e-05, 'dropout': 0.3362705682868072, 'num_layers': 2, 'hidden_size': 121, 'conv_filters': 32}. Best is trial 41 with value: 0.038246456533670425.\n",
      "[I 2024-12-21 15:35:47,987] Trial 43 finished with value: 0.04232614487409592 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 3.1633375687159984e-05, 'dropout': 0.2872115739944181, 'num_layers': 2, 'hidden_size': 106, 'conv_filters': 32}. Best is trial 41 with value: 0.038246456533670425.\n",
      "[I 2024-12-21 15:36:03,092] Trial 44 finished with value: 0.04763561487197876 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 3.384770576424767e-05, 'dropout': 0.2471945628456134, 'num_layers': 2, 'hidden_size': 105, 'conv_filters': 32}. Best is trial 41 with value: 0.038246456533670425.\n",
      "[I 2024-12-21 15:36:20,713] Trial 45 finished with value: 0.0733494907617569 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.00010169776872069978, 'dropout': 0.3039428306671735, 'num_layers': 2, 'hidden_size': 114, 'conv_filters': 32}. Best is trial 41 with value: 0.038246456533670425.\n",
      "[I 2024-12-21 15:36:36,302] Trial 46 finished with value: 0.07053462415933609 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.000354206537276444, 'dropout': 0.27388110256256715, 'num_layers': 2, 'hidden_size': 121, 'conv_filters': 32}. Best is trial 41 with value: 0.038246456533670425.\n",
      "[I 2024-12-21 15:37:05,128] Trial 47 finished with value: 0.21363972127437592 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.008216136882983087, 'dropout': 0.30301128665986143, 'num_layers': 2, 'hidden_size': 109, 'conv_filters': 32}. Best is trial 41 with value: 0.038246456533670425.\n",
      "[I 2024-12-21 15:37:25,184] Trial 48 finished with value: 0.03913312032818794 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 5.5279416154307606e-05, 'dropout': 0.34319566839416554, 'num_layers': 2, 'hidden_size': 102, 'conv_filters': 32}. Best is trial 41 with value: 0.038246456533670425.\n",
      "[I 2024-12-21 15:37:41,319] Trial 49 finished with value: 0.02999337948858738 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 4.9646901635836995e-05, 'dropout': 0.3591203614101314, 'num_layers': 2, 'hidden_size': 127, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:37:58,593] Trial 50 finished with value: 0.06534190475940704 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.00015577392530330663, 'dropout': 0.362565182120999, 'num_layers': 2, 'hidden_size': 126, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:38:23,330] Trial 51 finished with value: 0.082320936024189 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 5.6586216859042113e-05, 'dropout': 0.3375772830587239, 'num_layers': 2, 'hidden_size': 116, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:38:36,024] Trial 52 finished with value: 0.0964685007929802 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 5.056858934082852e-05, 'dropout': 0.336453153831087, 'num_layers': 2, 'hidden_size': 101, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:38:47,497] Trial 53 finished with value: 0.060840412974357605 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 7.718152262492208e-05, 'dropout': 0.3131993038802411, 'num_layers': 2, 'hidden_size': 117, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:39:02,908] Trial 54 finished with value: 0.033063795417547226 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 2.2219211315847753e-05, 'dropout': 0.3428086406511991, 'num_layers': 2, 'hidden_size': 88, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:39:16,484] Trial 55 finished with value: 0.035529475659132004 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 3.7857271493692294e-05, 'dropout': 0.34906672634181607, 'num_layers': 2, 'hidden_size': 90, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:39:28,874] Trial 56 finished with value: 0.06653662025928497 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 3.746408220714239e-05, 'dropout': 0.3497080639060562, 'num_layers': 2, 'hidden_size': 86, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:39:40,521] Trial 57 finished with value: 0.1460174173116684 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 8.525753322397133e-05, 'dropout': 0.3495390471922004, 'num_layers': 2, 'hidden_size': 94, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:39:57,626] Trial 58 finished with value: 0.09283832460641861 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 0.001288500051558836, 'dropout': 0.36369164725466513, 'num_layers': 2, 'hidden_size': 90, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:40:10,728] Trial 59 finished with value: 0.03658735007047653 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 2.1145602845749657e-05, 'dropout': 0.34473676971105816, 'num_layers': 2, 'hidden_size': 101, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:40:23,122] Trial 60 finished with value: 0.03945465758442879 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 2.069506443569733e-05, 'dropout': 0.39613366205271483, 'num_layers': 2, 'hidden_size': 83, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:40:34,897] Trial 61 finished with value: 0.035215653479099274 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 2.2197211359461662e-05, 'dropout': 0.34355476337184526, 'num_layers': 2, 'hidden_size': 100, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:40:46,184] Trial 62 finished with value: 0.0359511524438858 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 2.3285659101566292e-05, 'dropout': 0.3442972677149421, 'num_layers': 2, 'hidden_size': 100, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:40:59,318] Trial 63 finished with value: 0.03756367787718773 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.78419347167681e-05, 'dropout': 0.3605577597509237, 'num_layers': 2, 'hidden_size': 96, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:41:18,561] Trial 64 finished with value: 0.06756303459405899 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.796262411994873e-05, 'dropout': 0.3591165048803337, 'num_layers': 2, 'hidden_size': 99, 'conv_filters': 64}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:41:29,009] Trial 65 finished with value: 0.03764594718813896 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.4406736955594916e-05, 'dropout': 0.3790884383723764, 'num_layers': 2, 'hidden_size': 97, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:41:39,806] Trial 66 finished with value: 0.03667713329195976 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 2.1341903351432247e-05, 'dropout': 0.3120597435591507, 'num_layers': 2, 'hidden_size': 89, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:41:50,899] Trial 67 finished with value: 0.0346713624894619 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 2.3036882092558956e-05, 'dropout': 0.3084857200567772, 'num_layers': 2, 'hidden_size': 90, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:42:02,772] Trial 68 finished with value: 0.03806789219379425 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 2.3410261122627743e-05, 'dropout': 0.3449470493018592, 'num_layers': 2, 'hidden_size': 82, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:42:20,123] Trial 69 finished with value: 0.04733959957957268 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 3.971832621700573e-05, 'dropout': 0.25796543781024467, 'num_layers': 2, 'hidden_size': 110, 'conv_filters': 64}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:42:30,783] Trial 70 finished with value: 0.03733080253005028 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.411531799262989e-05, 'dropout': 0.37157528233064907, 'num_layers': 2, 'hidden_size': 87, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:42:42,184] Trial 71 finished with value: 0.03872332349419594 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 2.17639968718328e-05, 'dropout': 0.309638150321383, 'num_layers': 2, 'hidden_size': 87, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:42:59,762] Trial 72 finished with value: 0.04293297231197357 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 2.569212742670807e-05, 'dropout': 0.3144529575738202, 'num_layers': 2, 'hidden_size': 103, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:43:12,070] Trial 73 finished with value: 0.042417287826538086 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.6505288467933363e-05, 'dropout': 0.29081841348734155, 'num_layers': 2, 'hidden_size': 91, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:43:25,036] Trial 74 finished with value: 0.03602072596549988 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 1.2752160073611653e-05, 'dropout': 0.29587956969013096, 'num_layers': 2, 'hidden_size': 84, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:43:36,197] Trial 75 finished with value: 0.039424896240234375 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 1.2540287551919293e-05, 'dropout': 0.27038960293400255, 'num_layers': 2, 'hidden_size': 79, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:43:46,974] Trial 76 finished with value: 0.0369277149438858 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 1.2842303976558314e-05, 'dropout': 0.29560937587770186, 'num_layers': 2, 'hidden_size': 70, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:44:01,632] Trial 77 finished with value: 0.08749415725469589 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.0006525351211327702, 'dropout': 0.38992250191095246, 'num_layers': 2, 'hidden_size': 84, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:44:14,030] Trial 78 finished with value: 0.05077004060149193 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 4.308420249181364e-05, 'dropout': 0.21344987827464493, 'num_layers': 2, 'hidden_size': 100, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:44:29,771] Trial 79 finished with value: 0.1236671507358551 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 3.452660979144e-05, 'dropout': 0.3278157594222081, 'num_layers': 2, 'hidden_size': 95, 'conv_filters': 64}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:44:42,389] Trial 80 finished with value: 0.07506204396486282 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.003510502917739367, 'dropout': 0.3499633067550368, 'num_layers': 2, 'hidden_size': 92, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:44:54,253] Trial 81 finished with value: 0.03653465211391449 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 2.320296667563712e-05, 'dropout': 0.3176499283685769, 'num_layers': 2, 'hidden_size': 89, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:45:08,290] Trial 82 finished with value: 0.040119487792253494 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 2.5668868755634843e-05, 'dropout': 0.3305307581406603, 'num_layers': 2, 'hidden_size': 104, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:45:19,550] Trial 83 finished with value: 0.03853173181414604 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.728193878391189e-05, 'dropout': 0.34164347245741983, 'num_layers': 2, 'hidden_size': 81, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:45:30,933] Trial 84 finished with value: 0.030063243582844734 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 3.155415903988862e-05, 'dropout': 0.3199224821070003, 'num_layers': 2, 'hidden_size': 78, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:45:43,003] Trial 85 finished with value: 0.057088661938905716 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 3.1246879831254793e-05, 'dropout': 0.3168897918693863, 'num_layers': 2, 'hidden_size': 75, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:45:56,210] Trial 86 finished with value: 0.07001470774412155 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 4.7606309667517335e-05, 'dropout': 0.3057049571896655, 'num_layers': 2, 'hidden_size': 78, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:46:13,431] Trial 87 finished with value: 0.10009875148534775 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 6.209241402372938e-05, 'dropout': 0.3188866250181067, 'num_layers': 2, 'hidden_size': 85, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:46:25,179] Trial 88 finished with value: 0.03824317827820778 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 1.2275024067569655e-05, 'dropout': 0.29467846896050043, 'num_layers': 2, 'hidden_size': 69, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:46:38,139] Trial 89 finished with value: 0.04886353760957718 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.00012125572528067738, 'dropout': 0.2861476440932025, 'num_layers': 2, 'hidden_size': 88, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:46:50,740] Trial 90 finished with value: 0.05004667118191719 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 3.8105564643988184e-05, 'dropout': 0.3546035695687633, 'num_layers': 2, 'hidden_size': 72, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:47:03,875] Trial 91 finished with value: 0.03892926126718521 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 2.2964634927009866e-05, 'dropout': 0.3405137534896585, 'num_layers': 2, 'hidden_size': 92, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:47:14,756] Trial 92 finished with value: 0.0503324419260025 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.54981803358738e-05, 'dropout': 0.3685015426493271, 'num_layers': 2, 'hidden_size': 16, 'conv_filters': 32}. Best is trial 49 with value: 0.02999337948858738.\n",
      "[I 2024-12-21 15:47:24,975] Trial 93 finished with value: 0.029756812378764153 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 2.8671271055399792e-05, 'dropout': 0.32992177876448014, 'num_layers': 2, 'hidden_size': 111, 'conv_filters': 32}. Best is trial 93 with value: 0.029756812378764153.\n",
      "[I 2024-12-21 15:47:34,705] Trial 94 finished with value: 0.034832846373319626 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 2.9942219326568885e-05, 'dropout': 0.3313281663007307, 'num_layers': 2, 'hidden_size': 111, 'conv_filters': 32}. Best is trial 93 with value: 0.029756812378764153.\n",
      "[I 2024-12-21 15:47:46,848] Trial 95 finished with value: 0.0381135493516922 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 3.268357247857775e-05, 'dropout': 0.3306271060670417, 'num_layers': 2, 'hidden_size': 124, 'conv_filters': 32}. Best is trial 93 with value: 0.029756812378764153.\n",
      "[I 2024-12-21 15:47:59,101] Trial 96 finished with value: 0.0410967692732811 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 2.5628076386741512e-05, 'dropout': 0.37986469720679295, 'num_layers': 2, 'hidden_size': 114, 'conv_filters': 32}. Best is trial 93 with value: 0.029756812378764153.\n",
      "[I 2024-12-21 15:48:10,012] Trial 97 finished with value: 0.037481751292943954 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 2.8683192977301547e-05, 'dropout': 0.35573061290869906, 'num_layers': 2, 'hidden_size': 111, 'conv_filters': 32}. Best is trial 93 with value: 0.029756812378764153.\n",
      "[I 2024-12-21 15:48:24,203] Trial 98 finished with value: 0.052125319838523865 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 5.332117316701901e-05, 'dropout': 0.32575618711315385, 'num_layers': 2, 'hidden_size': 98, 'conv_filters': 64}. Best is trial 93 with value: 0.029756812378764153.\n",
      "[I 2024-12-21 15:48:36,077] Trial 99 finished with value: 0.09134036302566528 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 7.036656343505855e-05, 'dropout': 0.306930649220492, 'num_layers': 2, 'hidden_size': 124, 'conv_filters': 32}. Best is trial 93 with value: 0.029756812378764153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-GRU_window_7_look_forward_1_close_price_target saved to ..\\data\\models\\CNN-GRU_window_7_look_forward_1_close_price_target\\CNN-GRU_window_7_look_forward_1_close_price_target_study.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [2:04:16<00:00, 1864.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved to ..\\data\\models\\CNN-GRU_window_7_look_forward_1_close_price_target\n",
      "Saved to ..\\data\\models\\CNN-GRU_window_7_look_forward_1_close_price_target:\n",
      "Best hyperparameters for CNN-GRU, window size: 7, look forward: 1, target close_price_target: {'epochs': 15, 'batch_size': 32, 'learning_rate': 2.8671271055399792e-05, 'dropout': 0.32992177876448014, 'num_layers': 2, 'hidden_size': 111, 'conv_filters': 32}\n",
      "Best trial index: 93, Best trial value: 0.029756812378764153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s][I 2024-12-21 15:48:46,093] A new study created in memory with name: LSTM_window_7_look_forward_1_open_price_target\n",
      "[I 2024-12-21 15:50:41,242] Trial 0 finished with value: 0.0717935562133789 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 0.001916433265706, 'dropout': 0.4836628676253678, 'num_layers': 2, 'hidden_size': 122}. Best is trial 0 with value: 0.0717935562133789.\n",
      "[I 2024-12-21 15:50:56,442] Trial 1 finished with value: 0.08865353465080261 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.0006346076330489722, 'dropout': 0.3361913558692802, 'num_layers': 2, 'hidden_size': 72}. Best is trial 0 with value: 0.0717935562133789.\n",
      "[I 2024-12-21 15:51:16,428] Trial 2 finished with value: 0.058248840272426605 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 2.192766091090895e-05, 'dropout': 0.2772356905654953, 'num_layers': 2, 'hidden_size': 72}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 15:51:25,858] Trial 3 finished with value: 0.09227871149778366 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 6.204974151513017e-05, 'dropout': 0.3903548079651218, 'num_layers': 3, 'hidden_size': 45}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 15:51:45,406] Trial 4 finished with value: 0.07555440813302994 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 0.008067284123274863, 'dropout': 0.4970214737472405, 'num_layers': 2, 'hidden_size': 80}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 15:51:58,042] Trial 5 finished with value: 0.09157844632863998 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 1.8723027695995203e-05, 'dropout': 0.26316452505408977, 'num_layers': 2, 'hidden_size': 99}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 15:52:13,129] Trial 6 finished with value: 0.09348119795322418 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 5.526423059066492e-05, 'dropout': 0.2083408013336313, 'num_layers': 2, 'hidden_size': 22}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 15:52:27,416] Trial 7 finished with value: 0.09763840585947037 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 2.5397474377389083e-05, 'dropout': 0.3483489767952041, 'num_layers': 2, 'hidden_size': 56}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 15:52:34,542] Trial 8 finished with value: 0.0980689600110054 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 3.979750534422858e-05, 'dropout': 0.20070870227491197, 'num_layers': 2, 'hidden_size': 31}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 15:52:54,496] Trial 9 finished with value: 0.08648381382226944 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 0.00012281341596168853, 'dropout': 0.24999154789840122, 'num_layers': 3, 'hidden_size': 66}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 15:53:32,543] Trial 10 finished with value: 0.08890624344348907 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 1.0748897189698024e-05, 'dropout': 0.29361111614270263, 'num_layers': 3, 'hidden_size': 100}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 15:53:54,171] Trial 11 finished with value: 0.10540217161178589 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 0.0010383295171433272, 'dropout': 0.49626464516380353, 'num_layers': 2, 'hidden_size': 127}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 15:58:43,558] Trial 12 finished with value: 0.07280027866363525 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.0026029546988859515, 'dropout': 0.3969381442196118, 'num_layers': 2, 'hidden_size': 123}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 15:58:54,517] Trial 13 finished with value: 0.07351173460483551 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 0.00024959941847245773, 'dropout': 0.44309584039872035, 'num_layers': 2, 'hidden_size': 96}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:02:51,001] Trial 14 finished with value: 0.07699325680732727 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.0030307936031824345, 'dropout': 0.3039049420993991, 'num_layers': 3, 'hidden_size': 85}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:03:05,597] Trial 15 finished with value: 0.07343965023756027 and parameters: {'epochs': 12, 'batch_size': 64, 'learning_rate': 0.0003510908210265302, 'dropout': 0.4419374667641832, 'num_layers': 2, 'hidden_size': 114}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:03:31,873] Trial 16 finished with value: 0.07283394783735275 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 0.0016278821863105553, 'dropout': 0.39407636994212386, 'num_layers': 2, 'hidden_size': 45}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:04:10,262] Trial 17 finished with value: 0.0725160762667656 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.009655372273385998, 'dropout': 0.25117423858365556, 'num_layers': 3, 'hidden_size': 110}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:04:27,842] Trial 18 finished with value: 0.0753941684961319 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.0001292139538292876, 'dropout': 0.31375962780508865, 'num_layers': 2, 'hidden_size': 59}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:04:36,910] Trial 19 finished with value: 0.07768276333808899 and parameters: {'epochs': 12, 'batch_size': 64, 'learning_rate': 0.00048633416015193224, 'dropout': 0.4540425645196077, 'num_layers': 2, 'hidden_size': 83}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:04:48,716] Trial 20 finished with value: 0.0933273658156395 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 0.00016823319167738024, 'dropout': 0.3661739101370609, 'num_layers': 3, 'hidden_size': 90}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:05:48,697] Trial 21 finished with value: 0.12428529560565948 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.007814997357664907, 'dropout': 0.24156723465683425, 'num_layers': 3, 'hidden_size': 111}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:07:14,419] Trial 22 finished with value: 0.08007250726222992 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.005010836381822608, 'dropout': 0.27272878358500585, 'num_layers': 3, 'hidden_size': 111}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:07:38,258] Trial 23 finished with value: 0.13909003138542175 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.0011018878935374107, 'dropout': 0.22751092248646287, 'num_layers': 3, 'hidden_size': 117}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:09:28,761] Trial 24 finished with value: 0.07378694415092468 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 0.0046496060491337645, 'dropout': 0.2729758605942106, 'num_layers': 3, 'hidden_size': 103}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:11:51,235] Trial 25 finished with value: 0.08408603817224503 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.0019198967210159222, 'dropout': 0.3207056116668878, 'num_layers': 2, 'hidden_size': 128}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:12:16,979] Trial 26 finished with value: 0.07580068707466125 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.009962385697840198, 'dropout': 0.28694616749365737, 'num_layers': 3, 'hidden_size': 73}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:14:41,430] Trial 27 finished with value: 0.07514683902263641 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 0.00415261471829486, 'dropout': 0.22871323245085332, 'num_layers': 2, 'hidden_size': 106}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:14:55,062] Trial 28 finished with value: 0.14161013066768646 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 0.0007381055782347517, 'dropout': 0.4221237439212536, 'num_layers': 3, 'hidden_size': 120}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:15:29,243] Trial 29 finished with value: 0.11805722117424011 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.001495804070433442, 'dropout': 0.3657073611382905, 'num_layers': 2, 'hidden_size': 74}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:15:41,459] Trial 30 finished with value: 0.0839059129357338 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 1.0062654812511149e-05, 'dropout': 0.472205634509905, 'num_layers': 2, 'hidden_size': 91}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:20:32,341] Trial 31 finished with value: 0.07402929663658142 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.0026003607762419153, 'dropout': 0.3320978997489738, 'num_layers': 2, 'hidden_size': 122}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:25:12,953] Trial 32 finished with value: 0.07378754764795303 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.0030024016303364905, 'dropout': 0.3917912750038062, 'num_layers': 2, 'hidden_size': 108}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:26:31,244] Trial 33 finished with value: 0.07664226740598679 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.0059715189295683315, 'dropout': 0.416420540882162, 'num_layers': 2, 'hidden_size': 124}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:29:45,532] Trial 34 finished with value: 0.09039643406867981 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.0021045125791227717, 'dropout': 0.3691735436047249, 'num_layers': 2, 'hidden_size': 117}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:30:00,205] Trial 35 finished with value: 0.14961743354797363 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 0.0007950722861485028, 'dropout': 0.4140550093564894, 'num_layers': 2, 'hidden_size': 62}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:30:10,188] Trial 36 finished with value: 0.08110613375902176 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 0.0004967491419973134, 'dropout': 0.46765332279357025, 'num_layers': 2, 'hidden_size': 46}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:30:25,035] Trial 37 finished with value: 0.08238573372364044 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 9.209874825864624e-05, 'dropout': 0.2504556225726727, 'num_layers': 2, 'hidden_size': 53}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:31:14,430] Trial 38 finished with value: 0.07532884925603867 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 0.007297322988159814, 'dropout': 0.3436515062792482, 'num_layers': 2, 'hidden_size': 78}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:31:31,903] Trial 39 finished with value: 0.07223717868328094 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 2.38885031361067e-05, 'dropout': 0.22133591412377815, 'num_layers': 2, 'hidden_size': 68}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:31:55,736] Trial 40 finished with value: 0.08094368875026703 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 3.3681614425339354e-05, 'dropout': 0.21478906304020773, 'num_layers': 3, 'hidden_size': 66}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:32:16,504] Trial 41 finished with value: 0.0758509561419487 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 1.8174208130323315e-05, 'dropout': 0.2632947922285544, 'num_layers': 2, 'hidden_size': 68}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:32:38,273] Trial 42 finished with value: 0.07777494937181473 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 5.918801788942183e-05, 'dropout': 0.22129179515036795, 'num_layers': 2, 'hidden_size': 95}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:32:51,290] Trial 43 finished with value: 0.10854978114366531 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 1.5434572756165383e-05, 'dropout': 0.24244369959783696, 'num_layers': 2, 'hidden_size': 36}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:33:12,487] Trial 44 finished with value: 0.10013964027166367 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 3.957227665566107e-05, 'dropout': 0.20110393605921595, 'num_layers': 2, 'hidden_size': 76}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:33:42,696] Trial 45 finished with value: 0.06147731840610504 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 2.7179847282731313e-05, 'dropout': 0.4929270089013188, 'num_layers': 2, 'hidden_size': 123}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:33:52,168] Trial 46 finished with value: 0.06946808099746704 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 2.6857059984194495e-05, 'dropout': 0.4816133383483864, 'num_layers': 2, 'hidden_size': 52}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:34:03,085] Trial 47 finished with value: 0.06961021572351456 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 2.7946513170540787e-05, 'dropout': 0.49886799119015873, 'num_layers': 2, 'hidden_size': 51}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:34:09,827] Trial 48 finished with value: 0.06929412484169006 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 7.724756038539798e-05, 'dropout': 0.4960493689720428, 'num_layers': 2, 'hidden_size': 35}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:34:14,464] Trial 49 finished with value: 0.07218769192695618 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 2.7861011388405128e-05, 'dropout': 0.4996764881509642, 'num_layers': 2, 'hidden_size': 16}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:34:22,717] Trial 50 finished with value: 0.12805286049842834 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 1.3840266679822752e-05, 'dropout': 0.48412884362319253, 'num_layers': 2, 'hidden_size': 34}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:34:33,301] Trial 51 finished with value: 0.0735301747918129 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 4.6033679513353834e-05, 'dropout': 0.48714578756850874, 'num_layers': 2, 'hidden_size': 51}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:34:38,768] Trial 52 finished with value: 0.10725981742143631 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 2.5465868108301103e-05, 'dropout': 0.47048230952222897, 'num_layers': 2, 'hidden_size': 27}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:34:46,583] Trial 53 finished with value: 0.09562318027019501 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 7.199436461232295e-05, 'dropout': 0.456568139420483, 'num_layers': 2, 'hidden_size': 39}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:35:01,571] Trial 54 finished with value: 0.09632015228271484 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 2.008333032912901e-05, 'dropout': 0.4848268023955776, 'num_layers': 2, 'hidden_size': 41}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:35:10,986] Trial 55 finished with value: 0.08410381525754929 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 7.284968731301509e-05, 'dropout': 0.44472360295815994, 'num_layers': 2, 'hidden_size': 49}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:35:20,912] Trial 56 finished with value: 0.08641092479228973 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 0.0002279703901319325, 'dropout': 0.4932225296274486, 'num_layers': 2, 'hidden_size': 57}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:35:28,333] Trial 57 finished with value: 0.134173184633255 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 3.2316906335809836e-05, 'dropout': 0.4775904536049102, 'num_layers': 2, 'hidden_size': 25}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:35:40,499] Trial 58 finished with value: 0.06721056997776031 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 4.821764664473173e-05, 'dropout': 0.4589080702598522, 'num_layers': 2, 'hidden_size': 61}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:35:49,679] Trial 59 finished with value: 0.08277681469917297 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 4.6238562708807366e-05, 'dropout': 0.46022321057459803, 'num_layers': 2, 'hidden_size': 61}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:36:02,122] Trial 60 finished with value: 0.07988090068101883 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 1.2565197374537694e-05, 'dropout': 0.4305011024798224, 'num_layers': 2, 'hidden_size': 55}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:36:15,934] Trial 61 finished with value: 0.0690452978014946 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 9.802565368096598e-05, 'dropout': 0.497749075027203, 'num_layers': 2, 'hidden_size': 63}. Best is trial 2 with value: 0.058248840272426605.\n",
      "[I 2024-12-21 16:36:32,242] Trial 62 finished with value: 0.045915767550468445 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 7.680859897112594e-05, 'dropout': 0.49284058818429594, 'num_layers': 2, 'hidden_size': 82}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:36:44,396] Trial 63 finished with value: 0.10170012712478638 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 0.00010882292877386024, 'dropout': 0.47800660390305755, 'num_layers': 2, 'hidden_size': 70}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:36:59,429] Trial 64 finished with value: 0.057011380791664124 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.0001793333939172086, 'dropout': 0.46129507730858804, 'num_layers': 2, 'hidden_size': 82}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:37:14,807] Trial 65 finished with value: 0.10700144618749619 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.00015850998044241745, 'dropout': 0.461552906951437, 'num_layers': 2, 'hidden_size': 85}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:37:28,636] Trial 66 finished with value: 0.08221768587827682 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 9.029970659963587e-05, 'dropout': 0.4479375292723216, 'num_layers': 2, 'hidden_size': 80}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:37:44,956] Trial 67 finished with value: 0.06862836331129074 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.00020508658582560577, 'dropout': 0.4361418229052606, 'num_layers': 2, 'hidden_size': 89}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:38:07,842] Trial 68 finished with value: 0.11924048513174057 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.00026751858128538816, 'dropout': 0.43252271101462164, 'num_layers': 2, 'hidden_size': 88}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:38:21,242] Trial 69 finished with value: 0.08116810023784637 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 0.0001314366105795928, 'dropout': 0.401853226630876, 'num_layers': 2, 'hidden_size': 64}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:38:40,547] Trial 70 finished with value: 0.07993216812610626 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 0.0001863633827713648, 'dropout': 0.4343224609234483, 'num_layers': 2, 'hidden_size': 93}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:38:56,328] Trial 71 finished with value: 0.08132341504096985 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.00035391047355975557, 'dropout': 0.4916846225769774, 'num_layers': 2, 'hidden_size': 82}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:39:16,800] Trial 72 finished with value: 0.08082063496112823 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 7.364262561877113e-05, 'dropout': 0.47257302363519976, 'num_layers': 2, 'hidden_size': 97}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:39:32,537] Trial 73 finished with value: 0.08168420940637589 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 9.794464568656626e-05, 'dropout': 0.46220090476223247, 'num_layers': 2, 'hidden_size': 74}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:39:47,734] Trial 74 finished with value: 0.05358777567744255 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 5.0980924779200066e-05, 'dropout': 0.45325908045947594, 'num_layers': 2, 'hidden_size': 88}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:40:10,701] Trial 75 finished with value: 0.06202743202447891 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 4.910457893144577e-05, 'dropout': 0.4526660151889728, 'num_layers': 2, 'hidden_size': 102}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:40:31,077] Trial 76 finished with value: 0.0660928338766098 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 5.0323292666521415e-05, 'dropout': 0.45118478973626686, 'num_layers': 2, 'hidden_size': 101}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:40:47,858] Trial 77 finished with value: 0.07378792017698288 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 4.265962223909543e-05, 'dropout': 0.4478733320700669, 'num_layers': 2, 'hidden_size': 100}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:41:13,137] Trial 78 finished with value: 0.07730911672115326 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 5.030909196584389e-05, 'dropout': 0.3774852920927555, 'num_layers': 2, 'hidden_size': 84}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:41:35,628] Trial 79 finished with value: 0.09052630513906479 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 6.183365516503961e-05, 'dropout': 0.4265630145411173, 'num_layers': 2, 'hidden_size': 104}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:41:57,048] Trial 80 finished with value: 0.063379667699337 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 3.743015097119434e-05, 'dropout': 0.4539591920948949, 'num_layers': 2, 'hidden_size': 101}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:42:20,509] Trial 81 finished with value: 0.07121499627828598 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 3.582497003012865e-05, 'dropout': 0.45185907120412705, 'num_layers': 2, 'hidden_size': 102}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:42:39,045] Trial 82 finished with value: 0.06559652090072632 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 5.48071276191437e-05, 'dropout': 0.413061170590859, 'num_layers': 2, 'hidden_size': 87}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:42:56,837] Trial 83 finished with value: 0.09290189296007156 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 1.9912086916318654e-05, 'dropout': 0.41504996051650006, 'num_layers': 2, 'hidden_size': 86}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:43:18,968] Trial 84 finished with value: 0.06169780343770981 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 5.823850663424581e-05, 'dropout': 0.4047817261999045, 'num_layers': 2, 'hidden_size': 93}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:43:37,191] Trial 85 finished with value: 0.08031248301267624 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 3.490068139140284e-05, 'dropout': 0.40868270660631145, 'num_layers': 2, 'hidden_size': 94}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:43:52,727] Trial 86 finished with value: 0.06914367526769638 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 5.729330809687129e-05, 'dropout': 0.3556756651398547, 'num_layers': 2, 'hidden_size': 80}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:44:19,227] Trial 87 finished with value: 0.07133205235004425 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 2.1748682960347468e-05, 'dropout': 0.38712521816338613, 'num_layers': 2, 'hidden_size': 98}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:44:41,467] Trial 88 finished with value: 0.0545584000647068 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 3.0620623087211596e-05, 'dropout': 0.2987975918926754, 'num_layers': 2, 'hidden_size': 92}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:45:08,036] Trial 89 finished with value: 0.06429905444383621 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.6160409008139275e-05, 'dropout': 0.2909314500945545, 'num_layers': 2, 'hidden_size': 108}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:45:31,319] Trial 90 finished with value: 0.06879337131977081 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 3.219589489408079e-05, 'dropout': 0.2803527519639639, 'num_layers': 2, 'hidden_size': 92}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:45:54,817] Trial 91 finished with value: 0.07204611599445343 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.573636230030868e-05, 'dropout': 0.3012802355502203, 'num_layers': 2, 'hidden_size': 113}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:46:23,537] Trial 92 finished with value: 0.08370020240545273 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.700313561613701e-05, 'dropout': 0.32357398434023543, 'num_layers': 2, 'hidden_size': 106}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:46:47,225] Trial 93 finished with value: 0.08204302936792374 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.262203596985043e-05, 'dropout': 0.26727113237079675, 'num_layers': 2, 'hidden_size': 109}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:47:06,669] Trial 94 finished with value: 0.08060135692358017 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.1619325405527162e-05, 'dropout': 0.2947614944554974, 'num_layers': 2, 'hidden_size': 90}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:47:32,361] Trial 95 finished with value: 0.054904695600271225 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 3.9651735932701284e-05, 'dropout': 0.28288519891597275, 'num_layers': 2, 'hidden_size': 97}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:47:50,058] Trial 96 finished with value: 0.09299886226654053 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 3.8635158162409485e-05, 'dropout': 0.27935422854420683, 'num_layers': 2, 'hidden_size': 76}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:48:14,701] Trial 97 finished with value: 0.06793664395809174 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 3.061781443724188e-05, 'dropout': 0.46821059881640675, 'num_layers': 2, 'hidden_size': 96}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:48:34,960] Trial 98 finished with value: 0.08685173839330673 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 4.12265555121389e-05, 'dropout': 0.2576369032023568, 'num_layers': 2, 'hidden_size': 82}. Best is trial 62 with value: 0.045915767550468445.\n",
      "[I 2024-12-21 16:49:05,673] Trial 99 finished with value: 0.07600268721580505 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 6.86748612645351e-05, 'dropout': 0.3088359887229736, 'num_layers': 2, 'hidden_size': 117}. Best is trial 62 with value: 0.045915767550468445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_window_7_look_forward_1_open_price_target saved to ..\\data\\models\\LSTM_window_7_look_forward_1_open_price_target\\LSTM_window_7_look_forward_1_open_price_target_study.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [1:00:23<3:01:09, 3623.17s/it][I 2024-12-21 16:49:09,268] A new study created in memory with name: GRU_window_7_look_forward_1_open_price_target\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved to ..\\data\\models\\LSTM_window_7_look_forward_1_open_price_target\n",
      "Saved to ..\\data\\models\\LSTM_window_7_look_forward_1_open_price_target:\n",
      "Best hyperparameters for LSTM, window size: 7, look forward: 1, target open_price_target: {'epochs': 13, 'batch_size': 32, 'learning_rate': 7.680859897112594e-05, 'dropout': 0.49284058818429594, 'num_layers': 2, 'hidden_size': 82}\n",
      "Best trial index: 62, Best trial value: 0.045915767550468445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 16:49:19,318] Trial 0 finished with value: 0.05993909016251564 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 9.841639321129039e-05, 'dropout': 0.4657302716459322, 'num_layers': 2, 'hidden_size': 80}. Best is trial 0 with value: 0.05993909016251564.\n",
      "[I 2024-12-21 16:49:28,416] Trial 1 finished with value: 0.06237035617232323 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 3.14711966510697e-05, 'dropout': 0.4741145883937968, 'num_layers': 2, 'hidden_size': 84}. Best is trial 0 with value: 0.05993909016251564.\n",
      "[I 2024-12-21 16:49:37,770] Trial 2 finished with value: 0.11055473983287811 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.0006114904883380934, 'dropout': 0.31576970102590163, 'num_layers': 2, 'hidden_size': 54}. Best is trial 0 with value: 0.05993909016251564.\n",
      "[I 2024-12-21 16:49:43,293] Trial 3 finished with value: 0.09643345326185226 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 1.608419041240967e-05, 'dropout': 0.37717485131104833, 'num_layers': 3, 'hidden_size': 41}. Best is trial 0 with value: 0.05993909016251564.\n",
      "[I 2024-12-21 16:49:49,890] Trial 4 finished with value: 0.07335282117128372 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 2.9402741110235396e-05, 'dropout': 0.3316261461760354, 'num_layers': 2, 'hidden_size': 57}. Best is trial 0 with value: 0.05993909016251564.\n",
      "[I 2024-12-21 16:49:56,323] Trial 5 finished with value: 0.04380938783288002 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 1.7125651253597257e-05, 'dropout': 0.4064325450038956, 'num_layers': 2, 'hidden_size': 41}. Best is trial 5 with value: 0.04380938783288002.\n",
      "[I 2024-12-21 16:50:10,168] Trial 6 finished with value: 0.09595178067684174 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.004381629275349469, 'dropout': 0.310190880671226, 'num_layers': 3, 'hidden_size': 90}. Best is trial 5 with value: 0.04380938783288002.\n",
      "[I 2024-12-21 16:50:28,651] Trial 7 finished with value: 0.07646946609020233 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 0.0032033516358583717, 'dropout': 0.2218393049496101, 'num_layers': 3, 'hidden_size': 119}. Best is trial 5 with value: 0.04380938783288002.\n",
      "[I 2024-12-21 16:50:36,922] Trial 8 finished with value: 0.07858935743570328 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 0.0003245169652702923, 'dropout': 0.21847577367026982, 'num_layers': 2, 'hidden_size': 103}. Best is trial 5 with value: 0.04380938783288002.\n",
      "[I 2024-12-21 16:50:47,944] Trial 9 finished with value: 0.10910993069410324 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.0011221851606306426, 'dropout': 0.33241326568136653, 'num_layers': 2, 'hidden_size': 103}. Best is trial 5 with value: 0.04380938783288002.\n",
      "[I 2024-12-21 16:50:55,431] Trial 10 finished with value: 0.03939078003168106 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.00012268981962045193, 'dropout': 0.40755288185875466, 'num_layers': 3, 'hidden_size': 23}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:51:02,015] Trial 11 finished with value: 0.04636773094534874 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.00013384891703131424, 'dropout': 0.42491614632480745, 'num_layers': 3, 'hidden_size': 16}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:51:07,138] Trial 12 finished with value: 0.07121241092681885 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 7.753449873234804e-05, 'dropout': 0.42143484245360857, 'num_layers': 3, 'hidden_size': 16}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:51:15,002] Trial 13 finished with value: 0.1307741403579712 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 1.0154820164215271e-05, 'dropout': 0.3866027749516847, 'num_layers': 3, 'hidden_size': 35}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:51:22,522] Trial 14 finished with value: 0.07636844366788864 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 3.820402129030461e-05, 'dropout': 0.4256091224663594, 'num_layers': 2, 'hidden_size': 37}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:51:31,219] Trial 15 finished with value: 0.0651472732424736 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 0.0002166091828461877, 'dropout': 0.2729929362445396, 'num_layers': 3, 'hidden_size': 62}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:51:36,218] Trial 16 finished with value: 0.07165424525737762 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 5.254982332469469e-05, 'dropout': 0.37647200456080143, 'num_layers': 3, 'hidden_size': 31}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:51:42,933] Trial 17 finished with value: 0.0867009237408638 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.0010769651609645698, 'dropout': 0.49785203647103504, 'num_layers': 2, 'hidden_size': 48}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:51:48,156] Trial 18 finished with value: 0.13383762538433075 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 1.3417743020621206e-05, 'dropout': 0.39966562450972715, 'num_layers': 3, 'hidden_size': 26}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:51:58,259] Trial 19 finished with value: 0.1144193485379219 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 0.00023764762640551005, 'dropout': 0.4507335715659848, 'num_layers': 2, 'hidden_size': 66}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:52:03,974] Trial 20 finished with value: 0.07805022597312927 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 2.158556882799453e-05, 'dropout': 0.3620195545763666, 'num_layers': 2, 'hidden_size': 25}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:52:09,705] Trial 21 finished with value: 0.06630866229534149 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.00015062767108718183, 'dropout': 0.41683198645017344, 'num_layers': 3, 'hidden_size': 16}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:52:19,491] Trial 22 finished with value: 0.08620336651802063 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 9.176378796022389e-05, 'dropout': 0.4446730768669683, 'num_layers': 3, 'hidden_size': 46}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:52:26,421] Trial 23 finished with value: 0.07294495403766632 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.009705713775244427, 'dropout': 0.4064824655199916, 'num_layers': 3, 'hidden_size': 23}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:52:34,142] Trial 24 finished with value: 0.07902069389820099 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.0004197964345756304, 'dropout': 0.4390806918925944, 'num_layers': 3, 'hidden_size': 31}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:52:38,894] Trial 25 finished with value: 0.07686737179756165 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 5.679691164979092e-05, 'dropout': 0.3545163817421274, 'num_layers': 3, 'hidden_size': 17}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:52:46,599] Trial 26 finished with value: 0.04892388731241226 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.00011596089061806722, 'dropout': 0.4821667672052306, 'num_layers': 3, 'hidden_size': 45}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:52:52,165] Trial 27 finished with value: 0.09514296054840088 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.0007211763114001832, 'dropout': 0.39774002894888216, 'num_layers': 3, 'hidden_size': 26}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:53:06,496] Trial 28 finished with value: 0.09694889932870865 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.0001921680198088775, 'dropout': 0.2830383307017623, 'num_layers': 2, 'hidden_size': 70}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:53:14,372] Trial 29 finished with value: 0.09498835355043411 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 5.894210562028295e-05, 'dropout': 0.4622623244118227, 'num_layers': 3, 'hidden_size': 37}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:53:30,500] Trial 30 finished with value: 0.0856434553861618 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.0001309797820162541, 'dropout': 0.43119766288969597, 'num_layers': 2, 'hidden_size': 76}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:53:41,021] Trial 31 finished with value: 0.07187842577695847 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.000111797921443948, 'dropout': 0.4932001998002426, 'num_layers': 3, 'hidden_size': 52}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:53:48,497] Trial 32 finished with value: 0.08723681420087814 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.00035961419643131323, 'dropout': 0.4749015261952469, 'num_layers': 3, 'hidden_size': 41}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:53:55,470] Trial 33 finished with value: 0.08201546221971512 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 3.6225326732975785e-05, 'dropout': 0.4733893390315162, 'num_layers': 3, 'hidden_size': 30}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:54:04,860] Trial 34 finished with value: 0.06543391197919846 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 8.300947331255053e-05, 'dropout': 0.4565364558706901, 'num_layers': 3, 'hidden_size': 44}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:54:13,662] Trial 35 finished with value: 0.10532176494598389 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.0005151334450933033, 'dropout': 0.37242009166518325, 'num_layers': 3, 'hidden_size': 21}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:54:22,453] Trial 36 finished with value: 0.05005491152405739 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 2.155928651700792e-05, 'dropout': 0.4768294954278521, 'num_layers': 3, 'hidden_size': 52}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:54:29,948] Trial 37 finished with value: 0.09412840008735657 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 0.00017816861220284019, 'dropout': 0.4090967379041076, 'num_layers': 2, 'hidden_size': 60}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:54:44,875] Trial 38 finished with value: 0.05776391550898552 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 2.5887614526384902e-05, 'dropout': 0.3896112983140531, 'num_layers': 3, 'hidden_size': 86}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:54:50,301] Trial 39 finished with value: 0.09480775892734528 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 0.0009331232333212152, 'dropout': 0.4428983488441701, 'num_layers': 2, 'hidden_size': 40}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:54:58,513] Trial 40 finished with value: 0.0659307986497879 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 0.00025957462056641037, 'dropout': 0.329332757959052, 'num_layers': 3, 'hidden_size': 34}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:55:06,497] Trial 41 finished with value: 0.07659018039703369 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 1.403910546075521e-05, 'dropout': 0.4861801229152751, 'num_layers': 3, 'hidden_size': 52}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:55:15,608] Trial 42 finished with value: 0.05559122934937477 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 2.417982797644291e-05, 'dropout': 0.4693452401176988, 'num_layers': 3, 'hidden_size': 54}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:55:20,908] Trial 43 finished with value: 0.22885502874851227 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 1.8789419929281912e-05, 'dropout': 0.4781849520759578, 'num_layers': 3, 'hidden_size': 21}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:55:34,706] Trial 44 finished with value: 0.07518007606267929 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 4.522384271427769e-05, 'dropout': 0.4281988724614715, 'num_layers': 3, 'hidden_size': 123}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:55:41,304] Trial 45 finished with value: 0.07988860458135605 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 7.019176033986966e-05, 'dropout': 0.45880746620778273, 'num_layers': 3, 'hidden_size': 48}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:55:46,931] Trial 46 finished with value: 0.07488327473402023 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 3.447267240676208e-05, 'dropout': 0.41601221742231226, 'num_layers': 3, 'hidden_size': 29}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:55:53,514] Trial 47 finished with value: 0.05082881078124046 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 0.00010952738852431265, 'dropout': 0.4864265881108085, 'num_layers': 3, 'hidden_size': 58}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:55:59,270] Trial 48 finished with value: 0.08719341456890106 and parameters: {'epochs': 12, 'batch_size': 64, 'learning_rate': 1.6490795156989653e-05, 'dropout': 0.43634703775927275, 'num_layers': 2, 'hidden_size': 39}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:56:16,254] Trial 49 finished with value: 0.05212424695491791 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 1.0151409790993148e-05, 'dropout': 0.34242083887274777, 'num_layers': 3, 'hidden_size': 99}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:56:26,387] Trial 50 finished with value: 0.07053719460964203 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 4.251411595681626e-05, 'dropout': 0.38952186819389595, 'num_layers': 3, 'hidden_size': 65}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:56:37,188] Trial 51 finished with value: 0.07224205136299133 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 9.480549062967866e-05, 'dropout': 0.48736524696349226, 'num_layers': 3, 'hidden_size': 56}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:56:44,994] Trial 52 finished with value: 0.039874374866485596 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 0.00011996891279476934, 'dropout': 0.4993716435709439, 'num_layers': 3, 'hidden_size': 60}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:56:53,553] Trial 53 finished with value: 0.07376031577587128 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 0.0018404831365145876, 'dropout': 0.49708137375655426, 'num_layers': 3, 'hidden_size': 73}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:56:59,698] Trial 54 finished with value: 0.09077651798725128 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 0.00029306537427377117, 'dropout': 0.20146494272216034, 'num_layers': 3, 'hidden_size': 50}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:57:06,585] Trial 55 finished with value: 0.10418498516082764 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 0.0001638116455723038, 'dropout': 0.4464513269456339, 'num_layers': 3, 'hidden_size': 46}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:57:11,205] Trial 56 finished with value: 0.07416680455207825 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 0.0001196820111170032, 'dropout': 0.4663256926366155, 'num_layers': 3, 'hidden_size': 43}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:57:19,700] Trial 57 finished with value: 0.06106818467378616 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 7.215758860523558e-05, 'dropout': 0.3720383667063947, 'num_layers': 2, 'hidden_size': 63}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:57:23,593] Trial 58 finished with value: 0.08122681826353073 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 0.0002105214013120851, 'dropout': 0.453169396293513, 'num_layers': 3, 'hidden_size': 35}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:57:31,072] Trial 59 finished with value: 0.06862781196832657 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.00014102722963803938, 'dropout': 0.4799367324466837, 'num_layers': 3, 'hidden_size': 18}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:57:40,568] Trial 60 finished with value: 0.08232834190130234 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.00040991615743862824, 'dropout': 0.4254591041341908, 'num_layers': 2, 'hidden_size': 68}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:57:47,013] Trial 61 finished with value: 0.07297857105731964 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 0.00010589480202318429, 'dropout': 0.4847701098324597, 'num_layers': 3, 'hidden_size': 59}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:57:54,892] Trial 62 finished with value: 0.07348302006721497 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 6.136673291569781e-05, 'dropout': 0.49011227376496275, 'num_layers': 3, 'hidden_size': 59}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:58:02,396] Trial 63 finished with value: 0.07977313548326492 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 3.0146126748430964e-05, 'dropout': 0.49631195462627015, 'num_layers': 3, 'hidden_size': 27}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:58:11,770] Trial 64 finished with value: 0.05999321863055229 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 5.14369690925877e-05, 'dropout': 0.4633872557740912, 'num_layers': 3, 'hidden_size': 77}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:58:19,699] Trial 65 finished with value: 0.07333096861839294 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 0.00013814111248191307, 'dropout': 0.2994636743823225, 'num_layers': 3, 'hidden_size': 55}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:58:23,826] Trial 66 finished with value: 0.07637865841388702 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 8.565752611989285e-05, 'dropout': 0.40957894238409664, 'num_layers': 3, 'hidden_size': 33}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:58:34,041] Trial 67 finished with value: 0.06722316145896912 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.3494106053899732e-05, 'dropout': 0.24361137366860344, 'num_layers': 3, 'hidden_size': 48}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:58:40,075] Trial 68 finished with value: 0.07237093150615692 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.0002472469087894152, 'dropout': 0.46808893913425015, 'num_layers': 3, 'hidden_size': 24}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:58:50,337] Trial 69 finished with value: 0.08112308382987976 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.095056709381234e-05, 'dropout': 0.47715645675411283, 'num_layers': 3, 'hidden_size': 63}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:58:57,195] Trial 70 finished with value: 0.0816107988357544 and parameters: {'epochs': 12, 'batch_size': 64, 'learning_rate': 0.0005621957262080844, 'dropout': 0.4547343188921809, 'num_layers': 3, 'hidden_size': 51}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:59:14,059] Trial 71 finished with value: 0.06910110265016556 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 1.1758600168473636e-05, 'dropout': 0.3327883059464939, 'num_layers': 3, 'hidden_size': 98}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:59:28,068] Trial 72 finished with value: 0.06725067645311356 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 1.713955306231534e-05, 'dropout': 0.34475910495618833, 'num_layers': 3, 'hidden_size': 100}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 16:59:43,518] Trial 73 finished with value: 0.07350313663482666 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 1.0927587964465214e-05, 'dropout': 0.3169455470226785, 'num_layers': 3, 'hidden_size': 82}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:00:00,875] Trial 74 finished with value: 0.08472824841737747 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 1.0314815473361485e-05, 'dropout': 0.3987624112816331, 'num_layers': 3, 'hidden_size': 109}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:00:17,847] Trial 75 finished with value: 0.061937954276800156 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.0001850521968843185, 'dropout': 0.3644019880981906, 'num_layers': 3, 'hidden_size': 109}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:00:30,306] Trial 76 finished with value: 0.10125607997179031 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 2.6296893524870915e-05, 'dropout': 0.49965951302972694, 'num_layers': 3, 'hidden_size': 92}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:00:36,167] Trial 77 finished with value: 0.07264535129070282 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.00010911773020334807, 'dropout': 0.3488575872302946, 'num_layers': 3, 'hidden_size': 20}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:00:42,519] Trial 78 finished with value: 0.07916273921728134 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 1.5173262931042031e-05, 'dropout': 0.4340122706794061, 'num_layers': 2, 'hidden_size': 43}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:00:48,509] Trial 79 finished with value: 0.07786338031291962 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 4.357655918987638e-05, 'dropout': 0.42080296712391646, 'num_layers': 3, 'hidden_size': 37}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:01:08,785] Trial 80 finished with value: 0.05106654390692711 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.00032739862084044634, 'dropout': 0.4828921491632254, 'num_layers': 3, 'hidden_size': 128}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:01:26,598] Trial 81 finished with value: 0.12300805002450943 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.0007164126067631985, 'dropout': 0.3808711052975817, 'num_layers': 3, 'hidden_size': 120}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:01:39,071] Trial 82 finished with value: 0.08680706471204758 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.00031220870253490483, 'dropout': 0.4836629605808853, 'num_layers': 3, 'hidden_size': 89}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:01:53,957] Trial 83 finished with value: 0.06410855054855347 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.00016215402369754696, 'dropout': 0.48934544661517854, 'num_layers': 3, 'hidden_size': 125}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:02:11,975] Trial 84 finished with value: 0.11318528652191162 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.0004606078497492276, 'dropout': 0.448690713721787, 'num_layers': 3, 'hidden_size': 106}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:02:24,991] Trial 85 finished with value: 0.07494170218706131 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.00021751347600000267, 'dropout': 0.4720086725553359, 'num_layers': 3, 'hidden_size': 75}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:02:37,332] Trial 86 finished with value: 0.06375951319932938 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 2.0389411862304814e-05, 'dropout': 0.4619039943487989, 'num_layers': 3, 'hidden_size': 113}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:03:02,354] Trial 87 finished with value: 0.09032626450061798 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.00012359331005549353, 'dropout': 0.36222889140289194, 'num_layers': 3, 'hidden_size': 116}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:03:09,164] Trial 88 finished with value: 0.10282811522483826 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 0.00036861999022990045, 'dropout': 0.44163458551187007, 'num_layers': 2, 'hidden_size': 69}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:03:16,676] Trial 89 finished with value: 0.05467471480369568 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 6.637513941438718e-05, 'dropout': 0.47965396233668817, 'num_layers': 3, 'hidden_size': 16}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:03:22,380] Trial 90 finished with value: 0.09875465929508209 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 0.0016788426487042963, 'dropout': 0.4999023519842454, 'num_layers': 3, 'hidden_size': 58}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:03:30,429] Trial 91 finished with value: 0.0828772783279419 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 6.774913139206584e-05, 'dropout': 0.4803757294585464, 'num_layers': 3, 'hidden_size': 16}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:03:37,335] Trial 92 finished with value: 0.07885073125362396 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 0.0002764117202617907, 'dropout': 0.49251421722674066, 'num_layers': 3, 'hidden_size': 22}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:03:48,537] Trial 93 finished with value: 0.07297787815332413 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 9.012373038689696e-05, 'dropout': 0.47498088937191607, 'num_layers': 3, 'hidden_size': 54}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:03:56,931] Trial 94 finished with value: 0.13333235681056976 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.00015044975946902004, 'dropout': 0.33886805838469647, 'num_layers': 3, 'hidden_size': 18}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:04:08,545] Trial 95 finished with value: 0.041588399559259415 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 7.613878828129096e-05, 'dropout': 0.404870630430075, 'num_layers': 3, 'hidden_size': 46}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:04:21,556] Trial 96 finished with value: 0.04627472534775734 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 0.00010087015551095715, 'dropout': 0.3952482764372867, 'num_layers': 3, 'hidden_size': 49}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:04:33,816] Trial 97 finished with value: 0.08501508831977844 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 5.4410902577867876e-05, 'dropout': 0.39360164001869685, 'num_layers': 3, 'hidden_size': 46}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:04:43,544] Trial 98 finished with value: 0.07099427282810211 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.00010886216878714165, 'dropout': 0.4084576293119999, 'num_layers': 3, 'hidden_size': 50}. Best is trial 10 with value: 0.03939078003168106.\n",
      "[I 2024-12-21 17:04:49,350] Trial 99 finished with value: 0.06929836422204971 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 7.895048735221401e-05, 'dropout': 0.4054615907081105, 'num_layers': 3, 'hidden_size': 45}. Best is trial 10 with value: 0.03939078003168106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_window_7_look_forward_1_open_price_target saved to ..\\data\\models\\GRU_window_7_look_forward_1_open_price_target\\GRU_window_7_look_forward_1_open_price_target_study.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [1:16:06<1:08:13, 2046.68s/it][I 2024-12-21 17:04:52,405] A new study created in memory with name: CNN-LSTM_window_7_look_forward_1_open_price_target\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved to ..\\data\\models\\GRU_window_7_look_forward_1_open_price_target\n",
      "Saved to ..\\data\\models\\GRU_window_7_look_forward_1_open_price_target:\n",
      "Best hyperparameters for GRU, window size: 7, look forward: 1, target open_price_target: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.00012268981962045193, 'dropout': 0.40755288185875466, 'num_layers': 3, 'hidden_size': 23}\n",
      "Best trial index: 10, Best trial value: 0.03939078003168106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 17:05:05,851] Trial 0 finished with value: 0.09382019191980362 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 4.045228788447636e-05, 'dropout': 0.2903759884885443, 'num_layers': 2, 'hidden_size': 64, 'conv_filters': 32}. Best is trial 0 with value: 0.09382019191980362.\n",
      "[I 2024-12-21 17:05:19,529] Trial 1 finished with value: 0.06436359882354736 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.00037504809150905804, 'dropout': 0.21202200639010366, 'num_layers': 3, 'hidden_size': 92, 'conv_filters': 32}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:05:36,469] Trial 2 finished with value: 0.07663112133741379 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 0.007116853982086172, 'dropout': 0.355685204257902, 'num_layers': 3, 'hidden_size': 98, 'conv_filters': 32}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:05:53,123] Trial 3 finished with value: 0.07113802433013916 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.002028153228155441, 'dropout': 0.4309291072142597, 'num_layers': 3, 'hidden_size': 25, 'conv_filters': 32}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:06:22,282] Trial 4 finished with value: 0.07497036457061768 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 4.2064648956541604e-05, 'dropout': 0.29714323648651253, 'num_layers': 2, 'hidden_size': 54, 'conv_filters': 128}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:06:59,486] Trial 5 finished with value: 0.07322663068771362 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 0.0008939910685162735, 'dropout': 0.43475647661582134, 'num_layers': 2, 'hidden_size': 90, 'conv_filters': 128}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:07:16,885] Trial 6 finished with value: 0.08991069346666336 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 2.995036172304603e-05, 'dropout': 0.2592423200618064, 'num_layers': 3, 'hidden_size': 69, 'conv_filters': 128}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:07:42,779] Trial 7 finished with value: 0.11681676656007767 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.0004677213874909665, 'dropout': 0.23126389765837507, 'num_layers': 2, 'hidden_size': 21, 'conv_filters': 128}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:08:02,494] Trial 8 finished with value: 0.06526453793048859 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 4.757914157456474e-05, 'dropout': 0.49781654970895106, 'num_layers': 3, 'hidden_size': 123, 'conv_filters': 64}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:08:16,018] Trial 9 finished with value: 0.07663814723491669 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 0.004129371773288673, 'dropout': 0.29714291080885724, 'num_layers': 3, 'hidden_size': 58, 'conv_filters': 32}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:08:30,038] Trial 10 finished with value: 0.08082805573940277 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 0.00019080815666896162, 'dropout': 0.20064343275680052, 'num_layers': 3, 'hidden_size': 121, 'conv_filters': 64}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:08:46,025] Trial 11 finished with value: 0.06627050042152405 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.000134156660912931, 'dropout': 0.48678122846816474, 'num_layers': 3, 'hidden_size': 128, 'conv_filters': 64}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:09:10,975] Trial 12 finished with value: 0.07010779529809952 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 1.1515644150339511e-05, 'dropout': 0.3536324517727447, 'num_layers': 3, 'hidden_size': 103, 'conv_filters': 64}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:09:26,131] Trial 13 finished with value: 0.08061575144529343 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 0.00011382547946967275, 'dropout': 0.4081577103900719, 'num_layers': 3, 'hidden_size': 111, 'conv_filters': 64}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:09:37,125] Trial 14 finished with value: 0.11459925770759583 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.000615248250225611, 'dropout': 0.49019796165328144, 'num_layers': 3, 'hidden_size': 85, 'conv_filters': 32}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:09:46,384] Trial 15 finished with value: 0.08484453707933426 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 8.335424673489304e-05, 'dropout': 0.37933011964833296, 'num_layers': 3, 'hidden_size': 114, 'conv_filters': 64}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:10:04,311] Trial 16 finished with value: 0.1077871099114418 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 1.2235515761539645e-05, 'dropout': 0.32003753249591815, 'num_layers': 3, 'hidden_size': 82, 'conv_filters': 64}. Best is trial 1 with value: 0.06436359882354736.\n",
      "[I 2024-12-21 17:10:16,405] Trial 17 finished with value: 0.04401501268148422 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.0002637949326186407, 'dropout': 0.4527826252414749, 'num_layers': 2, 'hidden_size': 43, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:10:23,089] Trial 18 finished with value: 0.060665763914585114 and parameters: {'epochs': 12, 'batch_size': 64, 'learning_rate': 0.0013424476046430464, 'dropout': 0.39702286010138216, 'num_layers': 2, 'hidden_size': 43, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:10:29,961] Trial 19 finished with value: 0.12801134586334229 and parameters: {'epochs': 12, 'batch_size': 64, 'learning_rate': 0.0014065609473619695, 'dropout': 0.44560445661093634, 'num_layers': 2, 'hidden_size': 40, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:10:37,362] Trial 20 finished with value: 0.11224883049726486 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 0.002569740843287656, 'dropout': 0.4652717768106894, 'num_layers': 2, 'hidden_size': 40, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:10:46,796] Trial 21 finished with value: 0.07612121850252151 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.00023019879868219653, 'dropout': 0.3980610410671893, 'num_layers': 2, 'hidden_size': 39, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:10:52,878] Trial 22 finished with value: 0.09325604885816574 and parameters: {'epochs': 12, 'batch_size': 64, 'learning_rate': 0.0002953242450133566, 'dropout': 0.39118591474315645, 'num_layers': 2, 'hidden_size': 47, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:11:00,082] Trial 23 finished with value: 0.08793728053569794 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 0.001018815847048211, 'dropout': 0.3279622367464724, 'num_layers': 2, 'hidden_size': 29, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:11:11,458] Trial 24 finished with value: 0.09743516147136688 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.00046446910150773767, 'dropout': 0.4176349408585938, 'num_layers': 2, 'hidden_size': 78, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:11:20,242] Trial 25 finished with value: 0.0995529294013977 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 0.0006718762136921394, 'dropout': 0.46162662412099625, 'num_layers': 2, 'hidden_size': 52, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:11:29,376] Trial 26 finished with value: 0.08975639194250107 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 0.00038593965586650414, 'dropout': 0.37708449478146017, 'num_layers': 2, 'hidden_size': 74, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:11:38,267] Trial 27 finished with value: 0.07258713245391846 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 0.009608081548781495, 'dropout': 0.2600753831241561, 'num_layers': 2, 'hidden_size': 32, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:11:47,772] Trial 28 finished with value: 0.1083153560757637 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.0015734883554248654, 'dropout': 0.20702627177903932, 'num_layers': 2, 'hidden_size': 17, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:12:03,725] Trial 29 finished with value: 0.07350102066993713 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 0.0034348698247048093, 'dropout': 0.3265258002589221, 'num_layers': 2, 'hidden_size': 64, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:12:16,932] Trial 30 finished with value: 0.09816528856754303 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.000179213418022785, 'dropout': 0.45115612838015856, 'num_layers': 2, 'hidden_size': 65, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:12:34,959] Trial 31 finished with value: 0.07132687419652939 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 5.688788048363471e-05, 'dropout': 0.4827002625543575, 'num_layers': 3, 'hidden_size': 94, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:12:50,720] Trial 32 finished with value: 0.08903500437736511 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 2.8208255195216157e-05, 'dropout': 0.49970898740921565, 'num_layers': 3, 'hidden_size': 110, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:13:03,928] Trial 33 finished with value: 0.09927897155284882 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 7.662773070956777e-05, 'dropout': 0.46243453081865143, 'num_layers': 3, 'hidden_size': 47, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:13:40,743] Trial 34 finished with value: 0.11637993901968002 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 0.0002906804021436553, 'dropout': 0.42351142891761023, 'num_layers': 3, 'hidden_size': 103, 'conv_filters': 128}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:13:51,238] Trial 35 finished with value: 0.06428660452365875 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 1.7423164679456834e-05, 'dropout': 0.43798968228747615, 'num_layers': 3, 'hidden_size': 125, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:14:06,001] Trial 36 finished with value: 0.07630093395709991 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.004614088810294977, 'dropout': 0.4359119841676473, 'num_layers': 2, 'hidden_size': 33, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:14:18,341] Trial 37 finished with value: 0.06777150928974152 and parameters: {'epochs': 19, 'batch_size': 64, 'learning_rate': 2.8416677819552206e-05, 'dropout': 0.3749660070212649, 'num_layers': 3, 'hidden_size': 58, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:14:53,455] Trial 38 finished with value: 0.07456973195075989 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.0012727885625302064, 'dropout': 0.4065160831959206, 'num_layers': 2, 'hidden_size': 87, 'conv_filters': 128}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:15:12,747] Trial 39 finished with value: 0.07127396762371063 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 1.5037556562336417e-05, 'dropout': 0.2545353209711931, 'num_layers': 3, 'hidden_size': 100, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:15:20,376] Trial 40 finished with value: 0.06226171925663948 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 1.877770277854655e-05, 'dropout': 0.3617455062112526, 'num_layers': 2, 'hidden_size': 70, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:15:29,856] Trial 41 finished with value: 0.07639618217945099 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 1.928333727128677e-05, 'dropout': 0.33860109267775296, 'num_layers': 2, 'hidden_size': 69, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:15:37,537] Trial 42 finished with value: 0.07999501377344131 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 1.6809822772649454e-05, 'dropout': 0.36122027123958167, 'num_layers': 2, 'hidden_size': 46, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:15:45,207] Trial 43 finished with value: 0.0702519565820694 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 3.581734016947458e-05, 'dropout': 0.27948785749143923, 'num_layers': 2, 'hidden_size': 93, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:16:08,675] Trial 44 finished with value: 0.07302677631378174 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 2.1607884834214005e-05, 'dropout': 0.30823956982799544, 'num_layers': 2, 'hidden_size': 55, 'conv_filters': 128}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:16:15,838] Trial 45 finished with value: 0.11650793999433517 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 0.0008110632895654272, 'dropout': 0.36489935509214994, 'num_layers': 2, 'hidden_size': 24, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:16:26,455] Trial 46 finished with value: 0.06437699496746063 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 5.9725722582463985e-05, 'dropout': 0.4288701808406344, 'num_layers': 3, 'hidden_size': 76, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:16:37,452] Trial 47 finished with value: 0.08709505200386047 and parameters: {'epochs': 14, 'batch_size': 64, 'learning_rate': 0.00016492808202023585, 'dropout': 0.3909943891624032, 'num_layers': 3, 'hidden_size': 116, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:16:44,470] Trial 48 finished with value: 0.06306231021881104 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 8.773694271233983e-05, 'dropout': 0.47591895164038356, 'num_layers': 2, 'hidden_size': 128, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:16:50,730] Trial 49 finished with value: 0.07431197911500931 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 9.722948264621093e-05, 'dropout': 0.4742152035657904, 'num_layers': 2, 'hidden_size': 117, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:17:06,873] Trial 50 finished with value: 0.07873315364122391 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 1.0876826436520249e-05, 'dropout': 0.44448554327182976, 'num_layers': 2, 'hidden_size': 126, 'conv_filters': 128}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:17:13,657] Trial 51 finished with value: 0.07433672994375229 and parameters: {'epochs': 12, 'batch_size': 64, 'learning_rate': 4.716958450537327e-05, 'dropout': 0.41574300731251235, 'num_layers': 2, 'hidden_size': 122, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:17:19,385] Trial 52 finished with value: 0.06641557812690735 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 0.00013304348109561545, 'dropout': 0.345100619924806, 'num_layers': 2, 'hidden_size': 126, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:17:25,380] Trial 53 finished with value: 0.0978192538022995 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 0.0005891068070757034, 'dropout': 0.47538491765353563, 'num_layers': 2, 'hidden_size': 107, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:17:33,304] Trial 54 finished with value: 0.0831187516450882 and parameters: {'epochs': 12, 'batch_size': 64, 'learning_rate': 0.00024604240090089833, 'dropout': 0.45558168059088977, 'num_layers': 3, 'hidden_size': 120, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:17:47,714] Trial 55 finished with value: 0.10521355271339417 and parameters: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.0021611052517865807, 'dropout': 0.40412665450644125, 'num_layers': 2, 'hidden_size': 80, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:17:58,083] Trial 56 finished with value: 0.18561959266662598 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 2.473837443971642e-05, 'dropout': 0.440991423428109, 'num_layers': 3, 'hidden_size': 37, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:18:14,120] Trial 57 finished with value: 0.08505252003669739 and parameters: {'epochs': 18, 'batch_size': 64, 'learning_rate': 0.0004355625142106776, 'dropout': 0.3936430242460813, 'num_layers': 2, 'hidden_size': 44, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:18:23,210] Trial 58 finished with value: 0.06206398084759712 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 3.5087694581324536e-05, 'dropout': 0.47163219387354033, 'num_layers': 2, 'hidden_size': 53, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:18:32,463] Trial 59 finished with value: 0.05913495644927025 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 4.2667278936689254e-05, 'dropout': 0.4736744725100245, 'num_layers': 2, 'hidden_size': 60, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:18:40,198] Trial 60 finished with value: 0.059840403497219086 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 3.821448752879643e-05, 'dropout': 0.48826158511828877, 'num_layers': 2, 'hidden_size': 58, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:18:48,451] Trial 61 finished with value: 0.052144162356853485 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 3.689834284550044e-05, 'dropout': 0.4892296978427754, 'num_layers': 2, 'hidden_size': 59, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:18:58,502] Trial 62 finished with value: 0.08432977646589279 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 3.648217505972145e-05, 'dropout': 0.4912824257474203, 'num_layers': 2, 'hidden_size': 60, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:19:07,832] Trial 63 finished with value: 0.06685429066419601 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 5.623192938588611e-05, 'dropout': 0.46947129262952, 'num_layers': 2, 'hidden_size': 50, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:19:18,108] Trial 64 finished with value: 0.08538682013750076 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 4.0310099251033125e-05, 'dropout': 0.48494339377155615, 'num_layers': 2, 'hidden_size': 63, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:19:26,928] Trial 65 finished with value: 0.07650181651115417 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 6.654817745457378e-05, 'dropout': 0.4940739829687699, 'num_layers': 2, 'hidden_size': 68, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:19:34,876] Trial 66 finished with value: 0.09404648095369339 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 1.3674061531076902e-05, 'dropout': 0.4550458879552787, 'num_layers': 2, 'hidden_size': 55, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:19:46,490] Trial 67 finished with value: 0.07251725345849991 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 3.163516669886781e-05, 'dropout': 0.4828650160833567, 'num_layers': 2, 'hidden_size': 50, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:19:56,257] Trial 68 finished with value: 0.07792312651872635 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 2.1893728194666288e-05, 'dropout': 0.4648951903262874, 'num_layers': 2, 'hidden_size': 71, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:20:28,696] Trial 69 finished with value: 0.07580142468214035 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 2.4023448629895335e-05, 'dropout': 0.44788208036206445, 'num_layers': 2, 'hidden_size': 43, 'conv_filters': 128}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:20:37,301] Trial 70 finished with value: 0.06240293011069298 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 4.437233293547231e-05, 'dropout': 0.4770043394930037, 'num_layers': 2, 'hidden_size': 60, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:20:44,372] Trial 71 finished with value: 0.05555041506886482 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 5.098300197768076e-05, 'dropout': 0.49948216714323623, 'num_layers': 2, 'hidden_size': 59, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:20:51,421] Trial 72 finished with value: 0.07622206211090088 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 4.948781527201748e-05, 'dropout': 0.49967264157292435, 'num_layers': 2, 'hidden_size': 53, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:21:02,582] Trial 73 finished with value: 0.08775899559259415 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 6.830486787889425e-05, 'dropout': 0.4894339181192839, 'num_layers': 2, 'hidden_size': 58, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:21:11,820] Trial 74 finished with value: 0.08753742277622223 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 3.184494806584326e-05, 'dropout': 0.455893688749524, 'num_layers': 2, 'hidden_size': 65, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:21:25,657] Trial 75 finished with value: 0.07344693690538406 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.00011193661925968911, 'dropout': 0.48169853611570435, 'num_layers': 2, 'hidden_size': 62, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:21:33,655] Trial 76 finished with value: 0.0742809846997261 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 2.589109256346194e-05, 'dropout': 0.46934885871757626, 'num_layers': 2, 'hidden_size': 50, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:21:45,312] Trial 77 finished with value: 0.06104981154203415 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 1.8907710355200477e-05, 'dropout': 0.4917297133669671, 'num_layers': 2, 'hidden_size': 36, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:21:58,520] Trial 78 finished with value: 0.0671365037560463 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 3.784523585225479e-05, 'dropout': 0.4919677049354132, 'num_layers': 2, 'hidden_size': 36, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:22:50,539] Trial 79 finished with value: 0.07373411953449249 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.006705052654392905, 'dropout': 0.4998061235797916, 'num_layers': 2, 'hidden_size': 43, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:23:07,093] Trial 80 finished with value: 0.06902561336755753 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 1.3407179368945148e-05, 'dropout': 0.4635901144968254, 'num_layers': 2, 'hidden_size': 32, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:23:21,668] Trial 81 finished with value: 0.06641913950443268 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 1.78541725777609e-05, 'dropout': 0.4846378756926007, 'num_layers': 2, 'hidden_size': 67, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:23:33,889] Trial 82 finished with value: 0.06541503965854645 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 3.380058373555641e-05, 'dropout': 0.4707609826590999, 'num_layers': 2, 'hidden_size': 55, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:23:41,292] Trial 83 finished with value: 0.06140713393688202 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 1.9287176488835695e-05, 'dropout': 0.480954786973998, 'num_layers': 2, 'hidden_size': 73, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:23:48,536] Trial 84 finished with value: 0.08237691223621368 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 1.0211790132060965e-05, 'dropout': 0.480170295858807, 'num_layers': 2, 'hidden_size': 48, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:23:56,803] Trial 85 finished with value: 0.07001125067472458 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 2.1279322269730356e-05, 'dropout': 0.4898820897541266, 'num_layers': 2, 'hidden_size': 40, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:24:06,593] Trial 86 finished with value: 0.06289595365524292 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 5.3541635215618144e-05, 'dropout': 0.4582079786267841, 'num_layers': 2, 'hidden_size': 52, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:24:37,780] Trial 87 finished with value: 0.0698351114988327 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 4.642341894292017e-05, 'dropout': 0.43121766229500674, 'num_layers': 2, 'hidden_size': 73, 'conv_filters': 128}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:24:45,056] Trial 88 finished with value: 0.08184865117073059 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 1.5454269649605953e-05, 'dropout': 0.46922461898021844, 'num_layers': 2, 'hidden_size': 26, 'conv_filters': 32}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:24:56,211] Trial 89 finished with value: 0.05070095136761665 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 2.7496870143801453e-05, 'dropout': 0.4939781810767799, 'num_layers': 2, 'hidden_size': 61, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:25:11,002] Trial 90 finished with value: 0.07273221760988235 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 2.7470146879717813e-05, 'dropout': 0.49431804545896235, 'num_layers': 2, 'hidden_size': 76, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:25:24,946] Trial 91 finished with value: 0.0891619324684143 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 4.209548309458328e-05, 'dropout': 0.4868748951953606, 'num_layers': 2, 'hidden_size': 61, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:25:39,587] Trial 92 finished with value: 0.09251850843429565 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.001130202734848629, 'dropout': 0.47833645978793415, 'num_layers': 2, 'hidden_size': 57, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:25:49,583] Trial 93 finished with value: 0.06762323528528214 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 7.399907777002938e-05, 'dropout': 0.44944595944549215, 'num_layers': 2, 'hidden_size': 65, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:26:03,936] Trial 94 finished with value: 0.06191110983490944 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 2.9476656652122763e-05, 'dropout': 0.4948160284063022, 'num_layers': 2, 'hidden_size': 57, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:26:19,408] Trial 95 finished with value: 0.05356273055076599 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 2.823287883675359e-05, 'dropout': 0.4952570787126983, 'num_layers': 2, 'hidden_size': 83, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:26:35,065] Trial 96 finished with value: 0.07483384758234024 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 0.0018141899264983755, 'dropout': 0.49971910852156604, 'num_layers': 2, 'hidden_size': 83, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:26:47,067] Trial 97 finished with value: 0.06468403339385986 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 2.2440297303099926e-05, 'dropout': 0.4871128494562748, 'num_layers': 2, 'hidden_size': 86, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:26:59,569] Trial 98 finished with value: 0.06441353261470795 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 1.5692842077083296e-05, 'dropout': 0.46210944945439264, 'num_layers': 2, 'hidden_size': 91, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n",
      "[I 2024-12-21 17:27:09,930] Trial 99 finished with value: 0.06632253527641296 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 1.224459235809658e-05, 'dropout': 0.47829181167344814, 'num_layers': 2, 'hidden_size': 79, 'conv_filters': 64}. Best is trial 17 with value: 0.04401501268148422.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-LSTM_window_7_look_forward_1_open_price_target saved to ..\\data\\models\\CNN-LSTM_window_7_look_forward_1_open_price_target\\CNN-LSTM_window_7_look_forward_1_open_price_target_study.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [1:38:26<28:44, 1724.28s/it]  [I 2024-12-21 17:27:13,034] A new study created in memory with name: CNN-GRU_window_7_look_forward_1_open_price_target\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved to ..\\data\\models\\CNN-LSTM_window_7_look_forward_1_open_price_target\n",
      "Saved to ..\\data\\models\\CNN-LSTM_window_7_look_forward_1_open_price_target:\n",
      "Best hyperparameters for CNN-LSTM, window size: 7, look forward: 1, target open_price_target: {'epochs': 19, 'batch_size': 64, 'learning_rate': 0.0002637949326186407, 'dropout': 0.4527826252414749, 'num_layers': 2, 'hidden_size': 43, 'conv_filters': 32}\n",
      "Best trial index: 17, Best trial value: 0.04401501268148422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 17:27:18,620] Trial 0 finished with value: 0.053560029715299606 and parameters: {'epochs': 10, 'batch_size': 64, 'learning_rate': 2.3367121485164768e-05, 'dropout': 0.3524368783244453, 'num_layers': 2, 'hidden_size': 36, 'conv_filters': 32}. Best is trial 0 with value: 0.053560029715299606.\n",
      "[I 2024-12-21 17:27:36,749] Trial 1 finished with value: 0.0427863635122776 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 2.5293370813646228e-05, 'dropout': 0.3426894453680839, 'num_layers': 2, 'hidden_size': 84, 'conv_filters': 64}. Best is trial 1 with value: 0.0427863635122776.\n",
      "[I 2024-12-21 17:27:53,024] Trial 2 finished with value: 0.1060994416475296 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 0.00020916576061724964, 'dropout': 0.4992528897133408, 'num_layers': 2, 'hidden_size': 65, 'conv_filters': 64}. Best is trial 1 with value: 0.0427863635122776.\n",
      "[I 2024-12-21 17:28:18,789] Trial 3 finished with value: 0.10372059792280197 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 0.0001787423251660355, 'dropout': 0.2511308797344039, 'num_layers': 3, 'hidden_size': 96, 'conv_filters': 128}. Best is trial 1 with value: 0.0427863635122776.\n",
      "[I 2024-12-21 17:28:31,985] Trial 4 finished with value: 0.07437737286090851 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 0.0053513766096353645, 'dropout': 0.2767565734135169, 'num_layers': 2, 'hidden_size': 45, 'conv_filters': 64}. Best is trial 1 with value: 0.0427863635122776.\n",
      "[I 2024-12-21 17:28:47,058] Trial 5 finished with value: 0.049444619566202164 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 2.7474361130810882e-05, 'dropout': 0.28183977667451904, 'num_layers': 3, 'hidden_size': 120, 'conv_filters': 64}. Best is trial 1 with value: 0.0427863635122776.\n",
      "[I 2024-12-21 17:29:06,344] Trial 6 finished with value: 0.060583923012018204 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 0.00013086380693231532, 'dropout': 0.38770625619127125, 'num_layers': 3, 'hidden_size': 88, 'conv_filters': 32}. Best is trial 1 with value: 0.0427863635122776.\n",
      "[I 2024-12-21 17:29:20,007] Trial 7 finished with value: 0.038874246180057526 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 1.538770879446434e-05, 'dropout': 0.33443766219245286, 'num_layers': 3, 'hidden_size': 123, 'conv_filters': 32}. Best is trial 7 with value: 0.038874246180057526.\n",
      "[I 2024-12-21 17:29:33,602] Trial 8 finished with value: 0.04107509180903435 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 2.040145258946012e-05, 'dropout': 0.4538993032213985, 'num_layers': 2, 'hidden_size': 94, 'conv_filters': 64}. Best is trial 7 with value: 0.038874246180057526.\n",
      "[I 2024-12-21 17:30:00,563] Trial 9 finished with value: 0.07238328456878662 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.0008893763930823771, 'dropout': 0.2658778104862064, 'num_layers': 3, 'hidden_size': 37, 'conv_filters': 128}. Best is trial 7 with value: 0.038874246180057526.\n",
      "[I 2024-12-21 17:30:20,295] Trial 10 finished with value: 0.07707345485687256 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.001150291915868055, 'dropout': 0.20175031634111315, 'num_layers': 3, 'hidden_size': 126, 'conv_filters': 32}. Best is trial 7 with value: 0.038874246180057526.\n",
      "[I 2024-12-21 17:30:34,683] Trial 11 finished with value: 0.05075092613697052 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 1.5322527700111083e-05, 'dropout': 0.4581684062862028, 'num_layers': 2, 'hidden_size': 105, 'conv_filters': 32}. Best is trial 7 with value: 0.038874246180057526.\n",
      "[I 2024-12-21 17:30:50,718] Trial 12 finished with value: 0.05773582682013512 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 7.001629684718807e-05, 'dropout': 0.3977923556319161, 'num_layers': 2, 'hidden_size': 111, 'conv_filters': 64}. Best is trial 7 with value: 0.038874246180057526.\n",
      "[I 2024-12-21 17:31:01,836] Trial 13 finished with value: 0.04999157413840294 and parameters: {'epochs': 13, 'batch_size': 64, 'learning_rate': 1.077124715828367e-05, 'dropout': 0.43612169278356633, 'num_layers': 3, 'hidden_size': 68, 'conv_filters': 32}. Best is trial 7 with value: 0.038874246180057526.\n",
      "[I 2024-12-21 17:31:31,983] Trial 14 finished with value: 0.0349467396736145 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 5.3134609862035726e-05, 'dropout': 0.33984463114420005, 'num_layers': 2, 'hidden_size': 128, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:32:02,274] Trial 15 finished with value: 0.11379827558994293 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 6.377285104649818e-05, 'dropout': 0.32499555987338724, 'num_layers': 3, 'hidden_size': 18, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:32:41,000] Trial 16 finished with value: 0.03972827270627022 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 6.4496788422801e-05, 'dropout': 0.31937766592243994, 'num_layers': 3, 'hidden_size': 127, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:33:06,361] Trial 17 finished with value: 0.12218578159809113 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 0.0006011633948680137, 'dropout': 0.372757138561879, 'num_layers': 2, 'hidden_size': 111, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:33:23,482] Trial 18 finished with value: 0.05407753214240074 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 4.37342973323571e-05, 'dropout': 0.3054314584078472, 'num_layers': 3, 'hidden_size': 114, 'conv_filters': 32}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:33:47,120] Trial 19 finished with value: 0.07622317224740982 and parameters: {'epochs': 11, 'batch_size': 32, 'learning_rate': 0.0026930630664134124, 'dropout': 0.22789277006049163, 'num_layers': 2, 'hidden_size': 76, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:34:17,168] Trial 20 finished with value: 0.13043688237667084 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.00042023389507335967, 'dropout': 0.4187270732117967, 'num_layers': 3, 'hidden_size': 102, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:34:55,313] Trial 21 finished with value: 0.04013814032077789 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 8.58177162690529e-05, 'dropout': 0.31317618261290125, 'num_layers': 3, 'hidden_size': 126, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:35:36,493] Trial 22 finished with value: 0.04960991442203522 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 4.439663280806515e-05, 'dropout': 0.34656749559687144, 'num_layers': 3, 'hidden_size': 123, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:36:15,429] Trial 23 finished with value: 0.038965918123722076 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 1.1371175182669388e-05, 'dropout': 0.3007509067510328, 'num_layers': 3, 'hidden_size': 115, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:36:53,074] Trial 24 finished with value: 0.04391803592443466 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.607549676862566e-05, 'dropout': 0.2956946091725473, 'num_layers': 3, 'hidden_size': 116, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:37:06,657] Trial 25 finished with value: 0.04124610871076584 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.0062105670964183e-05, 'dropout': 0.36655336149237144, 'num_layers': 3, 'hidden_size': 103, 'conv_filters': 32}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:37:29,296] Trial 26 finished with value: 0.06407463550567627 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 3.8237270489933335e-05, 'dropout': 0.32850419105122497, 'num_layers': 2, 'hidden_size': 54, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:37:45,757] Trial 27 finished with value: 0.0410267673432827 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 1.0500047795647524e-05, 'dropout': 0.2562086209118758, 'num_layers': 3, 'hidden_size': 108, 'conv_filters': 32}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:38:17,373] Trial 28 finished with value: 0.07321822643280029 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 0.00012683785022628454, 'dropout': 0.29068796156758453, 'num_layers': 2, 'hidden_size': 117, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:38:26,540] Trial 29 finished with value: 0.04720718413591385 and parameters: {'epochs': 10, 'batch_size': 32, 'learning_rate': 3.0556388733793504e-05, 'dropout': 0.3530037695444403, 'num_layers': 3, 'hidden_size': 80, 'conv_filters': 32}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:38:47,098] Trial 30 finished with value: 0.0457514263689518 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 1.632241664564834e-05, 'dropout': 0.39510276293791624, 'num_layers': 2, 'hidden_size': 95, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:39:26,630] Trial 31 finished with value: 0.0576242059469223 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 5.6892592981106075e-05, 'dropout': 0.3248396568026045, 'num_layers': 3, 'hidden_size': 128, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:40:06,650] Trial 32 finished with value: 0.07940875738859177 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 2.489385525534781e-05, 'dropout': 0.3382383867905389, 'num_layers': 3, 'hidden_size': 121, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:40:46,097] Trial 33 finished with value: 0.11846085637807846 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 0.00010308339989827047, 'dropout': 0.31208973518218064, 'num_layers': 3, 'hidden_size': 128, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:41:25,461] Trial 34 finished with value: 0.1436140388250351 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.00026666947370320815, 'dropout': 0.35973947480641627, 'num_layers': 3, 'hidden_size': 117, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:42:00,670] Trial 35 finished with value: 0.05087580904364586 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.9886278760811837e-05, 'dropout': 0.2384845839197442, 'num_layers': 3, 'hidden_size': 100, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:42:13,313] Trial 36 finished with value: 0.05819682776927948 and parameters: {'epochs': 12, 'batch_size': 32, 'learning_rate': 0.00019133315972054044, 'dropout': 0.2995843552119537, 'num_layers': 3, 'hidden_size': 86, 'conv_filters': 32}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:42:29,127] Trial 37 finished with value: 0.045025330036878586 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 3.3738600536474676e-05, 'dropout': 0.37935798998026476, 'num_layers': 2, 'hidden_size': 121, 'conv_filters': 64}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:43:10,825] Trial 38 finished with value: 0.042797159403562546 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 1.4757350189700876e-05, 'dropout': 0.34217630393514864, 'num_layers': 3, 'hidden_size': 60, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:43:32,256] Trial 39 finished with value: 0.1716589629650116 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 0.008899488581384132, 'dropout': 0.277251384226874, 'num_layers': 2, 'hidden_size': 109, 'conv_filters': 64}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:43:40,014] Trial 40 finished with value: 0.05705220624804497 and parameters: {'epochs': 11, 'batch_size': 64, 'learning_rate': 2.4204608469294353e-05, 'dropout': 0.2667022221055243, 'num_layers': 3, 'hidden_size': 93, 'conv_filters': 32}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:44:21,771] Trial 41 finished with value: 0.07401423901319504 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 9.299835104677435e-05, 'dropout': 0.31810834208472627, 'num_layers': 3, 'hidden_size': 128, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:44:57,397] Trial 42 finished with value: 0.052914779633283615 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 7.9918733125488e-05, 'dropout': 0.28706521035015925, 'num_layers': 3, 'hidden_size': 122, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:45:39,945] Trial 43 finished with value: 0.04113765060901642 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 5.5960999661521e-05, 'dropout': 0.33714670915859457, 'num_layers': 3, 'hidden_size': 115, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:46:20,772] Trial 44 finished with value: 0.13305425643920898 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 0.00015234032485775096, 'dropout': 0.308260526724132, 'num_layers': 3, 'hidden_size': 122, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:46:57,850] Trial 45 finished with value: 0.14034610986709595 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 0.00036000660664203794, 'dropout': 0.35909462893996547, 'num_layers': 3, 'hidden_size': 124, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:47:12,853] Trial 46 finished with value: 0.08614084124565125 and parameters: {'epochs': 15, 'batch_size': 64, 'learning_rate': 0.00022708662236809514, 'dropout': 0.3299729483311792, 'num_layers': 3, 'hidden_size': 107, 'conv_filters': 64}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:47:48,914] Trial 47 finished with value: 0.08535363525152206 and parameters: {'epochs': 20, 'batch_size': 32, 'learning_rate': 4.7913143609815466e-05, 'dropout': 0.48585816743261534, 'num_layers': 3, 'hidden_size': 113, 'conv_filters': 128}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:48:03,904] Trial 48 finished with value: 0.09460367262363434 and parameters: {'epochs': 13, 'batch_size': 32, 'learning_rate': 0.0001095123959065041, 'dropout': 0.40869794783231383, 'num_layers': 3, 'hidden_size': 118, 'conv_filters': 32}. Best is trial 14 with value: 0.0349467396736145.\n",
      "[I 2024-12-21 17:48:35,089] Trial 49 finished with value: 0.03364561125636101 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.9224258459720607e-05, 'dropout': 0.2682226131007114, 'num_layers': 2, 'hidden_size': 126, 'conv_filters': 128}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:48:43,554] Trial 50 finished with value: 0.06253816932439804 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 1.3017493075593451e-05, 'dropout': 0.22320800035627603, 'num_layers': 2, 'hidden_size': 22, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:49:18,346] Trial 51 finished with value: 0.09936916828155518 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.9588296325918677e-05, 'dropout': 0.2698136915011831, 'num_layers': 2, 'hidden_size': 125, 'conv_filters': 128}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:49:45,593] Trial 52 finished with value: 0.08421621471643448 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 2.9570106579454958e-05, 'dropout': 0.24707845910212098, 'num_layers': 2, 'hidden_size': 113, 'conv_filters': 128}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:50:19,828] Trial 53 finished with value: 0.1026880219578743 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 7.314866122179933e-05, 'dropout': 0.31610851645654275, 'num_layers': 2, 'hidden_size': 119, 'conv_filters': 128}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:50:46,475] Trial 54 finished with value: 0.04617271199822426 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 3.634446127920622e-05, 'dropout': 0.30012443481603335, 'num_layers': 2, 'hidden_size': 128, 'conv_filters': 128}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:51:22,391] Trial 55 finished with value: 0.03677781671285629 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 2.0489481533639348e-05, 'dropout': 0.27995455850312095, 'num_layers': 2, 'hidden_size': 124, 'conv_filters': 128}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:51:50,380] Trial 56 finished with value: 0.04050034284591675 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.278185836729568e-05, 'dropout': 0.28174838095080373, 'num_layers': 2, 'hidden_size': 111, 'conv_filters': 128}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:52:16,591] Trial 57 finished with value: 0.03766258805990219 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.9309852166354186e-05, 'dropout': 0.20716647458062737, 'num_layers': 2, 'hidden_size': 119, 'conv_filters': 64}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:52:36,155] Trial 58 finished with value: 0.047302357852458954 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 2.427856083265126e-05, 'dropout': 0.20137755907854052, 'num_layers': 2, 'hidden_size': 99, 'conv_filters': 64}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:52:54,172] Trial 59 finished with value: 0.09381026774644852 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.9056367881307708e-05, 'dropout': 0.21533097499377232, 'num_layers': 2, 'hidden_size': 43, 'conv_filters': 64}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:53:16,057] Trial 60 finished with value: 0.04126249998807907 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.1564226806743972e-05, 'dropout': 0.25475790314293095, 'num_layers': 2, 'hidden_size': 105, 'conv_filters': 64}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:53:36,937] Trial 61 finished with value: 0.04045974463224411 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.576931607109581e-05, 'dropout': 0.243777028888986, 'num_layers': 2, 'hidden_size': 124, 'conv_filters': 64}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:54:12,933] Trial 62 finished with value: 0.041090309619903564 and parameters: {'epochs': 19, 'batch_size': 32, 'learning_rate': 2.8036786570729242e-05, 'dropout': 0.290219744251156, 'num_layers': 2, 'hidden_size': 119, 'conv_filters': 128}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:54:30,296] Trial 63 finished with value: 0.08099675923585892 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.0023102781826733368, 'dropout': 0.23304898409754066, 'num_layers': 2, 'hidden_size': 115, 'conv_filters': 64}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:54:43,767] Trial 64 finished with value: 0.037191543728113174 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.7676828492770253e-05, 'dropout': 0.2606127688983026, 'num_layers': 2, 'hidden_size': 124, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:54:56,650] Trial 65 finished with value: 0.03656598925590515 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.9813487059390925e-05, 'dropout': 0.2573314747572125, 'num_layers': 2, 'hidden_size': 124, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:55:16,405] Trial 66 finished with value: 0.03845778852701187 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 2.11553833823468e-05, 'dropout': 0.21618480420800287, 'num_layers': 2, 'hidden_size': 121, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:55:31,837] Trial 67 finished with value: 0.03927479684352875 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 2.0381699834350756e-05, 'dropout': 0.21339699111738086, 'num_layers': 2, 'hidden_size': 124, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:55:42,393] Trial 68 finished with value: 0.04286991059780121 and parameters: {'epochs': 17, 'batch_size': 64, 'learning_rate': 4.0474460596080515e-05, 'dropout': 0.26174316960185123, 'num_layers': 2, 'hidden_size': 111, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:55:55,575] Trial 69 finished with value: 0.0393516980111599 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 1.71927422076995e-05, 'dropout': 0.21247896229242969, 'num_layers': 2, 'hidden_size': 120, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:56:11,856] Trial 70 finished with value: 0.03528182581067085 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 5.066214021523816e-05, 'dropout': 0.22549645659084674, 'num_layers': 2, 'hidden_size': 125, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:56:25,926] Trial 71 finished with value: 0.03933967649936676 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.3464202538344224e-05, 'dropout': 0.22601172245825263, 'num_layers': 2, 'hidden_size': 125, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:56:38,416] Trial 72 finished with value: 0.03968203440308571 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 3.241430721424898e-05, 'dropout': 0.24066309638742414, 'num_layers': 2, 'hidden_size': 119, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:56:51,578] Trial 73 finished with value: 0.04491005837917328 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.3235284745697686e-05, 'dropout': 0.25129124279446163, 'num_layers': 2, 'hidden_size': 128, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:57:04,904] Trial 74 finished with value: 0.07624193280935287 and parameters: {'epochs': 18, 'batch_size': 32, 'learning_rate': 4.8564843788021304e-05, 'dropout': 0.20941282512111883, 'num_layers': 2, 'hidden_size': 122, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:57:17,708] Trial 75 finished with value: 0.03790895640850067 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.792265305150758e-05, 'dropout': 0.2709702164892768, 'num_layers': 2, 'hidden_size': 117, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:57:28,237] Trial 76 finished with value: 0.04009610787034035 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 2.839894156934473e-05, 'dropout': 0.272674689655137, 'num_layers': 2, 'hidden_size': 73, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:57:39,873] Trial 77 finished with value: 0.08508706092834473 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 5.4928009449541335e-05, 'dropout': 0.23476197109874078, 'num_layers': 2, 'hidden_size': 115, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:57:50,860] Trial 78 finished with value: 0.0364886149764061 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 3.294148748432684e-05, 'dropout': 0.2617783067036229, 'num_layers': 2, 'hidden_size': 109, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:58:05,838] Trial 79 finished with value: 0.03719449043273926 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 3.8933720234855515e-05, 'dropout': 0.26327690258401404, 'num_layers': 2, 'hidden_size': 125, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:58:22,224] Trial 80 finished with value: 0.03731460124254227 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 3.645531631460515e-05, 'dropout': 0.26055381561922814, 'num_layers': 2, 'hidden_size': 125, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:58:34,935] Trial 81 finished with value: 0.04916413873434067 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 3.995392307077482e-05, 'dropout': 0.26098422601090193, 'num_layers': 2, 'hidden_size': 125, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:58:46,498] Trial 82 finished with value: 0.0931287482380867 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 6.664137146942155e-05, 'dropout': 0.2508718661729598, 'num_layers': 2, 'hidden_size': 125, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:58:59,247] Trial 83 finished with value: 0.045279666781425476 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 3.481352313804094e-05, 'dropout': 0.28189164396931476, 'num_layers': 2, 'hidden_size': 128, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:59:11,208] Trial 84 finished with value: 0.05758200213313103 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 4.9709011184345355e-05, 'dropout': 0.2611067217754221, 'num_layers': 2, 'hidden_size': 90, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:59:24,761] Trial 85 finished with value: 0.04837578907608986 and parameters: {'epochs': 15, 'batch_size': 32, 'learning_rate': 4.220751917964838e-05, 'dropout': 0.279633339421426, 'num_layers': 2, 'hidden_size': 109, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:59:35,211] Trial 86 finished with value: 0.047260865569114685 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 6.239635933652555e-05, 'dropout': 0.257629670067617, 'num_layers': 2, 'hidden_size': 122, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:59:45,905] Trial 87 finished with value: 0.034157563000917435 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 2.3635752071844152e-05, 'dropout': 0.24567999422632733, 'num_layers': 2, 'hidden_size': 126, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 17:59:57,070] Trial 88 finished with value: 0.1298951655626297 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.0007583205480293283, 'dropout': 0.23077173787325095, 'num_layers': 2, 'hidden_size': 113, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 18:00:10,890] Trial 89 finished with value: 0.04021367058157921 and parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 1.533471653738771e-05, 'dropout': 0.2406897562632947, 'num_layers': 2, 'hidden_size': 117, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 18:00:24,829] Trial 90 finished with value: 0.03630286455154419 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.2806586279566658e-05, 'dropout': 0.24571120457090864, 'num_layers': 2, 'hidden_size': 122, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 18:00:37,907] Trial 91 finished with value: 0.03716832399368286 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.3113735264439608e-05, 'dropout': 0.2468409037559273, 'num_layers': 2, 'hidden_size': 123, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 18:00:49,764] Trial 92 finished with value: 0.035253431648015976 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.3023663620514704e-05, 'dropout': 0.2218189301875874, 'num_layers': 2, 'hidden_size': 121, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 18:01:02,858] Trial 93 finished with value: 0.03766501322388649 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.5609661136201597e-05, 'dropout': 0.24581530751977773, 'num_layers': 2, 'hidden_size': 82, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 18:01:20,926] Trial 94 finished with value: 0.03826890140771866 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.3210113331115586e-05, 'dropout': 0.21883105268260727, 'num_layers': 2, 'hidden_size': 121, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 18:01:35,212] Trial 95 finished with value: 0.03939630091190338 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 3.159252000631703e-05, 'dropout': 0.22274596945183392, 'num_layers': 2, 'hidden_size': 128, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 18:01:47,838] Trial 96 finished with value: 0.03935237228870392 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.4105194534758456e-05, 'dropout': 0.23586248458784145, 'num_layers': 2, 'hidden_size': 117, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 18:02:00,707] Trial 97 finished with value: 0.04264163225889206 and parameters: {'epochs': 16, 'batch_size': 32, 'learning_rate': 2.2509734480745423e-05, 'dropout': 0.2494960912331106, 'num_layers': 2, 'hidden_size': 62, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 18:02:12,127] Trial 98 finished with value: 0.04657634347677231 and parameters: {'epochs': 16, 'batch_size': 64, 'learning_rate': 1.180116324894747e-05, 'dropout': 0.22851087524998695, 'num_layers': 2, 'hidden_size': 113, 'conv_filters': 32}. Best is trial 49 with value: 0.03364561125636101.\n",
      "[I 2024-12-21 18:02:43,979] Trial 99 finished with value: 0.07466843724250793 and parameters: {'epochs': 17, 'batch_size': 32, 'learning_rate': 1.7555654210913077e-05, 'dropout': 0.27619441061629424, 'num_layers': 2, 'hidden_size': 122, 'conv_filters': 128}. Best is trial 49 with value: 0.03364561125636101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-GRU_window_7_look_forward_1_open_price_target saved to ..\\data\\models\\CNN-GRU_window_7_look_forward_1_open_price_target\\CNN-GRU_window_7_look_forward_1_open_price_target_study.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [2:14:01<00:00, 2010.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved to ..\\data\\models\\CNN-GRU_window_7_look_forward_1_open_price_target\n",
      "Saved to ..\\data\\models\\CNN-GRU_window_7_look_forward_1_open_price_target:\n",
      "Best hyperparameters for CNN-GRU, window size: 7, look forward: 1, target open_price_target: {'epochs': 16, 'batch_size': 32, 'learning_rate': 1.9224258459720607e-05, 'dropout': 0.2682226131007114, 'num_layers': 2, 'hidden_size': 126, 'conv_filters': 128}\n",
      "Best trial index: 49, Best trial value: 0.03364561125636101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s][I 2024-12-21 18:02:54,812] A new study created in memory with name: LSTM_window_7_look_forward_1_behavior_target\n",
      "[W 2024-12-21 18:02:54,877] Trial 0 failed with parameters: {'epochs': 14, 'batch_size': 32, 'learning_rate': 0.0014167584129807355, 'dropout': 0.45252862744755595, 'num_layers': 2, 'hidden_size': 38} because of the following error: RuntimeError('all elements of input should be between 0 and 1').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\guitz\\AppData\\Local\\Temp\\ipykernel_26232\\3815601039.py\", line 40, in <lambda>\n",
      "    lambda trial: train_evaluate_model(\n",
      "  File \"C:\\Users\\guitz\\AppData\\Local\\Temp\\ipykernel_26232\\3586603527.py\", line 48, in train_evaluate_model\n",
      "    loss = criterion(output, y_batch)\n",
      "  File \"c:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\loss.py\", line 697, in forward\n",
      "    return F.binary_cross_entropy(\n",
      "  File \"c:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\functional.py\", line 3554, in binary_cross_entropy\n",
      "    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)\n",
      "RuntimeError: all elements of input should be between 0 and 1\n",
      "[W 2024-12-21 18:02:54,903] Trial 0 failed with value None.\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m look_forwards \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m]  \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# # Call the optimize_models function\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m study_results \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_forwards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 39\u001b[0m, in \u001b[0;36moptimize_models\u001b[1;34m(df, targets, features, windows, look_forwards, max_samples)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Creating the Optuna study\u001b[39;00m\n\u001b[0;32m     38\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, study_name\u001b[38;5;241m=\u001b[39mstudy_name)\n\u001b[1;32m---> 39\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_samples\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m study_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_study.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(study, study_file)\n",
      "File \u001b[1;32mc:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[17], line 40\u001b[0m, in \u001b[0;36moptimize_models.<locals>.<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Creating the Optuna study\u001b[39;00m\n\u001b[0;32m     38\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, study_name\u001b[38;5;241m=\u001b[39mstudy_name)\n\u001b[0;32m     39\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mtrain_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     43\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39mmax_samples\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     46\u001b[0m study_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_study.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(study, study_file)\n",
      "Cell \u001b[1;32mIn[16], line 48\u001b[0m, in \u001b[0;36mtrain_evaluate_model\u001b[1;34m(trial, X_train, y_train, X_test, y_test, target, window_size, look_forward, model_type, study_name, model_dir)\u001b[0m\n\u001b[0;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     47\u001b[0m output \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[1;32m---> 48\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\loss.py:697\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guitz\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\functional.py:3554\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3551\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3552\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 3554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dir = os.path.join('..', 'data', 'processed')\n",
    "\n",
    "features_name = 'daily_features.pkl'\n",
    "input_dir_features = os.path.join('..', 'data', 'features')\n",
    "\n",
    "df1 = pd.read_parquet(os.path.join(input_dir, 'df_daily.parquet')).replace(\"/\", \"\\\\\")\n",
    "df2 = pd.read_parquet(os.path.join(input_dir, 'df_timestamp.parquet')).replace(\"/\", \"\\\\\")\n",
    "daily_features = joblib.load(os.path.join(input_dir_features, 'daily_features.pkl'))\n",
    "timnestamp_features = joblib.load(os.path.join(input_dir_features, '15min_timestamp_features.pkl'))\n",
    "\n",
    "features = daily_features\n",
    "targets = ['close_price_target', 'open_price_target', 'behavior_target']\n",
    "windows = [7]#, 15, 30, 45, 60] \n",
    "look_forwards = [1]  \n",
    "\n",
    "# # Call the optimize_models function\n",
    "study_results = optimize_models(df1, targets,features, windows, look_forwards, max_samples=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = joblib.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "models_dir = os.path.join('..', 'data', 'models', 'LSTM_window_7_look_forward_1_close_price_target_study.pkl').replace(\"/\", \"\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = joblib.load('C:\\\\Users\\\\guitz\\OneDrive\\\\Área de Trabalho\\\\monografia\\\\data\\\\models\\\\LSTM_window_7_look_forward_1_open_price_target\\\\LSTM_window_7_look_forward_1_open_price_target_study.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, label = data_to_array(df1, 7, 'close_price_target', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = parametros.best_params\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_history = study.trials\n",
    "for trial in optimization_history:\n",
    "    print(f\"Trial {trial.number}: Loss = {trial.value}, Params = {trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
