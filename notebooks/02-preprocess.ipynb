{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages: ['numpy', 'pandas', 'scikit-learn', 'joblib', 'pyarrow', 'fastparquet', 'plotly', 'matplotlib', 'MetaTrader5', 'tabulate']\n",
      "numpy is already installed.\n",
      "pandas is already installed.\n",
      "scikit-learn is already installed.\n",
      "joblib is already installed.\n",
      "pyarrow is already installed.\n",
      "fastparquet is already installed.\n",
      "plotly is already installed.\n",
      "matplotlib is already installed.\n",
      "MetaTrader5 is already installed.\n",
      "Installing tabulate...\n",
      "All packages are verified.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath('../scripts'))\n",
    "\n",
    "from myFunctions import install_packages, save_table \n",
    "install_packages()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### folders \n",
    "input_dir = os.path.join('..', 'data', 'assets')\n",
    "output_dir = os.path.join('..', 'data', 'preprocessed')\n",
    "table_dir= os.path.join('..', 'tables', 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\data\\\\assets'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(input_dir)\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def check_data(input_dir):\n",
    "\n",
    "    \"\"\"\n",
    "    Loads all .parquet files from the specified directory, processes them by:\n",
    "    - Extracting the ticker symbol from the filename (everything before the first '_').\n",
    "    - Creating a 'date' column with unique dates and dropping duplicates.\n",
    "    - Storing the ticker, first date, last date, and the number of columns in the DataFrame for each processed file.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): The path to the directory containing the .parquet files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the summary information (ticker, first date, last date, and shape).\n",
    "    \"\"\"\n",
    "    parquet_files = [f for f in os.listdir(input_dir) if f.endswith('.parquet')]\n",
    "    summary_data = [] \n",
    "    for parquet_file in parquet_files:\n",
    "        ticker = parquet_file.split('_')[0] \n",
    "        file_path = os.path.join(input_dir, parquet_file)\n",
    "        df = pd.read_parquet(file_path)\n",
    "        df['date'] = df['time'].dt.strftime('%Y-%m-%d')\n",
    "        df['time_of_trade'] = df['time'].dt.strftime('%H:%M:%S')\n",
    "        first_date = df['date'].min()\n",
    "        last_date = df['date'].max()\n",
    "        first_trade =  df['time_of_trade'].min()\n",
    "        last_trade = df['time_of_trade'].max()\n",
    "        summary_data.append({\n",
    "            'ticker': ticker,\n",
    "            'first_date': first_date,\n",
    "            'last_date': last_date,\n",
    "            'fist_trade': first_trade,\n",
    "            'last_trade': last_trade,\n",
    "            'rows': df.shape[0],\n",
    "            'columns': df.shape[1],\n",
    "            'unique_dates': len(df.date.unique())\n",
    "        })\n",
    "    \n",
    "    data_info_df = pd.DataFrame(summary_data)\n",
    "    save_table(data_info_df, title='Visualizaçao das séries de dados escolhidas')\n",
    "    return data_info_df\n",
    "\n",
    "\n",
    "def elegant_inputer(df: pd.DataFrame, \n",
    "                    start_date: str = '2022-06-01 09:00:00', \n",
    "                    end_date: str = '2024-11-22 17:45:00',\n",
    "                    timeframe: str = '15T', \n",
    "                    lookback: int = 180):\n",
    "    \"\"\"\n",
    "    Generates missing time intervals for the provided date range and timeframe, \n",
    "    adds them to the original dataframe, and fills missing values with forward fill method.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Original dataframe containing the time and other columns.\n",
    "    start_date (str): Start date and time of the range (default '2022-06-01 09:00:00').\n",
    "    end_date (str): End date and time of the range (default '2024-11-22 17:45:00').\n",
    "    timeframe (str): Time interval for generating timestamps (default '15T' for 15 minutes).\n",
    "    lookback (int): The number of previous valid entries to use for filling missing data (default 5).\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: A dataframe with the missing time intervals added and missing values filled.\n",
    "    \"\"\"\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "    time_intervals = pd.date_range(start=start_date, end=end_date, freq=timeframe)\n",
    "    df_aux = pd.DataFrame(time_intervals, columns=['time'])\n",
    "    df_aux['date'] = df_aux['time'].dt.date\n",
    "    df['date'] = df['time'].dt.date\n",
    "    valid_dates = df['date'].unique()\n",
    "    df_aux = df_aux[df_aux['date'].isin(valid_dates)]\n",
    "    df_inputed = pd.merge(df_aux, df, on=['date', 'time'], how='left')\n",
    "    df_inputed['tick_volume'].fillna(0, inplace=True)\n",
    "    df_inputed['real_volume'].fillna(0, inplace=True)\n",
    "    df_inputed = df_inputed.sort_values(by='time').reset_index(drop=True)\n",
    "    cols_to_ffill = ['open','high',\t'low',\t'close', 'spread']\n",
    "    df_inputed[cols_to_ffill] = df_inputed[cols_to_ffill].fillna(method='ffill',  limit=lookback)\n",
    "    first_trade = start_date.time()\n",
    "    last_trade = end_date.time()\n",
    "    df_inputed = df_inputed[(df_inputed['time'].dt.time >= first_trade) & (df_inputed['time'].dt.time <= last_trade)]\n",
    "\n",
    "    return df_inputed\n",
    "\n",
    "def process_data(input_dir: str, output_dir: str):\n",
    "    \"\"\"\n",
    "    Processes all .parquet files in the specified directory, concatenating DataFrames by aligning on the 'time' column\n",
    "    and appending the ticker as a suffix to each column name.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Path to the directory containing .parquet files.\n",
    "        output_dir (str): Path to save the processed DataFrame.\n",
    "    \"\"\"\n",
    "    parquet_files = [f for f in os.listdir(input_dir) if f.endswith('.parquet')]\n",
    "    processed_df = pd.DataFrame()\n",
    "    for parquet_file in parquet_files:\n",
    "        ticker = parquet_file.split('_')[0]\n",
    "        file_path = os.path.join(input_dir, parquet_file)\n",
    "        df = pd.read_parquet(file_path)\n",
    "        df = elegant_inputer(df)\n",
    "        df.drop(columns='date', inplace=True)\n",
    "        df = df.rename(columns=lambda col: f\"{col}_{ticker}\" if col != \"time\" else col)\n",
    "        processed_df = pd.concat([processed_df, df], axis=1)\n",
    "\n",
    "    processed_df = processed_df.loc[:, ~processed_df.columns.duplicated()]\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    processed_df.to_parquet(f'{output_dir}/data.parquet')\n",
    "    return processed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela saved as CSV: ../results/tables/csv\\Tabela_1_Visualizaçao das séries de dados escolhidas.csv\n",
      "+--------+------------+------------+------------+------------+-------+---------+--------------+\n",
      "| ticker | first_date | last_date  | fist_trade | last_trade | rows  | columns | unique_dates |\n",
      "+--------+------------+------------+------------+------------+-------+---------+--------------+\n",
      "|  AGFS  | 2022-06-01 | 2024-12-19 |  08:45:00  |  17:45:00  | 18729 |   10    |     641      |\n",
      "|  BGI$  | 2022-06-01 | 2024-12-19 |  09:00:00  |  16:30:00  | 18245 |   10    |     641      |\n",
      "|  CCM$  | 2022-06-01 | 2024-12-19 |  09:00:00  |  16:15:00  | 19181 |   10    |     641      |\n",
      "|  DI1$  | 2022-06-01 | 2024-12-19 |  09:00:00  |  17:45:00  | 22642 |   10    |     641      |\n",
      "|  DOL$  | 2022-06-01 | 2024-12-19 |  09:00:00  |  18:15:00  | 23777 |   10    |     641      |\n",
      "+--------+------------+------------+------------+------------+-------+---------+--------------+\n"
     ]
    }
   ],
   "source": [
    "df = check_data(input_dir=input_dir)\n",
    "print(tabulate(df.head(), headers='keys', tablefmt='pretty', showindex=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open_AGFS</th>\n",
       "      <th>high_AGFS</th>\n",
       "      <th>low_AGFS</th>\n",
       "      <th>close_AGFS</th>\n",
       "      <th>tick_volume_AGFS</th>\n",
       "      <th>spread_AGFS</th>\n",
       "      <th>real_volume_AGFS</th>\n",
       "      <th>open_BGI$</th>\n",
       "      <th>high_BGI$</th>\n",
       "      <th>...</th>\n",
       "      <th>tick_volume_IND$</th>\n",
       "      <th>spread_IND$</th>\n",
       "      <th>real_volume_IND$</th>\n",
       "      <th>open_IVVB11</th>\n",
       "      <th>high_IVVB11</th>\n",
       "      <th>low_IVVB11</th>\n",
       "      <th>close_IVVB11</th>\n",
       "      <th>tick_volume_IVVB11</th>\n",
       "      <th>spread_IVVB11</th>\n",
       "      <th>real_volume_IVVB11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-01 09:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319.66</td>\n",
       "      <td>323.15</td>\n",
       "      <td>...</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-01 09:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>322.38</td>\n",
       "      <td>322.59</td>\n",
       "      <td>...</td>\n",
       "      <td>491.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-01 09:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319.61</td>\n",
       "      <td>319.81</td>\n",
       "      <td>...</td>\n",
       "      <td>498.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-01 09:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319.61</td>\n",
       "      <td>319.81</td>\n",
       "      <td>...</td>\n",
       "      <td>399.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-01 10:00:00</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>1759.0</td>\n",
       "      <td>9444.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4538300.0</td>\n",
       "      <td>319.86</td>\n",
       "      <td>320.53</td>\n",
       "      <td>...</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7010.0</td>\n",
       "      <td>214.64</td>\n",
       "      <td>215.11</td>\n",
       "      <td>214.0</td>\n",
       "      <td>214.95</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2113.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  open_AGFS  high_AGFS  low_AGFS  close_AGFS  \\\n",
       "0 2022-06-01 09:00:00        NaN        NaN       NaN         NaN   \n",
       "1 2022-06-01 09:15:00        NaN        NaN       NaN         NaN   \n",
       "2 2022-06-01 09:30:00        NaN        NaN       NaN         NaN   \n",
       "3 2022-06-01 09:45:00        NaN        NaN       NaN         NaN   \n",
       "4 2022-06-01 10:00:00     1757.0     1760.0    1756.0      1759.0   \n",
       "\n",
       "   tick_volume_AGFS  spread_AGFS  real_volume_AGFS  open_BGI$  high_BGI$  ...  \\\n",
       "0               0.0          NaN               0.0     319.66     323.15  ...   \n",
       "1               0.0          NaN               0.0     322.38     322.59  ...   \n",
       "2               0.0          NaN               0.0     319.61     319.81  ...   \n",
       "3               0.0          NaN               0.0     319.61     319.81  ...   \n",
       "4            9444.0          0.0         4538300.0     319.86     320.53  ...   \n",
       "\n",
       "   tick_volume_IND$  spread_IND$  real_volume_IND$  open_IVVB11  high_IVVB11  \\\n",
       "0             480.0          1.0            2675.0          NaN          NaN   \n",
       "1             491.0          1.0            2550.0          NaN          NaN   \n",
       "2             498.0          1.0            2625.0          NaN          NaN   \n",
       "3             399.0          1.0            2175.0          NaN          NaN   \n",
       "4            1242.0          1.0            7010.0       214.64       215.11   \n",
       "\n",
       "   low_IVVB11  close_IVVB11  tick_volume_IVVB11  spread_IVVB11  \\\n",
       "0         NaN           NaN                 0.0            NaN   \n",
       "1         NaN           NaN                 0.0            NaN   \n",
       "2         NaN           NaN                 0.0            NaN   \n",
       "3         NaN           NaN                 0.0            NaN   \n",
       "4       214.0        214.95               227.0            1.0   \n",
       "\n",
       "   real_volume_IVVB11  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4              2113.0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = process_data(input_dir=input_dir, output_dir=output_dir)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|      variable      | missing_values |\n",
      "+--------------------+----------------+\n",
      "|        time        |       0        |\n",
      "|     open_AGFS      |       4        |\n",
      "|     high_AGFS      |       4        |\n",
      "|      low_AGFS      |       4        |\n",
      "|     close_AGFS     |       4        |\n",
      "|  tick_volume_AGFS  |       0        |\n",
      "|    spread_AGFS     |       4        |\n",
      "|  real_volume_AGFS  |       0        |\n",
      "|     open_BGI$      |       0        |\n",
      "|     high_BGI$      |       0        |\n",
      "|      low_BGI$      |       0        |\n",
      "|     close_BGI$     |       0        |\n",
      "|  tick_volume_BGI$  |       0        |\n",
      "|    spread_BGI$     |       0        |\n",
      "|  real_volume_BGI$  |       0        |\n",
      "|     open_CCM$      |       0        |\n",
      "|     high_CCM$      |       0        |\n",
      "|      low_CCM$      |       0        |\n",
      "|     close_CCM$     |       0        |\n",
      "|  tick_volume_CCM$  |       0        |\n",
      "|    spread_CCM$     |       0        |\n",
      "|  real_volume_CCM$  |       0        |\n",
      "|     open_DI1$      |       0        |\n",
      "|     high_DI1$      |       0        |\n",
      "|      low_DI1$      |       0        |\n",
      "|     close_DI1$     |       0        |\n",
      "|  tick_volume_DI1$  |       0        |\n",
      "|    spread_DI1$     |       0        |\n",
      "|  real_volume_DI1$  |       0        |\n",
      "|     open_DOL$      |       0        |\n",
      "|     high_DOL$      |       0        |\n",
      "|      low_DOL$      |       0        |\n",
      "|     close_DOL$     |       0        |\n",
      "|  tick_volume_DOL$  |       0        |\n",
      "|    spread_DOL$     |       0        |\n",
      "|  real_volume_DOL$  |       0        |\n",
      "|    open_GOLD11     |       4        |\n",
      "|    high_GOLD11     |       4        |\n",
      "|     low_GOLD11     |       4        |\n",
      "|    close_GOLD11    |       4        |\n",
      "| tick_volume_GOLD11 |       0        |\n",
      "|   spread_GOLD11    |       4        |\n",
      "| real_volume_GOLD11 |       0        |\n",
      "|     open_IBOV      |       4        |\n",
      "|     high_IBOV      |       4        |\n",
      "|      low_IBOV      |       4        |\n",
      "|     close_IBOV     |       4        |\n",
      "|  tick_volume_IBOV  |       0        |\n",
      "|    spread_IBOV     |       4        |\n",
      "|  real_volume_IBOV  |       0        |\n",
      "|     open_ICF$      |       0        |\n",
      "|     high_ICF$      |       0        |\n",
      "|      low_ICF$      |       0        |\n",
      "|     close_ICF$     |       0        |\n",
      "|  tick_volume_ICF$  |       0        |\n",
      "|    spread_ICF$     |       0        |\n",
      "|  real_volume_ICF$  |       0        |\n",
      "|     open_ICON      |       4        |\n",
      "|     high_ICON      |       4        |\n",
      "|      low_ICON      |       4        |\n",
      "|     close_ICON     |       4        |\n",
      "|  tick_volume_ICON  |       0        |\n",
      "|    spread_ICON     |       4        |\n",
      "|  real_volume_ICON  |       0        |\n",
      "|     open_IFIX      |       4        |\n",
      "|     high_IFIX      |       4        |\n",
      "|      low_IFIX      |       4        |\n",
      "|     close_IFIX     |       4        |\n",
      "|  tick_volume_IFIX  |       0        |\n",
      "|    spread_IFIX     |       4        |\n",
      "|  real_volume_IFIX  |       0        |\n",
      "|     open_IND$      |       0        |\n",
      "|     high_IND$      |       0        |\n",
      "|      low_IND$      |       0        |\n",
      "|     close_IND$     |       0        |\n",
      "|  tick_volume_IND$  |       0        |\n",
      "|    spread_IND$     |       0        |\n",
      "|  real_volume_IND$  |       0        |\n",
      "|    open_IVVB11     |       4        |\n",
      "|    high_IVVB11     |       4        |\n",
      "|     low_IVVB11     |       4        |\n",
      "|    close_IVVB11    |       4        |\n",
      "| tick_volume_IVVB11 |       0        |\n",
      "|   spread_IVVB11    |       4        |\n",
      "| real_volume_IVVB11 |       0        |\n",
      "+--------------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "isna_df = pd.DataFrame(data.isna().sum(), columns=['missing_values']).reset_index()\n",
    "isna_df.columns = ['variable', 'missing_values']\n",
    "print(tabulate(isna_df, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
